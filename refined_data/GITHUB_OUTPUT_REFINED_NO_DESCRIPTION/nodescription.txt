File: 108_atilsamancioglu_PythonCourse.txt
ID: 108
Full Name: atilsamancioglu/PythonCourse
Description: None
Created At: 2018-12-28T18:05:37Z
Updated At: 2024-11-22T23:51:54Z
Pushed At: 2024-01-30T23:29:49Z
Language: Jupyter Notebook
URL: https://github.com/atilsamancioglu/PythonCourse
Forks: 747
Stars: 481
Topics: 
README:
# PythonCourse
This is a repository containing Udemy Python Course for Atil Samancioglu



File: 148_calistus-igwilo_python.txt
ID: 148
Full Name: calistus-igwilo/python
Description: None
Created At: 2022-06-04T16:00:44Z
Updated At: 2024-01-24T19:12:32Z
Pushed At: 2022-12-06T13:22:42Z
Language: Python
URL: https://github.com/calistus-igwilo/python
Forks: 47
Stars: 126
Topics: 
README:



File: 175_davidbombal_red-python-scripts.txt
ID: 175
Full Name: davidbombal/red-python-scripts
Description: None
Created At: 2021-01-07T16:11:52Z
Updated At: 2024-12-01T13:50:52Z
Pushed At: 2024-10-22T13:31:06Z
Language: Python
URL: https://github.com/davidbombal/red-python-scripts
Forks: 1593
Stars: 2047
Topics: 
README:



File: 194_yasoob_intermediatePython.txt
ID: 194
Full Name: yasoob/intermediatePython
Description: None
Created At: 2015-08-15T21:21:51Z
Updated At: 2024-11-30T19:21:01Z
Pushed At: 2023-04-14T09:46:35Z
Language: Python
URL: https://github.com/yasoob/intermediatePython
Forks: 706
Stars: 3849
Topics: 
README:
![Intermediate Python Book Cover](_static/cover.png)

Intermediate Python
===================

Python is an amazing language with a strong and friendly community of programmers. However, there is a lack of documentation on what to learn after getting the basics of Python down your throat. Through this book I aim to solve this problem. I will give you bits of information about some interesting topics which you can further explore.

The topics which are discussed in this book will open your mind to some nice corners of Python language. This book is an outcome of my desire to have something like this when I was beginning to learn Python.

If you are a beginner, intermediate or even an advanced programmer there is something for you in this book.

Please note that this book is not a tutorial and does not teach you Python. The topics are not explained in-depth and only the minimum required information is given.

I am sure you are as excited as I am. So, let’s start!

Note: This book is a work in progress. If you find anything which you can further improve (I know you will find a lot of stuff) then kindly submit a pull request. :)

Moreover, if you want to add more content to this book then kindly submit a pull request and I will be more than happy to merge it. :+1:

-------------------

**Note:** If you want to tip me for my work then you can buy the donation version of this book from [Gumroad](https://gum.co/intermediate_python). Apart from that, if this book somehow helps you then kindly share your experience with [me](mailto:yasoob.khld@gmail.com). I would really appreciate it.

-------------------

Table of Contents:
------------------
1) Programmer tools
    - [Virtual Environment](virtual_environment.rst)
    - [Debugging](debugging.rst)
    - [Object introspection](object_introspection.rst)
2) Syntax
    - [Exceptions](exceptions.rst)
    - [For - Else](for_-_else.rst)
    - [Ternary Operators](ternary_operators.rst)
    - [Global & Return](global_&_return.rst)
    - [Open function](open_function.rst)
    - [\*args and \*\*kwargs](args_and_kwargs.rst)
    - [Context managers](context_managers.rst)
3) Functional programming
    - [Enumerate](enumerate.rst)
    - [Lambdas](lambdas.rst)
    - [``set`` Data Structure](set_-_data_structure.rst)
    - [Map & Filter](map_filter.rst)
    - [Comprehensions](comprehensions.rst)
4) Data structures
    - [Generators](generators.rst)
    - [Coroutines](coroutines.rst)
    - [Classes](classes.rst)
5) Data types
    - [Collections](collections.rst)
    - [Mutation](mutation.rst)
    - [\_\_slots\_\_ Magic](__slots__magic.rst)
6) Decorators
    - [What is a decorator?](decorators.rst)
    - [Function caching](function_caching.rst)
7) Extras
    - [One Liners](one_liners.rst)
    - [Targeting Python 2+3](targeting_python_2_3.rst)
    - [Python C extensions](python_c_extension.rst)

Author:
------

- [Muhammad Yasoob Ullah Khalid](https://github.com/yasoob)

Acknowledgement:
----------------

- [Philipp Hagemeister](https://github.com/phihag):

He wrote the chapter on Open function. Thanks Philipp! :+1:

Translation:
------------
If you want to translate this book in any other language then kindly let [me know](mailto:yasoob.khld@gmail.com). I would love your contribution. The currently translated versions are listed below:

- [Chinese](https://github.com/eastlakeside/interpy-zh)
- [Russian](https://github.com/lancelote/interpy-ru)
- [Korean](https://github.com/DDanggle/interpy-kr)
- [Portuguese](https://github.com/joanasouza/intermediatePython)
- [Spanish](https://github.com/cursospython/LibroPython)

License:
-------

This book is released under the [following](http://creativecommons.org/licenses/by-nc-sa/4.0/) CC license (CC BY-NC-SA 4.0).

If you end up using/recommending this book to someone then kindly [let me know](mailto:yasoob.khld@gmail.com). :smile:





File: 226_SAML-Toolkits_python3-saml.txt
ID: 226
Full Name: SAML-Toolkits/python3-saml
Description: None
Created At: 2015-08-14T16:24:22Z
Updated At: 2024-11-28T08:25:39Z
Pushed At: 2024-11-22T22:14:18Z
Language: Python
URL: https://github.com/SAML-Toolkits/python3-saml
Forks: 309
Stars: 705
Topics: 
README:
# SAML Python3 Toolkit

[![Python package](https://github.com/SAML-Toolkits/python3-saml/actions/workflows/python-package.yml/badge.svg)](https://github.com/SAML-Toolkits/python3-saml/actions/workflows/python-package.yml)
![PyPI Downloads](https://img.shields.io/pypi/dm/python3-saml.svg?label=PyPI%20Downloads)
[![Coverage Status](https://coveralls.io/repos/github/SAML-Toolkits/python3-saml/badge.svg?branch=master)](https://coveralls.io/github/SAML-Toolkits/python3-saml?branch=master)
[![PyPi Version](https://img.shields.io/pypi/v/python3-saml.svg)](https://pypi.python.org/pypi/python3-saml)
![Python versions](https://img.shields.io/python/required-version-toml?tomlFilePath=https%3A%2F%2Fraw.githubusercontent.com%2FSAML-Toolkits%2Fpython3-saml%2Fmaster%2Fpyproject.toml)

Add SAML support to your Python software using this library.
Forget those complicated libraries and use the open source library provided by the SAML tool community.

This version supports Python3. Python 2 support was deprecated on Jan 1st, 2020: [python-saml](https://github.com/onelogin/python-saml)

#### Warning ####

Version 1.16.X is the latest version supporting Python2, consider its use deprecated. 1.17 won't be Python2 and old Python3 compatible.

Version 1.13.0 sets sha256 and rsa-sha256 as default algorithms

Version 1.8.0 sets strict mode active by default

Update ``python3-saml`` to ``1.5.0``, this version includes security improvements for preventing XEE and Xpath Injections.

Update ``python3-saml`` to ``1.4.0``, this version includes a fix for the [CVE-2017-11427](https://www.cvedetails.com/cve/CVE-2017-11427/) vulnerability.

This version also changes how the calculate fingerprint method works, and will expect as input a formatted X.509 certificate.

Update ``python3-saml`` to ``1.2.6`` that adds the use defusedxml that will prevent XEE and other attacks based on the abuse of XML. (CVE-2017-9672)

Update ``python3-saml`` to ``>= 1.2.1``, ``1.2.0`` had a bug on signature validation process (when using ``wantAssertionsSigned`` and ``wantMessagesSigned``). [CVE-2016-1000251](https://github.com/distributedweaknessfiling/DWF-Database-Artifacts/blob/master/DWF/2016/1000251/CVE-2016-1000251.json)

``1.2.0`` version includes a security patch that contains extra validations that will prevent signature wrapping attacks.

``python3-saml < v1.2.0`` is vulnerable and allows signature wrapping!

#### Security Guidelines ####

If you believe you have discovered a security vulnerability in this toolkit, please report it by mail to the maintainer: sixto.martin.garcia+security@gmail.com

### Sponsors
Thanks to the following sponsors for their support:

[<img alt="84codes" src="https://avatars.githubusercontent.com/u/739212?s=200&v=4" width="50px">](https://www.maykinmedia.nl)

Why add SAML support to my software?
------------------------------------

SAML is an XML-based standard for web browser single sign-on and is defined by
the OASIS Security Services Technical Committee. The standard has been around
since 2002, but lately it is becoming popular due its advantages:

 * **Usability** - One-click access from portals or intranets, deep linking,
   password elimination and automatically renewing sessions make life
   easier for the user.
 * **Security** - Based on strong digital signatures for authentication and
   integrity, SAML is a secure single sign-on protocol that the largest
   and most security conscious enterprises in the world rely on.
 * **Speed** - SAML is fast. One browser redirect is all it takes to securely
   sign a user into an application.
 * **Phishing Prevention** - If you don’t have a password for an app, you
   can’t be tricked into entering it on a fake login page.
 * **IT Friendly** - SAML simplifies life for IT because it centralizes
   authentication, provides greater visibility and makes directory
   integration easier.
 * **Opportunity** - B2B cloud vendor should support SAML to facilitate the
   integration of their product.

General Description
-------------------

SAML Python toolkit lets you turn your Python application into a SP
(Service Provider) that can be connected to an IdP (Identity Provider).

**Supports:**

 * SSO and SLO (SP-Initiated and IdP-Initiated).
 * Assertion and nameId encryption.
 * Assertion signatures.
 * Message signatures: ``AuthNRequest``, ``LogoutRequest``, ``LogoutResponses``.
 * Enable an Assertion Consumer Service endpoint.
 * Enable a Single Logout Service endpoint.
 * Publish the SP metadata (which can be signed).

**Key Features:**

 * **saml2int** - Implements the SAML 2.0 Web Browser SSO Profile.
 * **Session-less** - Forget those common conflicts between the SP and
   the final app, the toolkit delegate session in the final app.
 * **Easy to use** - Programmer will be allowed to code high-level and
   low-level programming, 2 easy to use APIs are available.
 * **Tested** - Thoroughly tested.

Installation
------------

### Dependencies ###

 * python => 3.7
 * [xmlsec](https://pypi.python.org/pypi/xmlsec) Python bindings for the XML Security Library.
 * [lxml](https://pypi.python.org/pypi/lxml) Python bindings for the libxml2 and libxslt libraries.
 * [isodate](https://pypi.python.org/pypi/isodate) An ISO 8601 date/time/
 duration parser and formatter

Review the ``pyproject.toml`` file to know the version of the library that ``python3-saml`` is using

### Code ###

#### Option 1. Download from GitHub ####

The toolkit is hosted on GitHub. You can download it from:

 * Latest release: https://github.com/saml-toolkits/python3-saml/releases/latest
 * Master repo: https://github.com/saml-toolkits/python3-saml/tree/master

Find the core of the library at ``src/onelogin/saml2`` folder.

#### Option 2. Download from pypi ####

The toolkit is hosted in pypi, you can find the ``python3-saml`` package at https://pypi.python.org/pypi/python3-saml

You can install it executing:
```
$ pip install python3-saml
```

If you want to know how a project can handle python packages review this [guide](https://packaging.python.org/en/latest/tutorial.html) and review this [sampleproject](https://github.com/pypa/sampleproject)

#### NOTE ####
To avoid ``libxml2`` library version incompatibilities between ``xmlsec`` and ``lxml`` it is recommended that ``lxml`` is not installed from binary.

This can be ensured by executing:
```
$ pip install --force-reinstall --no-binary lxml lxml
```

Security Warning
----------------

In production, the **strict** parameter MUST be set as **"true"**. Otherwise
your environment is not secure and will be exposed to attacks.

In production also we highly recommend to register on the settings the IdP certificate instead of using the fingerprint method. The fingerprint, is a hash, so at the end is open to a collision attack that can end on a signature validation bypass. Other SAML toolkits deprecated that mechanism, we maintain it for compatibility and also to be used on test environment.


### Avoiding Open Redirect attacks ###

Some implementations uses the RelayState parameter as a way to control the flow when SSO and SLO succeeded. So basically the
user is redirected to the value of the RelayState.

If you are using Signature Validation on the HTTP-Redirect binding, you will have the RelayState value integrity covered, otherwise, and
on HTTP-POST binding, you can't trust the RelayState so before
executing the validation, you need to verify that its value belong
a trusted and expected URL.

Read more about Open Redirect [CWE-601](https://cwe.mitre.org/data/definitions/601.html).

### Avoiding Replay attacks ###

A replay attack is basically try to reuse an intercepted valid SAML Message in order to impersonate a SAML action (SSO or SLO).

SAML Messages have a limited timelife (NotBefore, NotOnOrAfter) that
make harder this kind of attacks, but they are still possible.

In order to avoid them, the SP can keep a list of SAML Messages or Assertion IDs already validated and processed. Those values only need
to be stored the amount of time of the SAML Message life time, so
we don't need to store all processed message/assertion Ids, but the most recent ones.

The OneLogin_Saml2_Auth class contains the [get_last_request_id](https://github.com/onelogin/python3-saml/blob/ab62b0d6f3e5ac2ae8e95ce3ed2f85389252a32d/src/onelogin/saml2/auth.py#L357), [get_last_message_id](https://github.com/onelogin/python3-saml/blob/ab62b0d6f3e5ac2ae8e95ce3ed2f85389252a32d/src/onelogin/saml2/auth.py#L364) and [get_last_assertion_id](https://github.com/onelogin/python3-saml/blob/ab62b0d6f3e5ac2ae8e95ce3ed2f85389252a32d/src/onelogin/saml2/auth.py#L371) methods to retrieve the IDs

Checking that the ID of the current Message/Assertion does not exists in the list of the ones already processed will prevent replay attacks.


Getting Started
---------------

### Knowing the toolkit ###

The new SAML Toolkit contains different folders (``certs``, ``lib``, ``demo-django``, ``demo-flask`` and ``tests``) and some files.

Let's start describing them:

#### src ####

This folder contains the heart of the toolkit, **onelogin/saml2** folder contains the new version of
the classes and methods that are described in a later section.

#### demo-django ####

This folder contains a Django project that will be used as demo to show how to add SAML support to the Django Framework. **demo** is the main folder of the Django project (with its ``settings.py``, ``views.py``, ``urls.py``), **templates** is the Django templates of the project and **saml** is a folder that contains the ``certs`` folder that could be used to store the X.509 public and private key, and the SAML toolkit settings (``settings.json`` and ``advanced_settings.json``).

***Notice about certs***

SAML requires a X.509 cert to sign and encrypt elements like ``NameID``, ``Message``, ``Assertion``, ``Metadata``.

If our environment requires sign or encrypt support, the certs folder may contain the X.509 cert and the private key that the SP will use:

* sp.crt The public cert of the SP
* sp.key The private key of the SP

Or also we can provide those data in the setting file at the ``x509cert`` and the ``privateKey`` JSON parameters of the ``sp`` element.

Sometimes we could need a signature on the metadata published by the SP, in this case we could use the X.509 cert previously mentioned or use a new X.509 cert: ``metadata.crt`` and ``metadata.key``.

Use ``sp_new.crt`` if you are in a key rollover process and you want to
publish that X.509 certificate on Service Provider metadata.

If you want to create self-signed certs, you can do it at the https://www.samltool.com/self_signed_certs.php service, or using the command:

```bash
openssl req -new -x509 -days 3652 -nodes -out sp.crt -keyout sp.key
```

#### demo-flask ####

This folder contains a Flask project that will be used as demo to show how to add SAML support to the Flask Framework. ``index.py`` is the main Flask file that has all the code, this file uses the templates stored at the ``templates`` folder. In the ``saml`` folder we found the ``certs`` folder to store the X.509 public and private key, and the SAML toolkit settings (``settings.json`` and ``advanced_settings.json``).

#### demo_pyramid ####

This folder contains a Pyramid project that will be used as demo to show how to add SAML support to the [Pyramid Web Framework](http://docs.pylonsproject.org/projects/pyramid/en/latest/).  ``\_\_init__.py`` is the main file that configures the app and its routes, ``views.py`` is where all the logic and SAML handling takes place, and the templates are stored in the ``templates`` folder. The ``saml`` folder is the same as in the other two demos.

#### demo-tornado ####

This folder contains a Tornado project that will be used as demo to show how to add SAML support to the Tornado Framework. ``views.py`` (with its ``settings.py``) is the main Flask file that has all the code, this file uses the templates stored at the ``templates`` folder. In the ``saml`` folder we found the ``certs`` folder to store the X.509 public and private key, and the SAML toolkit settings (``settings.json`` and ``advanced_settings.json``).

It requires python3.8 (it's using tornado 6.4.1)


#### tests ####

Contains the unit test of the toolkit.

In order to execute the test you only need to load the virtualenv with the toolkit installed on it properly:
```
make install-test
```

and execute:
```
make pytest
```
The previous line will run the tests for the whole toolkit. You can also run the tests for a specific module. To do so for the auth module you would have to execute this:
```
pytest tests/src/OneLogin/saml2_tests/auth_test.py::OneLogin_Saml2_Auth_Test
```

Or for an specific method:
```
pytest tests/src/OneLogin/saml2_tests/auth_test.py::OneLogin_Saml2_Auth_Test::testBuildRequestSignature
```


### How It Works ###

#### Settings ####

First of all we need to configure the toolkit. The SP's info, the IdP's info, and in some cases, configure advanced security issues like signatures and encryption.

There are two ways to provide the settings information:

* Use a ``settings.json`` file that we should locate in any folder, but indicates its path with the ``custom_base_path`` parameter.

* Use a JSON object with the setting data and provide it directly to the constructor of the class (if your toolkit integation requires certs, remember to provide the ``custom_base_path`` as part of the settings or as a parameter in the constructor).

In the demo-django and in the demo-flask folders you will find a ``saml`` folder, inside there is a ``certs`` folder and a ``settings.json`` and ``advanced_settings.json`` file. Those files contain the settings for the SAML toolkit. Copy them in your project and set the correct values.

This is the ``settings.json`` file:

```javascript
{
    // If strict is True, then the Python Toolkit will reject unsigned
    // or unencrypted messages if it expects them to be signed or encrypted.
    // Also it will reject the messages if the SAML standard is not strictly
    // followed. Destination, NameId, Conditions ... are validated too.
    "strict": true,

    // Enable debug mode (outputs errors).
    "debug": true,

    // Service Provider Data that we are deploying.
    "sp": {
        // Identifier of the SP entity  (must be a URI)
        "entityId": "https://<sp_domain>/metadata/",
        // Specifies info about where and how the <AuthnResponse> message MUST be
        // returned to the requester, in this case our SP.
        "assertionConsumerService": {
            // URL Location where the <Response> from the IdP will be returned
            "url": "https://<sp_domain>/?acs",
            // SAML protocol binding to be used when returning the <Response>
            // message. SAML Toolkit supports this endpoint for the
            // HTTP-POST binding only.
            "binding": "urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST"
        },
        // Specifies info about where and how the <Logout Request/Response> message MUST be sent.
        "singleLogoutService": {
            // URL Location where the <LogoutRequest> from the IdP will be sent (IdP-initiated logout)
            "url": "https://<sp_domain>/?sls",
            // URL Location where the <LogoutResponse> from the IdP will sent (SP-initiated logout, reply)
            // OPTIONAL: only specify if different from url parameter
            //"responseUrl": "https://<sp_domain>/?sls",
            // SAML protocol binding to be used when returning the <Response>
            // message. SAML Toolkit supports the HTTP-Redirect binding
            // only for this endpoint.
            "binding": "urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect"
        },
        // If you need to specify requested attributes, set a
        // attributeConsumingService. nameFormat, attributeValue and
        // friendlyName can be omitted
        "attributeConsumingService": {
                // OPTIONAL: only specify if SP requires this.
                // index is an integer which identifies the attributeConsumingService used
                // to the SP. SAML toolkit supports configuring only one attributeConsumingService
                // but in certain cases the SP requires a different value.  Defaults to '1'.
                // "index": '1',
                "serviceName": "SP test",
                "serviceDescription": "Test Service",
                "requestedAttributes": [
                    {
                        "name": "",
                        "isRequired": false,
                        "nameFormat": "",
                        "friendlyName": "",
                        "attributeValue": []
                    }
                ]
        },
        // Specifies the constraints on the name identifier to be used to
        // represent the requested subject.
        // Take a look on src/onelogin/saml2/constants.py to see the NameIdFormat that are supported.
        "NameIDFormat": "urn:oasis:names:tc:SAML:1.1:nameid-format:unspecified",
        // Usually X.509 cert and privateKey of the SP are provided by files placed at
        // the certs folder. But we can also provide them with the following parameters
        "x509cert": "",
        "privateKey": ""

        /*
         * Key rollover
         * If you plan to update the SP X.509cert and privateKey
         * you can define here the new X.509cert and it will be
         * published on the SP metadata so Identity Providers can
         * read them and get ready for rollover.
         */
        // 'x509certNew': '',
    },

    // Identity Provider Data that we want connected with our SP.
    "idp": {
        // Identifier of the IdP entity  (must be a URI)
        "entityId": "https://app.onelogin.com/saml/metadata/<onelogin_connector_id>",
        // SSO endpoint info of the IdP. (Authentication Request protocol)
        "singleSignOnService": {
            // URL Target of the IdP where the Authentication Request Message
            // will be sent.
            "url": "https://app.onelogin.com/trust/saml2/http-post/sso/<onelogin_connector_id>",
            // SAML protocol binding to be used when returning the <Response>
            // message. SAML Toolkit supports the HTTP-Redirect binding
            // only for this endpoint.
            "binding": "urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect"
        },
        // SLO endpoint info of the IdP.
        "singleLogoutService": {
            // URL Location where the <LogoutRequest> from the IdP will be sent (IdP-initiated logout)
            "url": "https://app.onelogin.com/trust/saml2/http-redirect/slo/<onelogin_connector_id>",
            // URL Location where the <LogoutResponse> from the IdP will sent (SP-initiated logout, reply)
            // OPTIONAL: only specify if different from url parameter
            "responseUrl": "https://app.onelogin.com/trust/saml2/http-redirect/slo_return/<onelogin_connector_id>",
            // SAML protocol binding to be used when returning the <Response>
            // message. SAML Toolkit supports the HTTP-Redirect binding
            // only for this endpoint.
            "binding": "urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect"
        },
        // Public X.509 certificate of the IdP
        "x509cert": "<onelogin_connector_cert>"
        /*
         *  Instead of using the whole X.509cert you can use a fingerprint in order to
         *  validate a SAMLResponse (but you still need the X.509cert to validate LogoutRequest and LogoutResponse using the HTTP-Redirect binding).
         *  But take in mind that the algorithm for the fingerprint should be as strong as the algorithm in a normal certificate signature
	 *  (e.g. SHA256 or strong)
         *
         *  (openssl x509 -noout -fingerprint -in "idp.crt" to generate it,
         *  or add for example the -sha256 , -sha384 or -sha512 parameter)
         *
         *  If a fingerprint is provided, then the certFingerprintAlgorithm is required in order to
         *  let the toolkit know which algorithm was used.
         Possible values: sha1, sha256, sha384 or sha512
         *  'sha1' is the default value.
         *
         *  Notice that if you want to validate any SAML Message sent by the HTTP-Redirect binding, you
         *  will need to provide the whole X.509cert.
         */
        // "certFingerprint": "",
        // "certFingerprintAlgorithm": "sha1",

        /* In some scenarios the IdP uses different certificates for
         * signing/encryption, or is under key rollover phase and
         * more than one certificate is published on IdP metadata.
         * In order to handle that the toolkit offers that parameter.
         * (when used, 'X.509cert' and 'certFingerprint' values are
         * ignored).
         */
        // 'x509certMulti': {
        //      'signing': [
        //          '<cert1-string>'
        //      ],
        //      'encryption': [
        //          '<cert2-string>'
        //      ]
        // }
    }
}
```

In addition to the required settings data (idp, sp), extra settings can be defined in `advanced_settings.json`:

```javascript
{
    // Security settings
    "security": {

        /** signatures and encryptions offered **/

        // Indicates that the nameID of the <samlp:logoutRequest> sent by this SP
        // will be encrypted.
        "nameIdEncrypted": false,

        // Indicates whether the <samlp:AuthnRequest> messages sent by this SP
        // will be signed.  [Metadata of the SP will offer this info]
        "authnRequestsSigned": false,

        // Indicates whether the <samlp:logoutRequest> messages sent by this SP
        // will be signed.
        "logoutRequestSigned": false,

        // Indicates whether the <samlp:logoutResponse> messages sent by this SP
        // will be signed.
        "logoutResponseSigned": false,

        /* Sign the Metadata
         false || true (use sp certs) || {
                                            "keyFileName": "metadata.key",
                                            "certFileName": "metadata.crt"
                                         }
        */
        "signMetadata": false,

        /** signatures and encryptions required **/

        // Indicates a requirement for the <samlp:Response>, <samlp:LogoutRequest>
        // and <samlp:LogoutResponse> elements received by this SP to be signed.
        "wantMessagesSigned": false,

        // Indicates a requirement for the <saml:Assertion> elements received by
        // this SP to be signed. [Metadata of the SP will offer this info]
        "wantAssertionsSigned": false,

        // Indicates a requirement for the <saml:Assertion>
        // elements received by this SP to be encrypted.
        "wantAssertionsEncrypted": false,

        // Indicates a requirement for the NameID element on the SAMLResponse
        // received by this SP to be present.
        "wantNameId": true,

        // Indicates a requirement for the NameID received by
        // this SP to be encrypted.
        "wantNameIdEncrypted": false,

        // Indicates a requirement for the AttributeStatement element
        "wantAttributeStatement": true,

        // Authentication context.
        // Set to false and no AuthContext will be sent in the AuthNRequest,
        // Set true or don't present this parameter and you will get an AuthContext 'exact' 'urn:oasis:names:tc:SAML:2.0:ac:classes:PasswordProtectedTransport'
        // Set an array with the possible auth context values: array ('urn:oasis:names:tc:SAML:2.0:ac:classes:Password', 'urn:oasis:names:tc:SAML:2.0:ac:classes:X509'),
        "requestedAuthnContext": true,
	// Allows the authn comparison parameter to be set, defaults to 'exact' if the setting is not present.
        "requestedAuthnContextComparison": "exact",
        // Set to true to check that the AuthnContext(s) received match(es) the requested.
        "failOnAuthnContextMismatch": false,

        // In some environment you will need to set how long the published metadata of the Service Provider gonna be valid.
        // is possible to not set the 2 following parameters (or set to null) and default values will be set (2 days, 1 week)
        // Provide the desire TimeStamp, for example 2015-06-26T20:00:00Z
        "metadataValidUntil": null,
        // Provide the desire Duration, for example PT518400S (6 days)
        "metadataCacheDuration": null,

        // If enabled, URLs with single-label-domains will
        // be allowed and not rejected by the settings validator (Enable it under Docker/Kubernetes/testing env, not recommended on production)
        "allowSingleLabelDomains": false,

        // Algorithm that the toolkit will use on signing process. Options:
        //    'http://www.w3.org/2000/09/xmldsig#rsa-sha1'
        //    'http://www.w3.org/2000/09/xmldsig#dsa-sha1'
        //    'http://www.w3.org/2001/04/xmldsig-more#rsa-sha256'
        //    'http://www.w3.org/2001/04/xmldsig-more#rsa-sha384'
        //    'http://www.w3.org/2001/04/xmldsig-more#rsa-sha512'
        "signatureAlgorithm": "http://www.w3.org/2001/04/xmldsig-more#rsa-sha256",

        // Algorithm that the toolkit will use on digest process. Options:
        //    'http://www.w3.org/2000/09/xmldsig#sha1'
        //    'http://www.w3.org/2001/04/xmlenc#sha256'
        //    'http://www.w3.org/2001/04/xmldsig-more#sha384'
        //    'http://www.w3.org/2001/04/xmlenc#sha512'
        'digestAlgorithm': "http://www.w3.org/2001/04/xmlenc#sha256",

        // Specify if you want the SP to view assertions with duplicated Name or FriendlyName attributes to be valid
        // Defaults to false if not specified
        'allowRepeatAttributeName': false,

        // If the toolkit receive a message signed with a
        // deprecated algorithm (defined at the constant class)
        // will raise an error and reject the message
        "rejectDeprecatedAlgorithm": true
    },

    // Contact information template, it is recommended to suply a
    // technical and support contacts.
    "contactPerson": {
        "technical": {
            "givenName": "technical_name",
            "emailAddress": "technical@example.com"
        },
        "support": {
            "givenName": "support_name",
            "emailAddress": "support@example.com"
        }
    },

    // Organization information template, the info in en_US lang is
    // recommended, add more if required.
    "organization": {
        "en-US": {
            "name": "sp_test",
            "displayname": "SP test",
            "url": "http://sp.example.com"
        }
    }
}
```

In the ``security`` section, you can set the way that the SP will handle the messages and assertions. Contact the admin of the IdP and ask them what the IdP expects, and decide what validations will handle the SP and what requirements the SP will have and communicate them to the IdP's admin too.

Once we know what kind of data could be configured, let's talk about the way settings are handled within the toolkit.

The settings files described (``settings.json`` and ``advanced_settings.json``) are loaded by the toolkit if not other dict with settings info is provided in the constructors of the toolkit. Let's see some examples.

```python
# Initializes toolkit with settings.json & advanced_settings.json files.
auth = OneLogin_Saml2_Auth(req)
# or
settings = OneLogin_Saml2_Settings()

# Initializes toolkit with settings.json & advanced_settings.json files from a custom base path.
custom_folder = '/var/www/django-project'
auth = OneLogin_Saml2_Auth(req, custom_base_path=custom_folder)
# or
settings = OneLogin_Saml2_Settings(custom_base_path=custom_folder)

# Initializes toolkit with the dict provided.
auth = OneLogin_Saml2_Auth(req, settings_data)
# or
settings = OneLogin_Saml2_Settings(settings_data)
```

You can declare the ``settings_data`` in the file that contains the constructor execution or locate them in any file and load the file in order to get the dict available as we see in the following example:

```python
filename = "/var/www/django-project/custom_settings.json" # The custom_settings.json contains a
json_data_file = open(filename, 'r')                      # settings_data dict.
settings_data = json.load(json_data_file)
json_data_file.close()

auth = OneLogin_Saml2_Auth(req, settings_data)
```

#### Metadata Based Configuration

The method above requires a little extra work to manually specify attributes about the IdP. (And your SP application)

There's an easier method -- use a metadata exchange.  Metadata is just an XML file that defines the capabilities of both the IdP and the SP application.  It also contains the X.509 public key certificates which add to the trusted relationship.  The IdP administrator can also configure custom settings for an SP based on the metadata.

Using ````parse_remote```` IdP metadata can be obtained and added to the settings without further ado.

Take in mind that the OneLogin_Saml2_IdPMetadataParser class does not validate in any way the URL that is introduced in order to be parsed.

Usually the same administrator that handles the Service Provider also sets the URL to the IdP, which should be a trusted resource.

But there are other scenarios, like a SAAS app where the administrator of the app delegates this functionality to other users. In this case, extra precaution should be taken in order to validate such URL inputs and avoid attacks like SSRF.


``
idp_data = OneLogin_Saml2_IdPMetadataParser.parse_remote('https://example.com/auth/saml2/idp/metadata')
``

You can specify a timeout in seconds for metadata retrieval, without it is not guaranteed that the request will complete

``
idp_data = OneLogin_Saml2_IdPMetadataParser.parse_remote('https://example.com/auth/saml2/idp/metadata', timeout=5)
``

If the Metadata contains several entities, the relevant ``EntityDescriptor`` can be specified when retrieving the settings from the ``IdpMetadataParser`` by its ``entityId`` value:

``idp_data = OneLogin_Saml2_IdPMetadataParser.parse_remote(https://example.com/metadatas, entity_id='idp_entity_id')``


#### How load the library ####

In order to use the toolkit library you need to import the file that contains the class that you will need
on the top of your python file.

``` python
from onelogin.saml2.auth import OneLogin_Saml2_Auth
from onelogin.saml2.settings import OneLogin_Saml2_Settings
from onelogin.saml2.utils import OneLogin_Saml2_Utils
```

#### The Request ####

Building a ``OneLogin\_Saml2\_Auth`` object requires a ``request`` parameter:

```python
auth = OneLogin_Saml2_Auth(req)
```

This parameter has the following scheme:

```python
req = {
    "http_host": "",
    "script_name": "",
    "get_data": "",
    "post_data": "",

    # Advanced request options
    "https": "",
    "request_uri": "",
    "query_string": "",
    "validate_signature_from_qs": False,
    "lowercase_urlencoding": False
}
```

Each Python framework builds its own ``request`` object, you may map its data to match what the SAML toolkit expects.
Let`s see some examples:

```python
def prepare_from_django_request(request):
    return {
        'http_host': request.META['HTTP_HOST'],
        'script_name': request.META['PATH_INFO'],
        'get_data': request.GET.copy(),
        'post_data': request.POST.copy()
    }

def prepare_from_flask_request(request):
    url_data = urlparse(request.url)
    return {
        'http_host': request.netloc,
        'script_name': request.path,
        'get_data': request.args.copy(),
        'post_data': request.form.copy()
    }
```

An explanation of some advanced request parameters:

* `https` - Defaults to ``off``. Set this to ``on`` if you receive responses over HTTPS.

* `request_uri` - The path where your SAML server receives requests. Set this if requests are not received at the server's root.

* `query_string` - Set this with additional query parameters that should be passed to the request endpoint.

* `validate_signature_from_qs` - If `True`, use `query_string` to validate request and response signatures. Otherwise, use `get_data`. Defaults to `False`. Note that when using `get_data`, query parameters need to be url-encoded for validation. By default we use upper-case url-encoding. Some IdPs, notably Microsoft AD, use lower-case url-encoding, which makes signature validation to fail. To fix this issue, either pass `query_string` and set `validate_signature_from_qs` to `True`, which works for all IdPs, or set `lowercase_urlencoding` to `True`, which only works for AD.


#### Initiate SSO ####

In order to send an ``AuthNRequest`` to the IdP:

```python
from onelogin.saml2.auth import OneLogin_Saml2_Auth

req = prepare_request_for_toolkit(request)
auth = OneLogin_Saml2_Auth(req)   # Constructor of the SP, loads settings.json
                                  # and advanced_settings.json

auth.login()      # This method will build and return a AuthNRequest URL that can be
                  # either redirected to, or printed out onto the screen as a hyperlink
```

The ``AuthNRequest`` will be sent signed or unsigned based on the security info of the ``advanced_settings.json`` file (i.e. ``authnRequestsSigned``).

The IdP will then return the SAML Response to the user's client. The client is then forwarded to the **Assertion Consumer Service (ACS)** of the SP with this information.

We can set a ``return_to`` url parameter to the login function and that will be converted as a ``RelayState`` parameter:

```python
target_url = 'https://example.com'
auth.login(return_to=target_url)
```
The login method can receive 3 more optional parameters:

* ``force_authn``       When ``true``, the ``AuthNReuqest`` will set the ``ForceAuthn='true'``
* ``is_passive``        When true, the ``AuthNReuqest`` will set the ``Ispassive='true'``
* ``set_nameid_policy`` When true, the ``AuthNReuqest`` will set a ``nameIdPolicy`` element.

If a match on the future ``SAMLResponse`` ID and the ``AuthNRequest`` ID to be sent is required, that ``AuthNRequest`` ID must to be extracted and stored for future validation, we can get that ID by

``auth.get_last_request_id()``

#### The SP Endpoints ####

Related to the SP there are 3 important endpoints: The metadata view, the ACS view and the SLS view.
The toolkit provides examples of those views in the demos, but let's see an example.

***SP Metadata***

This code will provide the XML metadata file of our SP, based on the info that we provided in the settings files.

```python
req = prepare_request_for_toolkit(request)
auth = OneLogin_Saml2_Auth(req)
saml_settings = auth.get_settings()
metadata = saml_settings.get_sp_metadata()
errors = saml_settings.validate_metadata(metadata)
if len(errors) == 0:
    print(metadata)
else:
    print("Error found on Metadata: %s" % (', '.join(errors)))
```

The ``get_sp_metadata`` will return the metadata signed or not based on the security info of the ``advanced_settings.json`` (``signMetadata``).

Before the XML metadata is exposed, a check takes place to ensure that the info to be provided is valid.

Instead of using the Auth object, you can directly use
```
saml_settings = OneLogin_Saml2_Settings(settings=None, custom_base_path=None, sp_validation_only=True)
```
to get the settings object and with the ``sp_validation_only=True`` parameter we will avoid the IdP settings validation.

***Assertion Consumer Service (ACS)***

This code handles the SAML response that the IdP forwards to the SP through the user's client.

```python
req = prepare_request_for_toolkit(request)
auth = OneLogin_Saml2_Auth(req)
auth.process_response()
errors = auth.get_errors()
if not errors:
    if auth.is_authenticated():
        request.session['samlUserdata'] = auth.get_attributes()
        if 'RelayState' in req['post_data'] and
          OneLogin_Saml2_Utils.get_self_url(req) != req['post_data']['RelayState']:
            # To avoid 'Open Redirect' attacks, before execute the redirection confirm
                # the value of the req['post_data']['RelayState'] is a trusted URL.
            auth.redirect_to(req['post_data']['RelayState'])
        else:
            for attr_name in request.session['samlUserdata'].keys():
                print('%s ==> %s' % (attr_name, '|| '.join(request.session['samlUserdata'][attr_name])))
    else:
      print('Not authenticated')
else:
    print("Error when processing SAML Response: %s %s" % (', '.join(errors), auth.get_last_error_reason()))
```

The SAML response is processed and then checked that there are no errors. It also verifies that the user is authenticated and stored the userdata in session.

At that point there are 2 possible alternatives:

* If no ``RelayState`` is provided, we could show the user data in this view or however we wanted.
* If ``RelayState`` is provided, a redirection takes place.

Notice that we saved the user data in the session before the redirection to have the user data available at the ``RelayState`` view.

In order to retrieve attributes we use:

```python
attributes = auth.get_attributes()
```

With this method we get a dict with all the user data provided by the IdP in the assertion of the SAML response.

If we execute print attributes we could get:

```python
{
    "cn": ["Jhon"],
    "sn": ["Doe"],
    "mail": ["Doe"],
    "groups": ["users", "members"]
}
```

Each attribute name can be used as a key to obtain the value. Every attribute is a list of values. A single-valued attribute is a list of a single element.

The following code is equivalent:

```python
attributes = auth.get_attributes()
print(attributes['cn'])

print(auth.get_attribute('cn'))
```

Before trying to get an attribute, check that the user is authenticated. If the user isn't authenticated, an empty dict will be returned. For example, if we call to ``get_attributes`` before a ``auth.process_response``, the ``get_attributes()`` will return an empty dict.


***Single Logout Service (SLS)***

This code handles the Logout Request and the Logout Responses.

```python
delete_session_callback = lambda: request.session.flush()
url = auth.process_slo(delete_session_cb=delete_session_callback)
errors = auth.get_errors()
if len(errors) == 0:
    if url is not None:
        # To avoid 'Open Redirect' attacks, before execute the redirection confirm
        # the value of the url is a trusted URL.
        return redirect(url)
    else:
        print("Successfully Logged out")
else:
    print("Error when processing SLO: %s %s" % (', '.join(errors), auth.get_last_error_reason()))
```

If the SLS endpoints receives a Logout Response, the response is validated and the session could be closed, using the callback.

```python
# Part of the process_slo method
logout_response = OneLogin_Saml2_Logout_Response(self.__settings, self.__request_data['get_data']['SAMLResponse'])
if not logout_response.is_valid(self.__request_data, request_id):
    self.__errors.append('invalid_logout_response')
elif logout_response.get_status() != OneLogin_Saml2_Constants.STATUS_SUCCESS:
    self.__errors.append('logout_not_success')
elif not keep_local_session:
    OneLogin_Saml2_Utils.delete_local_session(delete_session_cb)
```

If the SLS endpoints receives an Logout Request, the request is validated, the session is closed and a Logout Response is sent to the SLS endpoint of the IdP.

```python
# Part of the process_slo method
request = OneLogin_Saml2_Utils.decode_base64_and_inflate(self.__request_data['get_data']['SAMLRequest'])
if not OneLogin_Saml2_Logout_Request.is_valid(self.__settings, request, self.__request_data):
    self.__errors.append('invalid_logout_request')
else:
    if not keep_local_session:
        OneLogin_Saml2_Utils.delete_local_session(delete_session_cb)

    in_response_to = request.id
    response_builder = OneLogin_Saml2_Logout_Response(self.__settings)
    response_builder.build(in_response_to)
    logout_response = response_builder.get_response()

    parameters = {'SAMLResponse': logout_response}
    if 'RelayState' in self.__request_data['get_data']:
        parameters['RelayState'] = self.__request_data['get_data']['RelayState']

    security = self.__settings.get_security_data()
    if 'logoutResponseSigned' in security and security['logoutResponseSigned']:
        parameters['SigAlg'] = OneLogin_Saml2_Constants.RSA_SHA1
        parameters['Signature'] = self.build_response_signature(logout_response, parameters.get('RelayState', None))

    return self.redirect_to(self.get_slo_url(), parameters)
```

If we don't want that ``process_slo`` to destroy the session, pass a ``true`` parameter to the ``process_slo`` method:

```python
keepLocalSession = true
auth.process_slo(keep_local_session=keepLocalSession);
```

#### Initiate SLO ####

In order to send a Logout Request to the IdP:

The Logout Request will be sent signed or unsigned based on the security info of the ``advanced_settings.json`` (``logoutRequestSigned``).

The IdP will return the Logout Response through the user's client to the Single Logout Service (SLS) of the SP.

We can set a ``return_to`` url parameter to the logout function and that will be converted as a ``RelayState`` parameter:

```python
target_url = 'https://example.com'
auth.logout(return_to=target_url)
```

Also there are another 5 optional parameters that can be set:

* ``name_id``: That will be used to build the ``LogoutRequest``. If no ``name_id`` parameter is set and the auth object processed a
SAML Response with a ``NameId``, then this ``NameId`` will be used.
* ``session_index``: ``SessionIndex`` that identifies the session of the user.
* ``nq``: IDP Name Qualifier.
* ``name_id_format``: The ``NameID`` Format that will be set in the ``LogoutRequest``.
* ``spnq``: The ``NameID SP NameQualifier`` will be set in the ``LogoutRequest``.

If no ``name_id`` is provided, the ``LogoutRequest`` will contain a ``NameID`` with the entity Format.
If ``name_id`` is provided and no ``name_id_format`` is provided, the ``NameIDFormat`` of the settings will be used.

If a match on the ``LogoutResponse`` ID and the ``LogoutRequest`` ID to be sent is required, that ``LogoutRequest`` ID must to be extracted and stored for future validation, we can get that ID by:

```python
auth.get_last_request_id()
```

#### Example of a view that initiates the SSO request and handles the response (is the acs target) ####

We can code a unique file that initiates the SSO process, handle the response, get the attributes, initiate the SLO and processes the logout response.

Note: Review the demos, in a later section we explain the demo use case further in detail.

```python
req = prepare_request_for_toolkit(request)  # Process the request and build the request dict that
                                            # the toolkit expects

auth = OneLogin_Saml2_Auth(req)             # Initialize the SP SAML instance

if 'sso' in request.args:                   # SSO action (SP-SSO initited).  Will send an AuthNRequest to the IdP
    return redirect(auth.login())
elif 'sso2' in request.args:                       # Another SSO init action
    return_to = '%sattrs/' % request.host_url      # but set a custom RelayState URL
    return redirect(auth.login(return_to))
elif 'slo' in request.args:                     # SLO action. Will sent a Logout Request to IdP
    nameid = request.session['samlNameId']
    nameid_format = request.session['samlNameIdFormat']
    nameid_nq = request.session['samlNameIdNameQualifier']
    nameid_spnq = request.session['samlNameIdSPNameQualifier']
    session_index = request.session['samlSessionIndex']
    return redirect(auth.logout(None, nameid, session_index, nameid_nq, nameid_format, nameid_spnq))
elif 'acs' in request.args:                 # Assertion Consumer Service
    auth.process_response()                     # Process the Response of the IdP
    errors = auth.get_errors()              # This method receives an array with the errors
    if len(errors) == 0:                    # that could took place during the process
        if not auth.is_authenticated():         # This check if the response was ok and the user
            msg = "Not authenticated"           # data retrieved or not (user authenticated)
        else:
            request.session['samlUserdata'] = auth.get_attributes()     # Retrieves user data
            request.session['samlNameId'] = auth.get_nameid()
            request.session['samlNameIdFormat'] = auth.get_nameid_format()
            request.session['samlNameIdNameQualifier'] = auth.get_nameid_nq()
            request.session['samlNameIdSPNameQualifier'] = auth.get_nameid_spnq()
            request.session['samlSessionIndex'] = auth.get_session_index()
            self_url = OneLogin_Saml2_Utils.get_self_url(req)
            if 'RelayState' in request.form and self_url != request.form['RelayState']:
                # To avoid 'Open Redirect' attacks, before execute the redirection confirm
                # the value of the request.form['RelayState'] is a trusted URL.
                return redirect(auth.redirect_to(request.form['RelayState']))   # Redirect if there is a relayState
            else:                           # If there is user data we save that to print it later.
                msg = ''
                for attr_name in request.session['samlUserdata'].keys():
                    msg += '%s ==> %s' % (attr_name, '|| '.join(request.session['samlUserdata'][attr_name]))
elif 'sls' in request.args:                                             # Single Logout Service
    delete_session_callback = lambda: session.clear()           # Obtain session clear callback
    url = auth.process_slo(delete_session_cb=delete_session_callback)   # Process the Logout Request & Logout Response
    errors = auth.get_errors()              #  Retrieves possible validation errors
    if len(errors) == 0:
        if url is not None:
            # To avoid 'Open Redirect' attacks, before execute the redirection confirm
            # the value of the url is a trusted URL.
            return redirect(url)
        else:
            msg = "Successfully logged out"

if len(errors) == 0:
  print(msg)
else:
  print(', '.join(errors))
```


### SP Key rollover ###

If you plan to update the SP ``x509cert`` and ``privateKey`` you can define the new ``x509cert`` as ``settings['sp']['x509certNew']`` and it will be
published on the SP metadata so Identity Providers can read them and get ready for rollover.


### IdP with multiple certificates ###

In some scenarios the IdP uses different certificates for
signing/encryption, or is under key rollover phase and more than one certificate is published on IdP metadata.

In order to handle that the toolkit offers the ``settings['idp']['x509certMulti']`` parameter.

When that parameter is used, ``x509cert`` and ``certFingerprint`` values will be ignored by the toolkit.

The ``x509certMulti`` is an array with 2 keys:
- ``signing``: An array of certs that will be used to validate IdP signature
- ``encryption``: An array with one unique cert that will be used to encrypt data to be sent to the IdP.


### Replay attacks ###

In order to avoid replay attacks, you can store the ID of the SAML messages already processed, to avoid processing them twice. Since the Messages expires and will be invalidated due that fact, you don't need to store those IDs longer than the time frame that you currently accepting.

Get the ID of the last processed message/assertion with the ``get_last_message_id/get_last_assertion_id`` method of the ``Auth`` object.


### Main classes and methods ###

Described below are the main classes and methods that can be invoked from the SAML2 library.

#### OneLogin_Saml2_Auth - auth.py ####

Main class of SAML Python Toolkit

* `__init__` Initializes the SP SAML instance.
* ***login*** Initiates the SSO process.
* ***logout*** Initiates the SLO process.
* ***process_response*** Process the SAML Response sent by the IdP.
* ***process_slo*** Process the SAML Logout Response / Logout Request sent by the IdP.
* ***redirect_to*** Redirects the user to the url past by parameter or to the url that we defined in our SSO Request.
* ***is_authenticated*** Checks if the user is authenticated or not.
* ***get_attributes*** Returns the set of SAML attributes.
* ***get_attribute*** Returns the requested SAML attribute.
* ***get_nameid*** Returns the ``nameID``.
* ***get_session_index*** Gets the ``SessionIndex`` from the ``AuthnStatement``.
* ***get_session_expiration*** Gets the ``SessionNotOnOrAfter`` from the ``AuthnStatement``.
* ***get_errors*** Returns a list with code errors if something went wrong.
* ***get_last_error_reason*** Returns the reason of the last error
* ***get_sso_url*** Gets the SSO url.
* ***get_slo_url*** Gets the SLO url.
* ***get_last_request_id*** The ID of the last Request SAML message generated (``AuthNRequest``, ``LogoutRequest``).
* ***get_last_authn_contexts*** Returns the list of authentication contexts sent in the last SAML Response.
* ***build_request_signature*** Builds the Signature of the SAML Request.
* ***build_response_signature*** Builds the Signature of the SAML Response.
* ***get_settings*** Returns the settings info.
* ***set_strict*** Set the strict mode active/disable.
* ***get_last_request_xml*** Returns the most recently-constructed/processed XML SAML request (``AuthNRequest``, ``LogoutRequest``)
* ***get_last_response_xml*** Returns the most recently-constructed/processed XML SAML response (``SAMLResponse``, ``LogoutResponse``). If the SAMLResponse had an encrypted assertion, decrypts it.
* ***get_last_response_in_response_to*** The `InResponseTo` ID of the most recently processed SAML Response.
* ***get_last_message_id*** The ID of the last Response SAML message processed.
* ***get_last_assertion_id*** The ID of the last assertion processed.
* ***get_last_assertion_not_on_or_after*** The ``NotOnOrAfter`` value of the valid ``SubjectConfirmationData`` node (if any) of the last assertion processed (is only calculated with strict = true)
* ***get_last_assertion_issue_instant*** The `IssueInstant` value of the last assertion processed.

#### OneLogin_Saml2_Auth - authn_request.py ####

SAML 2 Authentication Request class

* `__init__` This class handles an ``AuthNRequest``. It builds an ``AuthNRequest`` object.
* ***get_request*** Returns unsigned ``AuthnRequest``.
* ***get_id*** Returns the ``AuthNRequest`` ID.
* ***get_xml*** Returns the XML that will be sent as part of the request.

#### OneLogin_Saml2_Response - response.py ####

SAML 2 Authentication Response class

* `__init__` Constructs the SAML Response object.
* ***is_valid*** Determines if the SAML Response is valid. Includes checking of the signature by a certificate.
* ***check_status*** Check if the status of the response is success or not
* ***get_audiences*** Gets the audiences
* ***get_issuers*** Gets the issuers (from message and from assertion)
* ***get_nameid_data*** Gets the NameID Data provided by the SAML Response from the IdP (returns a dict)
* ***get_nameid*** Gets the NameID provided by the SAML Response from the IdP (returns a string)
* ***get_session_not_on_or_after*** Gets the ``SessionNotOnOrAfter`` from the ``AuthnStatement``
* ***get_session_index*** Gets the ``SessionIndex`` from the ``AuthnStatement``
* ***get_attributes*** Gets the Attributes from the ``AttributeStatement`` element.
* ***validate_num_assertions*** Verifies that the document only contains a single Assertion (encrypted or not)
* ***validate_timestamps*** Verifies that the document is valid according to Conditions Element
* ***get_error*** After execute a validation process, if fails this method returns the cause
* ***get_xml_document*** Returns the SAML Response document (If contains an encrypted assertion, decrypts it).
* ***get_id*** the ID of the response
* ***get_assertion_id*** the ID of the assertion in the response
* ***get_assertion_not_on_or_after*** the ``NotOnOrAfter`` value of the valid ``SubjectConfirmationData`` if any

#### OneLogin_Saml2_LogoutRequest - logout_request.py ####

SAML 2 Logout Request class

* `__init__` Constructs the Logout Request object.
* ***get_request*** Returns the Logout Request deflated, base64-encoded.
* ***get_id*** Returns the ID of the Logout Request. (If you have the object you can access to the id attribute)
* ***get_nameid_data*** Gets the NameID Data of the the Logout Request (returns a dict).
* ***get_nameid*** Gets the NameID of the Logout Request Message (returns a string).
* ***get_issuer*** Gets the Issuer of the Logout Request Message.
* ***get_session_indexes*** Gets the ``SessionIndexes`` from the Logout Request.
* ***is_valid*** Checks if the Logout Request received is valid.
* ***get_error*** After execute a validation process, if fails this method returns the cause.
* ***get_xml*** Returns the XML that will be sent as part of the request or that was received at the SP

#### OneLogin_Saml2_LogoutResponse - logout_response.py ####

SAML 2 Logout Response class

* `__init__` Constructs a Logout Response object.
* ***get_issuer*** Gets the Issuer of the Logout Response Message
* ***get_status*** Gets the Status of the Logout Response.
* ***is_valid*** Determines if the SAML ``LogoutResponse`` is valid
* ***build*** Creates a Logout Response object.
* ***get_response*** Returns a Logout Response object.
* ***get_error*** After execute a validation process, if fails this method returns the cause.
* ***get_xml*** Returns the XML that will be sent as part of the response or that was received at the SP

#### OneLogin_Saml2_Settings - settings.py ####

Configuration of the SAML Python Toolkit

* `__init__`  Initializes the settings: Sets the paths of the different folders and Loads settings info from settings file or array/object provided.
* ***check_settings*** Checks the settings info.
* ***check_idp_settings*** Checks the IdP settings info.
* ***check_sp_settings*** Checks the SP settings info.
* ***get_errors*** Returns an array with the errors, the array is empty when the settings is ok.
* ***get_sp_metadata*** Gets the SP metadata. The XML representation.
* ***validate_metadata*** Validates an XML SP Metadata.
* ***get_base_path*** Returns base path.
* ***get_cert_path*** Returns cert path.
* ***get_lib_path*** Returns lib path.
* ***get_ext_lib_path*** Returns external lib path.
* ***get_schemas_path*** Returns schema path.
* ***check_sp_certs*** Checks if the X.509 certs of the SP exists and are valid.
* ***get_sp_key*** Returns the X.509 private key of the SP.
* ***get_sp_cert*** Returns the X.509 public cert of the SP.
* ***get_sp_cert_new*** Returns the future X.509 public cert of the SP.
* ***get_idp_cert*** Returns the X.509 public cert of the IdP.
* ***get_sp_data*** Gets the SP data.
* ***get_idp_data*** Gets the IdP data.
* ***get_security_data***  Gets security data.
* ***get_contacts*** Gets contacts data.
* ***get_organization*** Gets organization data.
* ***format_idp_cert*** Formats the IdP cert.
* ***format_idp_cert_multi*** Formats all registered IdP certs.
* ***format_sp_cert*** Formats the SP cert.
* ***format_sp_cert_new*** Formats the SP cert new.
* ***format_sp_key*** Formats the private key.
* ***set_strict*** Activates or deactivates the strict mode.
* ***is_strict*** Returns if the ``strict`` mode is active.
* ***is_debug_active*** Returns if the debug is active.

#### OneLogin_Saml2_Metadata - metadata.py ####

A class that contains functionality related to the metadata of the SP

* ***builder*** Generates the metadata of the SP based on the settings.
* ***sign_metadata*** Signs the metadata with the key/cert provided.
* ***add_x509_key_descriptors*** Adds the X.509 descriptors (sign/encryption) to the metadata

#### OneLogin_Saml2_Utils - utils.py ####

Auxiliary class that contains several methods

* ***decode_base64_and_inflate*** Base64 decodes and then inflates according to RFC1951.
* ***deflate_and_base64_encode*** Deflates and the base64 encodes a string.
* ***format_cert*** Returns a X.509 cert (adding header & footer if required).
* ***format_private_key*** Returns a private key (adding header & footer if required).
* ***redirect*** Executes a redirection to the provided url (or return the target url).
* ***get_self_url_host*** Returns the protocol + the current host + the port (if different than common ports).
* ***get_self_host*** Returns the current host.
* ***is_https*** Checks if https or http.
* ***get_self_url_no_query*** Returns the URL of the current host + current view.
* ***get_self_routed_url_no_query*** Returns the routed URL of the current host + current view.
* ***get_self_url*** Returns the URL of the current host + current view + query.
* ***generate_unique_id*** Generates an unique string (used for example as ID for assertions).
* ***parse_time_to_SAML*** Converts a UNIX timestamp to SAML2 timestamp on the form yyyy-mm-ddThh:mm:ss(\.s+)?Z.
* ***parse_SAML_to_time*** Converts a SAML2 timestamp on the form yyyy-mm-ddThh:mm:ss(\.s+)?Z to a UNIX timestamp.
* ***now*** Returns unix timestamp of actual time.
* ***parse_duration*** Interprets a ISO8601 duration value relative to a given timestamp.
* ***get_expire_time*** Compares 2 dates and returns the earliest.
* ***delete_local_session*** Deletes the local session.
* ***calculate_X.509_fingerprint*** Calculates the fingerprint of a X.509 cert.
* ***format_finger_print*** Formats a fingerprint.
* ***generate_name_id*** Generates a nameID.
* ***get_status*** Gets Status from a Response.
* ***decrypt_element*** Decrypts an encrypted element.
* ***write_temp_file*** Writes some content into a temporary file and returns it.
* ***add_sign*** Adds signature key and senders certificate to an element (Message or Assertion).
* ***validate_sign*** Validates a signature (Message or Assertion).
* ***validate_binary_sign*** Validates signed bynary data (Used to validate GET Signature).

#### OneLogin_Saml2_XML- xml_utils.py ####

A class that contains methods to handle XMLs

* ***to_string*** Serialize an element to an encoded string representation of its XML tree.
* ***to_etree*** Parses an XML document or fragment from a string.
* ***validate_xml*** Validates a xml against a schema
* ***query*** Extracts nodes that match the query from the Element
* ***extract_tag_text***

#### OneLogin_Saml2_IdPMetadataParser - idp_metadata_parser.py ####

A class that contains methods to obtain and parse metadata from IdP

* ***get_metadata*** Get the metadata XML from the provided URL
* ***parse_remote*** Get the metadata XML from the provided URL and parse it, returning a dict with extracted data
* ***parse*** Parse the Identity Provider metadata and returns a dict with extracted data
* ***merge_settings*** Will update the settings with the provided new settings data extracted from the IdP metadata


For more info, look at the source code. Each method is documented and details about what does and how to use it are provided. Make sure to also check the doc folder where HTML documentation about the classes and methods is provided.

Demos included in the toolkit
-----------------------------

The toolkit includes 3 demos to teach how use the toolkit (A Django, Flask and a Tornado project), take a look on it.
Demos require that SP and IdP are well configured before test it, so edit the settings files.

Notice that each python framework has it own way to handle routes/urls and process request, so focus on
how it deployed. New demos using other python frameworks are welcome as a contribution.

### Getting Started ###

We said that this toolkit includes a Django application demo and a Flask application demo,
let's see how fast is it to deploy them.

***Virtualenv***

The use of a [virtualenv](http://virtualenv.readthedocs.org/en/latest/) is
highly recommended.

Virtualenv helps isolating the python environment used to run the toolkit. You
can find more details and an installation guide in the
[official documentation](http://virtualenv.readthedocs.org/en/latest/).

Once you have your virtualenv ready and loaded, then you can install the
toolkit executing this:
```
 make install-req
```

### Demo Flask ###

You'll need a virtualenv with the toolkit installed on it.

To run the demo you need to install the requirements first. Load your
virtualenv and execute:

```
 pip install -r demo-flask/requirements.txt
```

This will install flask and its dependencies. Once it has finished, you have to complete the configuration
of the toolkit. You'll find it at `demo-flask/settings.json`

Now, with the virtualenv loaded, you can run the demo like this:
```
 cd demo-flask
 python index.py
```

You'll have the demo running at http://localhost:8000

#### Content ####

The flask project contains:


* ***index.py*** Is the main flask file, where or the SAML handle take place.

* ***templates***. Is the folder where flask stores the templates of the project. It was implemented a base.html template that is extended by index.html and attrs.html, the templates of our simple demo that shows messages, user attributes when available and login and logout links.

* ***saml*** Is a folder that contains the 'certs' folder that could be used to store the X.509 public and private key, and the saml toolkit settings (settings.json and advanced_settings.json).


#### SP setup ####

The SAML Python Toolkit allows you to provide the settings info in 2 ways: Settings files or define a setting dict. In the ``demo-flask``, it uses the first method.

In the ``index.py`` file we define the ``app.config['SAML_PATH']``, that will target to the ``saml`` folder. We require it in order to load the settings files.

First we need to edit the ``saml/settings.json`` file, configure the SP part and review the metadata of the IdP and complete the IdP info.  Later edit the ``saml/advanced_settings.json`` files and configure the how the toolkit will work. Check the settings section of this document if you have any doubt.

#### IdP setup ####

Once the SP is configured, the metadata of the SP is published at the ``/metadata`` url. Based on that info, configure the IdP.

#### How it works ####

 1. First time you access to the main view (http://localhost:8000), you can select to login and return to the same view or login and be redirected to ``/?attrs`` (attrs view).

 2. When you click:

    2.1 in the first link, we access to ``/?sso`` (index view). An ``AuthNRequest`` is sent to the IdP, we authenticate at the IdP and then a Response is sent through the user's client to the SP, specifically the Assertion Consumer Service view: ``/?acs``. Notice that a ``RelayState`` parameter is set to the url that initiated the process, the index view.

    2.2 in the second link we access to ``/?attrs`` (attrs view), we will expetience have the same process described at 2.1 with the diference that as ``RelayState`` is set the ``attrs`` url.

 3. The SAML Response is processed in the ACS ``/?acs``, if the Response is not valid, the process stops here and a message is shown. Otherwise we are redirected to the ``RelayState`` view. a) / or b) ``/?attrs``

 4. We are logged in the app and the user attributes are showed. At this point, we can test the single log out functionality.

 The single log out functionality could be tested by 2 ways.

    5.1 SLO Initiated by SP. Click on the ``logout`` link at the SP, after that a Logout Request is sent to the IdP, the session at the IdP is closed and replies through the client to the SP with a Logout Response (sent to the Single Logout Service endpoint). The SLS endpoint ``/?sls`` of the SP process the Logout Response and if is valid, close the user session of the local app. Notice that the SLO Workflow starts and ends at the SP.

    5.2 SLO Initiated by IdP. In this case, the action takes place on the IdP side, the logout process is initiated at the IdP, sends a Logout Request to the SP (SLS endpoint, ``/?sls``). The SLS endpoint of the SP process the Logout Request and if is valid, close the session of the user at the local app and send a Logout Response to the IdP (to the SLS endpoint of the IdP). The IdP receives the Logout Response, process it and close the session at of the IdP. Notice that the SLO Workflow starts and ends at the IdP.

Notice that all the SAML Requests and Responses are handled at a unique view (index) and how GET parameters are used to know the action that must be done.

### Demo Tornado ###

You'll need a virtualenv with the toolkit installed on it.

First of all you need some packages, execute:
```
apt-get install libxml2-dev libxmlsec1-dev libxmlsec1-openssl
```

To run the demo you need to install the requirements first. Load your
virtualenv and execute:
```
 pip install -r demo-tornado/requirements.txt
```


This will install tornado and its dependencies. Once it has finished, you have to complete the configuration
of the toolkit. You'll find it at `demo-tornado/saml/settings.json`

Now, with the virtualenv loaded, you can run the demo like this:
```
 cd demo-tornado
 python views.py
```

You'll have the demo running at http://localhost:8000

#### Content ####

The tornado project contains:

* ***views.py*** Is the main flask file, where or the SAML handle take place.

* ***settings.py*** Contains the base path and the path where is located the ``saml`` folder and the ``template`` folder

* ***templates***. Is the folder where tornado stores the templates of the project. It was implemented a base.html template that is extended by index.html and attrs.html, the templates of our simple demo that shows messages, user attributes when available and login and logout links.

* ***saml*** Is a folder that contains the 'certs' folder that could be used to store the X.509 public and private key, and the saml toolkit settings (settings.json and advanced_settings.json).

#### SP setup ####

The SAML Python Toolkit allows you to provide the settings info in 2 ways: Settings files or define a setting dict. In the ``demo-tornado``, it uses the first method.

In the ``settings.py`` file we define the ``SAML_PATH``, that will target to the ``saml`` folder. We require it in order to load the settings files.

First we need to edit the ``saml/settings.json`` file, configure the SP part and review the metadata of the IdP and complete the IdP info.  Later edit the ``saml/advanced_settings.json`` files and configure the how the toolkit will work. Check the settings section of this document if you have any doubt.

#### IdP setup ####

Once the SP is configured, the metadata of the SP is published at the ``/metadata`` url. Based on that info, configure the IdP.

#### How it works ####

1. First time you access to the main view (http://localhost:8000), you can select to login and return to the same view or login and be redirected to ``/?attrs`` (attrs view).

 2. When you click:

    2.1 in the first link, we access to ``/?sso`` (index view). An ``AuthNRequest`` is sent to the IdP, we authenticate at the IdP and then a Response is sent through the user's client to the SP, specifically the Assertion Consumer Service view: ``/?acs``. Notice that a ``RelayState`` parameter is set to the url that initiated the process, the index view.

    2.2 in the second link we access to ``/?attrs`` (attrs view), we will expetience have the same process described at 2.1 with the diference that as ``RelayState`` is set the ``attrs`` url.

 3. The SAML Response is processed in the ACS ``/?acs``, if the Response is not valid, the process stops here and a message is shown. Otherwise we are redirected to the ``RelayState`` view. a) / or b) ``/?attrs``

 4. We are logged in the app and the user attributes are showed. At this point, we can test the single log out functionality.

 The single log out functionality could be tested by 2 ways.

    5.1 SLO Initiated by SP. Click on the ``logout`` link at the SP, after that a Logout Request is sent to the IdP, the session at the IdP is closed and replies through the client to the SP with a Logout Response (sent to the Single Logout Service endpoint). The SLS endpoint ``/?sls`` of the SP process the Logout Response and if is valid, close the user session of the local app. Notice that the SLO Workflow starts and ends at the SP.

    5.2 SLO Initiated by IdP. In this case, the action takes place on the IdP side, the logout process is initiated at the IdP, sends a Logout Request to the SP (SLS endpoint, ``/?sls``). The SLS endpoint of the SP process the Logout Request and if is valid, close the session of the user at the local app and send a Logout Response to the IdP (to the SLS endpoint of the IdP). The IdP receives the Logout Response, process it and close the session at of the IdP. Notice that the SLO Workflow starts and ends at the IdP.

Notice that all the SAML Requests and Responses are handled at a unique view (index) and how GET parameters are used to know the action that must be done.

### Demo Django ###

You'll need a virtualenv with the toolkit installed on it.

To run the demo you need to install the requirements first. Load your
virtualenv and execute:
```
 pip install -r demo-django/requirements.txt
```
This will install django and its dependencies. Once it has finished, you have to complete the configuration of the toolkit.

Later, with the virtualenv loaded, you can run the demo like this:
```
 cd demo-django
 python manage.py runserver 0.0.0.0:8000
```

You'll have the demo running at http://localhost:8000.

Note that many of the configuration files expect HTTPS. This is not required by the demo, as replacing these SP URLs with HTTP will work just fine. HTTPS is however highly encouraged, and left as an exercise for the reader for their specific needs.

If you want to integrate a production django application, take a look on this SAMLServiceProviderBackend that uses our toolkit to add SAML support: https://github.com/KristianOellegaard/django-saml-service-provider

#### Content ####

The django project contains:

* ***manage.py***. A file that is automatically created in each Django project. Is a thin wrapper around django-admin.py that takes care of putting the project’s package on ``sys.path`` and sets the ``DJANGO_SETTINGS_MODULE`` environment variable.

* ***saml*** Is a folder that contains the 'certs' folder that could be used to store the X.509 public and private key, and the saml toolkit settings (``settings.json`` and ``advanced_settings.json``).

* ***demo*** Is the main folder of the django project, that contains the typical files:
  * ***settings.py*** Contains the default parameters of a django project except the ``SAML_FOLDER`` parameter, that may contain the path where is located the ``saml`` folder.
  * ***urls.py*** A file that define url routes. In the demo we defined ``'/'`` that is related to the index view, ``'/attrs'`` that is related with the attrs view and ``'/metadata'``, related to the metadata view.
  * ***views.py*** This file contains the views of the django project and some aux methods.
  * ***wsgi.py*** A file that let as deploy django using WSGI, the Python standard for web servers and applications.

* ***templates***. Is the folder where django stores the templates of the project. It was implemented a ``base.html`` template that is extended by ``index.html`` and ``attrs.html``, the templates of our simple demo that shows messages, user attributes when available and login and logout links.

#### SP setup ####

The SAML Python Toolkit allows you to provide the settings info in 2 ways: settings files or define a setting dict. In the demo-django it used the first method.

After set the ``SAML_FOLDER`` in the ``demo/settings.py``, the settings of the Python toolkit will be loaded on the Django web.

First we need to edit the ``saml/settings.json``, configure the SP part and review the metadata of the IdP and complete the IdP info.  Later edit the ``saml/advanced_settings.json`` files and configure the how the toolkit will work. Check the settings section of this document if you have any doubt.

#### IdP setup ####

Once the SP is configured, the metadata of the SP is published at the ``/metadata`` url. Based on that info, configure the IdP.

#### How it works ####

This demo works very similar to the ``flask-demo`` (We did it intentionally).

### Getting up and running on Heroku ###

Getting ``python3-saml`` up and running on Heroku will require some extra legwork: ``python3-saml`` depends on ``python-xmlsec`` which depends on headers from the ``xmlsec1-dev`` Linux package to install correctly.

First you will need to add the ```apt``` buildpack to your build server:

```
heroku buildpacks:add --index=1 -a your-app heroku-community/apt
heroku buildpacks:add --index=2 -a your-app heroku/python
```

You can confirm the buildpacks have been added in the correct order with ```heroku buildpacks -a your-app```, you should see the apt buildpack first followed by the Python buildpack.

Then add an ```Aptfile``` into the root of your repository containing the ```libxmlsec1-dev``` package, the file should look like:
```
libxmlsec1-dev

```

Finally, add ``python3-saml`` to your ``requirements.txt`` and ```git push``` to trigger a build.

### Demo Pyramid ###

Unlike the other two projects, you don't need a pre-existing virtualenv to get
up and running here, since Pyramid comes from the
[buildout](http://www.buildout.org/en/latest/) school of thought.

To run the demo you need to install Pyramid, the requirements, etc.:
```
 cd demo_pyramid
 python3 -m venv env
 env/bin/pip install --upgrade pip setuptools
 env/bin/pip install -e ".[testing]"
```

If you want to make sure the tests pass, run:
```
 env/bin/pytest
```

Next, edit the settings in `demo_pyramid/saml/settings.json`. (Pyramid runs on
port 6543 by default.)

Now you can run the demo like this:
```
 env/bin/pserve development.ini
```

If that worked, the demo is now running at http://localhost:6543.

#### Content ####

The Pyramid project contains:


* ***\_\_init__.py*** is the main Pyramid file that configures the app and its routes.

* ***views.py*** is where all the SAML handling takes place.

* ***templates*** is the folder where Pyramid stores the templates of the project. It was implemented a ``layout.jinja2`` template that is extended by ``index.jinja2`` and ``attrs.jinja2``, the templates of our simple demo that shows messages, user attributes when available and login and logout links.

* ***saml*** is a folder that contains the 'certs' folder that could be used to store the X.509 public and private key, and the saml toolkit settings (``settings.json`` and ``advanced_settings.json``).


#### SP setup ####

The SAML Python Toolkit allows you to provide the settings info in 2 ways: settings files or define a setting dict. In ``demo_pyramid`` the first method is used.

In the ``views.py`` file we define the ``SAML_PATH``, which will target the ``saml`` folder. We require it in order to load the settings files.

First we need to edit the ``saml/settings.json``, configure the SP part and review the metadata of the IdP and complete the IdP info.  Later edit the ``saml/advanced_settings.json`` files and configure the how the toolkit will work. Check the settings section of this document if you have any doubt.

#### IdP setup ####

Once the SP is configured, the metadata of the SP is published at the ``/metadata`` url. Based on that info, configure the IdP.

#### How it works ####

1. First time you access to the main view (http://localhost:6543), you can select to login and return to the same view or login and be redirected to ``/?attrs`` (attrs view).

 2. When you click:

    2.1 in the first link, we access to ``/?sso`` (index view). An ``AuthNRequest`` is sent to the IdP, we authenticate at the IdP and then a Response is sent through the user's client to the SP, specifically the Assertion Consumer Service view: ``/?acs``. Notice that a ``RelayState`` parameter is set to the url that initiated the process, the index view.

    2.2 in the second link we access to ``/?attrs`` (attrs view), we will experience the same process described at 2.1 with the diference that as ``RelayState`` is set the ``attrs`` url.

 3. The SAML Response is processed in the ACS ``/?acs``, if the Response is not valid, the process stops here and a message is shown. Otherwise we are redirected to the ``RelayState`` view. a) ``/`` or b) ``/?attrs``

 4. We are logged in the app and the user attributes are showed. At this point, we can test the single log out functionality.

 The single log out functionality could be tested by 2 ways.

    5.1 SLO Initiated by SP. Click on the "logout" link at the SP, after that a Logout Request is sent to the IdP, the session at the IdP is closed and replies through the client to the SP with a Logout Response (sent to the Single Logout Service endpoint). The SLS endpoint /?sls of the SP process the Logout Response and if is valid, close the user session of the local app. Notice that the SLO Workflow starts and ends at the SP.

    5.2 SLO Initiated by IdP. In this case, the action takes place on the IdP side, the logout process is initiated at the IdP, sends a Logout Request to the SP (SLS endpoint, /?sls). The SLS endpoint of the SP process the Logout Request and if is valid, close the session of the user at the local app and send a Logout Response to the IdP (to the SLS endpoint of the IdP). The IdP receives the Logout Response, process it and close the session at of the IdP. Notice that the SLO Workflow starts and ends at the IdP.

Notice that all the SAML Requests and Responses are handled at a unique view (index) and how GET parameters are used to know the action that must be done.



File: 231_liguoyu1_python.txt
ID: 231
Full Name: liguoyu1/python
Description: None
Created At: 2016-03-18T08:39:10Z
Updated At: 2024-03-15T02:08:36Z
Pushed At: 2018-09-09T13:38:28Z
Language: Python
URL: https://github.com/liguoyu1/python
Forks: 53
Stars: 49
Topics: 
README:



File: 257_navinreddy20_Python-.txt
ID: 257
Full Name: navinreddy20/Python-
Description: None
Created At: 2019-10-04T07:06:13Z
Updated At: 2024-10-24T05:56:42Z
Pushed At: 2022-09-09T08:39:38Z
Language: None
URL: https://github.com/navinreddy20/Python-
Forks: 466
Stars: 461
Topics: 
README:



File: 263_aneagoie_ztm-python-cheat-sheet.txt
ID: 263
Full Name: aneagoie/ztm-python-cheat-sheet
Description: None
Created At: 2019-09-21T23:51:14Z
Updated At: 2024-12-01T11:52:20Z
Pushed At: 2024-05-01T20:44:25Z
Language: None
URL: https://github.com/aneagoie/ztm-python-cheat-sheet
Forks: 1357
Stars: 2460
Topics: 
README:
Python ZTM Cheatsheet 💻🚀
===============================

We created this Python 3 Cheat Sheet initially for students of [Complete Python Developer: Zero to Mastery](https://zerotomastery.io/courses/learn-python/) but we're now sharing it with any Python beginners to help them learn and remember common Python syntax and with intermediate and advanced Python developers as a handy reference. If you'd like to download a PDF version of this Python Cheat Sheet, you can get it [here](https://zerotomastery.io/courses/python/cheatsheet/?utm_source=github&utm_medium=ztm-python-cheat-sheet)!

Contents
--------
**Python Types:** **[`Numbers`](#numbers)__,__[`Strings`](#strings)__,__[`Boolean`](#boolean)__,__[`Lists`](#lists)__,__[`Dictionaries`](#dictionaries)__,__ [`Tuples`](#tuples)__,__[`Sets`](#sets)__,__[`None`](#none)**  

**Python Basics:** **[`Comparison Operators`](#comparison-operators)__,__[`Logical Operators`](#logical-operators)__,__[`Loops`](#loops)__,__[`Range`](#range)__,__[`Enumerate`](#enumerate)__,__[`Counter`](#counter)__,__[`Named Tuple`](#named-tuple)__,__[`OrderedDict`](#ordereddict)**    

**Functions:** **[`Functions`](#functions)__,__[`Lambda`](#lambda)__,__[`Comprehensions`](#comprehensions)__,__[`Map,Filter,Reduce`](#map-filter-reduce)__,__[`Ternary`](#ternary-condition)__,__[`Any,All`](#any-all)__,__[`Closures`](#closures)__,__[`Scope`](#scope)**    

**Advanced Python:** **[`Modules`](#modules)__,__[`Iterators`](#iterators)__,__[`Generators`](#generators)__,__[`Decorators`](#decorators)__,__[`Class`](#class)__,__[`Exceptions`](#exceptions)__,__[`Command Line Arguments`](#command-line-arguments)__,__[`File IO`](#file-io)__,__[`Useful Libraries`](#useful-libraries)**  


Numbers
----
**python's 2 main types for Numbers is int and float (or integers and floating point numbers)**
```python
type(1)   # int 
type(-10) # int
type(0)   # int
type(0.0) # float
type(2.2) # float
type(4E2) # float - 4*10 to the power of 2
```

```python
# Arithmetic
10 + 3  # 13
10 - 3  # 7
10 * 3  # 30
10 ** 3 # 1000
10 / 3  # 3.3333333333333335
10 // 3 # 3 --> floor division - no decimals and returns an int
10 % 3  # 1 --> modulo operator - return the remainder. Good for deciding if number is even or odd
```

```python
# Basic Functions
pow(5, 2)      # 25 --> like doing 5**2
abs(-50)       # 50
round(5.46)    # 5
round(5.468, 2)# 5.47 --> round to nth digit
bin(512)       # '0b1000000000' -->  binary format
hex(512)       # '0x200' --> hexadecimal format
```

```python
# Converting Strings to Numbers
age = input("How old are you?")
age = int(age)
pi = input("What is the value of pi?")
pi = float(pi)
```

Strings
----
**strings in python are stored as sequences of letters in memory**
```python
type('Hellloooooo') # str

'I\'m thirsty'
"I'm thirsty"
"\n" # new line
"\t" # adds a tab

'Hey you!'[4] # y
name = 'Andrei Neagoie'
name[4]     # e
name[:]     # Andrei Neagoie
name[1:]    # ndrei Neagoie
name[:1]    # A
name[-1]    # e
name[::1]   # Andrei Neagoie
name[::-1]  # eiogaeN ierdnA
name[0:10:2]# Ade e
# : is called slicing and has the format [ start : end : step ]

'Hi there ' + 'Timmy' # 'Hi there Timmy' --> This is called string concatenation
'*'*10 # **********
```

```python
# Basic Functions
len('turtle') # 6

# Basic Methods
'  I am alone '.strip()               # 'I am alone' --> Strips all whitespace characters from both ends.
'On an island'.strip('d')             # 'On an islan' --> # Strips all passed characters from both ends.
'but life is good!'.split()           # ['but', 'life', 'is', 'good!']
'Help me'.replace('me', 'you')        # 'Help you' --> Replaces first with second param
'Need to make fire'.startswith('Need')# True
'and cook rice'.endswith('rice')      # True
'still there?'.upper()                # STILL THERE?
'HELLO?!'.lower()                     # hello?!
'ok, I am done.'.capitalize()         # 'Ok, I am done.'
'oh hi there'.count('e')              # 2
'bye bye'.index('e')                  # 2
'oh hi there'.find('i')               # 4 --> returns the starting index position of the first occurrence
'oh hi there'.find('a')               # -1
'oh hi there'.index('a')              # Raises ValueError
```

```python
# String Formatting
name1 = 'Andrei'
name2 = 'Sunny'
print(f'Hello there {name1} and {name2}')       # Hello there Andrei and Sunny - Newer way to do things as of python 3.6
print('Hello there {} and {}'.format(name1, name2))# Hello there Andrei and Sunny
print('Hello there %s and %s' %(name1, name2))  # Hello there Andrei and Sunny --> you can also use %d, %f, %r for integers, floats, string representations of objects respectively
```

```python
# Palindrome check
word = 'reviver'
p = bool(word.find(word[::-1]) + 1)
print(p) # True
```

Boolean
----
**True or False. Used in a lot of comparison and logical operations in Python**
```python
bool(True)
bool(False)

# all of the below evaluate to False. Everything else will evaluate to True in Python.
print(bool(None))
print(bool(False))
print(bool(0))
print(bool(0.0))
print(bool([]))
print(bool({}))
print(bool(()))
print(bool(''))
print(bool(range(0)))
print(bool(set()))

# See Logical Operators and Comparison Operators section for more on booleans.
```

Lists
----
**Unlike strings, lists are mutable sequences in python**
```python
my_list = [1, 2, '3', True]# We assume this list won't mutate for each example below
len(my_list)               # 4
my_list.index('3')         # 2
my_list.count(2)           # 1 --> count how many times 2 appears

my_list[3]                 # True
my_list[1:]                # [2, '3', True]
my_list[:1]                # [1]
my_list[-1]                # True
my_list[::1]               # [1, 2, '3', True]
my_list[::-1]              # [True, '3', 2, 1]
my_list[0:3:2]             # [1, '3']

# : is called slicing and has the format [ start : end : step ]
```

```python
# Add to List
my_list * 2                # [1, 2, '3', True, 1, 2, '3', True]
my_list + [100]            # [1, 2, '3', True, 100] --> doesn't mutate original list, creates new one
my_list.append(100)        # None --> Mutates original list to [1, 2, '3', True, 100]          # Or: <list> += [<el>]
my_list.extend([100, 200]) # None --> Mutates original list to [1, 2, '3', True, 100, 200]
my_list.insert(2, '!!!')   # None -->  [1, 2, '!!!', '3', True] - Inserts item at index and moves the rest to the right.

' '.join(['Hello','There'])# 'Hello There' --> Joins elements using string as separator.
```

```python
# Copy a List
basket = ['apples', 'pears', 'oranges']
new_basket = basket.copy()
new_basket2 = basket[:]
```
```python
# Remove from List
[1,2,3].pop()    # 3 --> mutates original list, default index in the pop method is -1 (the last item)
[1,2,3].pop(1)   # 2 --> mutates original list
[1,2,3].remove(2)# None --> [1,3] Removes first occurrence of item or raises ValueError.
[1,2,3].clear()  # None --> mutates original list and removes all items: []
del [1,2,3][0]   # None --> removes item on index 0 or raises IndexError
```

```python
# Ordering
[1,2,5,3].sort()         # None --> Mutates list to [1, 2, 3, 5]
[1,2,5,3].sort(reverse=True) # None --> Mutates list to [5, 3, 2, 1]
[1,2,5,3].reverse()      # None --> Mutates list to [3, 5, 2, 1]
sorted([1,2,5,3])        # [1, 2, 3, 5] --> new list created
my_list = [(4,1),(2,4),(2,5),(1,6),(8,9)]
sorted(my_list,key=lambda x: int(x[0])) # [(1, 6), (2, 4), (2, 5), (4, 1), (8, 9)] --> sort the list by 1st (0th index) value of the tuple
list(reversed([1,2,5,3]))# [3, 5, 2, 1] --> reversed() returns an iterator
```

```python
# Useful operations
1 in [1,2,5,3]  # True
min([1,2,3,4,5])# 1
max([1,2,3,4,5])# 5
sum([1,2,3,4,5])# 15
```

```python
# Get First and Last element of a list
mList = [63, 21, 30, 14, 35, 26, 77, 18, 49, 10]
first, *x, last = mList
print(first) #63
print(last) #10
```

```python
# Matrix
matrix = [[1,2,3], [4,5,6], [7,8,9]]
matrix[2][0] # 7 --> Grab first first of the third item in the matrix object

# Looping through a matrix by rows:
mx = [[1,2,3],[4,5,6]]
for row in range(len(mx)):
	for col in range(len(mx[0])):
		print(mx[row][col]) # 1 2 3 4 5 6
    
# Transform into a list:
[mx[row][col] for row in range(len(mx)) for col in range(len(mx[0]))] # [1,2,3,4,5,6]

# Combine columns with zip and *:
[x for x in zip(*mx)] # [(1, 3), (2, 4)]

```

```python
# List Comprehensions
# new_list[<action> for <item> in <iterator> if <some condition>]
a = [i for i in 'hello']                  # ['h', 'e', 'l', 'l', '0']
b = [i*2 for i in [1,2,3]]                # [2, 4, 6]
c = [i for i in range(0,10) if i % 2 == 0]# [0, 2, 4, 6, 8]
```

```python
# Advanced Functions
list_of_chars = list('Helloooo')                                   # ['H', 'e', 'l', 'l', 'o', 'o', 'o', 'o']
sum_of_elements = sum([1,2,3,4,5])                                 # 15
element_sum = [sum(pair) for pair in zip([1,2,3],[4,5,6])]         # [5, 7, 9]
sorted_by_second = sorted(['hi','you','man'], key=lambda el: el[1])# ['man', 'hi', 'you']
sorted_by_key = sorted([
                       {'name': 'Bina', 'age': 30},
                       {'name':'Andy', 'age': 18},
                       {'name': 'Zoey', 'age': 55}],
                       key=lambda el: (el['name']))# [{'name': 'Andy', 'age': 18}, {'name': 'Bina', 'age': 30}, {'name': 'Zoey', 'age': 55}]
```

```python
# Read line of a file into a list
with open("myfile.txt") as f:
  lines = [line.strip() for line in f]
```

Dictionaries
----------
**Also known as mappings or hash tables. They are key value pairs that are guaranteed to retain order of insertion starting from Python 3.7**
```python
my_dict = {'name': 'Andrei Neagoie', 'age': 30, 'magic_power': False}
my_dict['name']                      # Andrei Neagoie
len(my_dict)                         # 3
list(my_dict.keys())                 # ['name', 'age', 'magic_power']
list(my_dict.values())               # ['Andrei Neagoie', 30, False]
list(my_dict.items())                # [('name', 'Andrei Neagoie'), ('age', 30), ('magic_power', False)]
my_dict['favourite_snack'] = 'Grapes'# {'name': 'Andrei Neagoie', 'age': 30, 'magic_power': False, 'favourite_snack': 'Grapes'}
my_dict.get('age')                   # 30 --> Returns None if key does not exist.
my_dict.get('ages', 0 )              # 0 --> Returns default (2nd param) if key is not found

#Remove key
del my_dict['name']
my_dict.pop('name', None)
```

```python
my_dict.update({'cool': True})                                         # {'name': 'Andrei Neagoie', 'age': 30, 'magic_power': False, 'favourite_snack': 'Grapes', 'cool': True}
{**my_dict, **{'cool': True} }                                         # {'name': 'Andrei Neagoie', 'age': 30, 'magic_power': False, 'favourite_snack': 'Grapes', 'cool': True}
new_dict = dict([['name','Andrei'],['age',32],['magic_power',False]])  # Creates a dict from collection of key-value pairs.
new_dict = dict(zip(['name','age','magic_power'],['Andrei',32, False]))# Creates a dict from two collections.
new_dict = my_dict.pop('favourite_snack')                              # Removes item from dictionary.
```

```python
# Dictionary Comprehension
{key: value for key, value in new_dict.items() if key == 'age' or key == 'name'} # {'name': 'Andrei', 'age': 32} --> Filter dict by keys
```

Tuples
----
**Like lists, but they are used for immutable thing (that don't change)**
```python
my_tuple = ('apple','grapes','mango', 'grapes')
apple, grapes, mango, grapes = my_tuple# Tuple unpacking
len(my_tuple)                          # 4
my_tuple[2]                            # mango
my_tuple[-1]                           # 'grapes'
```

```python
# Immutability
my_tuple[1] = 'donuts'  # TypeError
my_tuple.append('candy')# AttributeError
```

```python
# Methods
my_tuple.index('grapes') # 1
my_tuple.count('grapes') # 2
```

```python
# Zip
list(zip([1,2,3], [4,5,6])) # [(1, 4), (2, 5), (3, 6)]
```

```python
# unzip
z = [(1, 2), (3, 4), (5, 6), (7, 8)] # Some output of zip() function
unzip = lambda z: list(zip(*z))
unzip(z)
```

Sets
---
**Unorderd collection of unique elements.**
```python
my_set = set()
my_set.add(1)  # {1}
my_set.add(100)# {1, 100}
my_set.add(100)# {1, 100} --> no duplicates!
```

```python
new_list = [1,2,3,3,3,4,4,5,6,1]
set(new_list)           # {1, 2, 3, 4, 5, 6}

my_set.remove(100)      # {1} --> Raises KeyError if element not found
my_set.discard(100)     # {1} --> Doesn't raise an error if element not found
my_set.clear()          # {}
new_set = {1,2,3}.copy()# {1,2,3}
```

```python
set1 = {1,2,3}
set2 = {3,4,5}
set3 = set1.union(set2)               # {1,2,3,4,5}
set4 = set1.intersection(set2)        # {3}
set5 = set1.difference(set2)          # {1, 2}
set6 = set1.symmetric_difference(set2)# {1, 2, 4, 5}
set1.issubset(set2)                   # False
set1.issuperset(set2)                 # False
set1.isdisjoint(set2)                 # False --> return True if two sets have a null intersection.

```

```python
# Frozenset
# hashable --> it can be used as a key in a dictionary or as an element in a set.
<frozenset> = frozenset(<collection>)
```

None
----
**None is used for absence of a value and can be used to show nothing has been assigned to an object**
```python
type(None) # NoneType
a = None
```

Comparison Operators
--------
```python
==                   # equal values
!=                   # not equal
>                    # left operand is greater than right operand
<                    # left operand is less than right operand
>=                   # left operand is greater than or equal to right operand
<=                   # left operand is less than or equal to right operand
<element> is <element> # check if two operands refer to same object in memory
```

Logical Operators
--------
```python
1 < 2 and 4 > 1 # True
1 > 3 or 4 > 1  # True
1 is not 4      # True
not True        # False
1 not in [2,3,4]# True

if <condition that evaluates to boolean>:
  # perform action1
elif <condition that evaluates to boolean>:
  # perform action2
else:
  # perform action3
```

Loops
--------
```python
my_list = [1,2,3]
my_tuple = (1,2,3)
my_list2 = [(1,2), (3,4), (5,6)]
my_dict = {'a': 1, 'b': 2. 'c': 3}

for num in my_list:
    print(num) # 1, 2, 3

for num in my_tuple:
    print(num) # 1, 2, 3

for num in my_list2:
    print(num) # (1,2), (3,4), (5,6)

for num in '123':
    print(num) # 1, 2, 3

for idx,value in enumerate(my_list):
    print(idx) # get the index of the item
    print(value) # get the value

for k,v in my_dict.items(): # Dictionary Unpacking
    print(k) # 'a', 'b', 'c'
    print(v) # 1, 2, 3

while <condition that evaluates to boolean>:
  # action
  if <condition that evaluates to boolean>:
    break # break out of while loop
  if <condition that evaluates to boolean>:
    continue # continue to the next line in the block
```

```python
# waiting until user quits
msg = ''
while msg != 'quit':
    msg = input("What should I do?")
    print(msg)
```

Range
-----
```python
range(10)          # range(0, 10) --> 0 to 9
range(1,10)        # range(1, 10)
list(range(0,10,2))# [0, 2, 4, 6, 8]
```

Enumerate
---------
```python
for i, el in enumerate('helloo'):
  print(f'{i}, {el}')
# 0, h
# 1, e
# 2, l
# 3, l
# 4, o
# 5, o
```

Counter
-----
```python
from collections import Counter
colors = ['red', 'blue', 'yellow', 'blue', 'red', 'blue']
counter = Counter(colors)# Counter({'blue': 3, 'red': 2, 'yellow': 1})
counter.most_common()[0] # ('blue', 3)
```

Named Tuple
-----------
* **Tuple is an immutable and hashable list.**
* **Named tuple is its subclass with named elements.**

```python
from collections import namedtuple
Point = namedtuple('Point', 'x y')
p = Point(1, y=2)# Point(x=1, y=2)
p[0]             # 1
p.x              # 1
getattr(p, 'y')  # 2
p._fields        # Or: Point._fields #('x', 'y')
```

```python
from collections import namedtuple
Person = namedtuple('Person', 'name height')
person = Person('Jean-Luc', 187)
f'{person.height}'           # '187'
'{p.height}'.format(p=person)# '187'
```

OrderedDict
--------
* **Maintains order of insertion**
```python
from collections import OrderedDict
# Store each person's languages, keeping # track of who responded first. 
programmers = OrderedDict()
programmers['Tim'] = ['python', 'javascript']
programmers['Sarah'] = ['C++']
programmers['Bia'] = ['Ruby', 'Python', 'Go']

for name, langs in programmers.items():
    print(name + '-->')
    for lang in langs:
      print('\t' + lang)

```

Functions
-------

#### \*args and \*\*kwargs
**Splat (\*) expands a collection into positional arguments, while splatty-splat (\*\*) expands a dictionary into keyword arguments.**
```python
args   = (1, 2)
kwargs = {'x': 3, 'y': 4, 'z': 5}
some_func(*args, **kwargs) # same as some_func(1, 2, x=3, y=4, z=5)
```

#### \* Inside Function Definition
**Splat combines zero or more positional arguments into a tuple, while splatty-splat combines zero or more keyword arguments into a dictionary.**
```python
def add(*a):
    return sum(a)

add(1, 2, 3) # 6
```

##### Ordering of parameters:
```python
def f(*args):                  # f(1, 2, 3)
def f(x, *args):               # f(1, 2, 3)
def f(*args, z):               # f(1, 2, z=3)
def f(x, *args, z):            # f(1, 2, z=3)

def f(**kwargs):               # f(x=1, y=2, z=3)
def f(x, **kwargs):            # f(x=1, y=2, z=3) | f(1, y=2, z=3)

def f(*args, **kwargs):        # f(x=1, y=2, z=3) | f(1, y=2, z=3) | f(1, 2, z=3) | f(1, 2, 3)
def f(x, *args, **kwargs):     # f(x=1, y=2, z=3) | f(1, y=2, z=3) | f(1, 2, z=3) | f(1, 2, 3)
def f(*args, y, **kwargs):     # f(x=1, y=2, z=3) | f(1, y=2, z=3)
def f(x, *args, z, **kwargs):  # f(x=1, y=2, z=3) | f(1, y=2, z=3) | f(1, 2, z=3)
```

#### Other Uses of \*
```python
[*[1,2,3], *[4]]                # [1, 2, 3, 4]
{*[1,2,3], *[4]}                # {1, 2, 3, 4}
(*[1,2,3], *[4])                # (1, 2, 3, 4)
{**{'a': 1, 'b': 2}, **{'c': 3}}# {'a': 1, 'b': 2, 'c': 3}
```

```python
head, *body, tail = [1,2,3,4,5]
```


Lambda
------
```python
# lambda: <return_value>
# lambda <argument1>, <argument2>: <return_value>
```

```python
# Factorial
from functools import reduce

n = 3
factorial = reduce(lambda x, y: x*y, range(1, n+1))
print(factorial) #6
```

```python
# Fibonacci
fib = lambda n : n if n <= 1 else fib(n-1) + fib(n-2)
result = fib(10)
print(result) #55
```

Comprehensions
------
```python
<list> = [i+1 for i in range(10)]         # [1, 2, ..., 10]
<set>  = {i for i in range(10) if i > 5}  # {6, 7, 8, 9}
<iter> = (i+5 for i in range(10))         # (5, 6, ..., 14)
<dict> = {i: i*2 for i in range(10)}      # {0: 0, 1: 2, ..., 9: 18}
```

```python
output = [i+j for i in range(3) for j in range(3)] # [0, 1, 2, 1, 2, 3, 2, 3, 4]

# Is the same as:
output = []
for i in range(3):
  for j in range(3):
    output.append(i+j)
```

Ternary Condition
-------
```python
# <expression_if_true> if <condition> else <expression_if_false>

[a if a else 'zero' for a in [0, 1, 0, 3]] # ['zero', 1, 'zero', 3]
```

Map Filter Reduce
------
```python
from functools import reduce
list(map(lambda x: x + 1, range(10)))            # [1, 2, 3, 4, 5, 6, 7, 8, 9,10]
list(filter(lambda x: x > 5, range(10)))         # (6, 7, 8, 9)
reduce(lambda acc, x: acc + x, range(10))        # 45
```

Any All
------
```python
any([False, True, False])# True if at least one item in collection is truthy, False if empty.
all([True,1,3,True])     # True if all items in collection are true
```


Closures
-------
**We have a closure in Python when:**
* **A nested function references a value of its enclosing function and then**
* **the enclosing function returns the nested function.**

```python
def get_multiplier(a):
    def out(b):
        return a * b
    return out
```

```python
>>> multiply_by_3 = get_multiplier(3)
>>> multiply_by_3(10)
30
```

* **If multiple nested functions within enclosing function reference the same value, that value gets shared.**
* **To dynamically access function's first free variable use `'<function>.__closure__[0].cell_contents'`.**



### Scope
**If variable is being assigned to anywhere in the scope, it is regarded as a local variable, unless it is declared as a 'global' or a 'nonlocal'.**

```python
def get_counter():
    i = 0
    def out():
        nonlocal i
        i += 1
        return i
    return out
```

```python
>>> counter = get_counter()
>>> counter(), counter(), counter()
(1, 2, 3)
```

Modules
----
```python
if __name__ == '__main__': # Runs main() if file wasn't imported.
    main()
```

```python
import <module_name>
from <module_name> import <function_name>
import <module_name> as m
from <module_name> import <function_name> as m_function
from <module_name> import *
```


Iterators
--------
**In this cheatsheet `'<collection>'` can also mean an iterator.**

```python
<iter> = iter(<collection>)
<iter> = iter(<function>, to_exclusive)     # Sequence of return values until 'to_exclusive'.
<el>   = next(<iter> [, default])           # Raises StopIteration or returns 'default' on end.
```


Generators
---------
**Convenient way to implement the iterator protocol.**

```python
def count(start, step):
    while True:
        yield start
        start += step
```

```python
>>> counter = count(10, 2)
>>> next(counter), next(counter), next(counter)
(10, 12, 14)
```


Decorators
---------
**A decorator takes a function, adds some functionality and returns it.**

```python
@decorator_name
def function_that_gets_passed_to_decorator():
    ...
```

**Example Decorator: timing performance using a decorator.**
* **The functools decorator `@functools.wraps` is used to maintain function naming and 
documentation of the function within the decorator.**

```python
from time import time 
import functools

def performance(func):

    @functools.wraps()
    def wrapper(*args, **kwargs):
        t1 = time()
        result = func(*args, **kwargs)
        t2 = time() 
        print(f"Took: {t2 - t1} ms")
        return result
    return wrapper

# calling a function with the decorator 
@performance
def long_time():
    print(sum(i*i for i in range(10000)))
``` 

### Debugger Example
**Decorator that prints function's name every time it gets called.**

```python
from functools import wraps

def debug(func):
    @wraps(func)
    def out(*args, **kwargs):
        print(func.__name__)
        return func(*args, **kwargs)
    return out

@debug
def add(x, y):
    return x + y
```
* **Wraps is a helper decorator that copies metadata of function add() to function out().**
* **Without it `'add.__name__'` would return `'out'`.**



Class
-----
**User defined objects are created using the class keyword**

```python
class <name>:
    age = 80 # Class Object Attribute
    def __init__(self, a):
        self.a = a # Object Attribute

    @classmethod
    def get_class_name(cls):
        return cls.__name__
```

### Inheritance
```python
class Person:
    def __init__(self, name, age):
        self.name = name
        self.age  = age

class Employee(Person):
    def __init__(self, name, age, staff_num):
        super().__init__(name, age)
        self.staff_num = staff_num
```

### Multiple Inheritance
```python
class A: pass
class B: pass
class C(A, B): pass
```

**MRO determines the order in which parent classes are traversed when searching for a method:**
```python
>>> C.mro()
[<class 'C'>, <class 'A'>, <class 'B'>, <class 'object'>]
```

Exceptions
----------

```python
try:
  5/0
except ZeroDivisionError:
  print("No division by zero!")
```

```python
while True:
  try:
    x = int(input('Enter your age: '))
  except ValueError:
    print('Oops!  That was no valid number.  Try again...')
  else: # code that depends on the try block running successfully should be placed in the else block.
    print('Carry on!')
    break
```

### Raising Exception
```python
raise ValueError('some error message')
```

### Finally
```python
try:
  raise KeyboardInterrupt
except:
  print('oops')
finally:
  print('All done!')

```



Command Line Arguments
----------------------
```python
import sys
script_name = sys.argv[0]
arguments   = sys.argv[1:]
```

File IO
----
**Opens a file and returns a corresponding file object.**

```python
<file> = open('<path>', mode='r', encoding=None)
```

### Modes
* **`'r'`  - Read (default).**
* **`'w'`  - Write (truncate).**
* **`'x'`  - Write or fail if the file already exists.**
* **`'a'`  - Append.**
* **`'w+'` - Read and write (truncate).**
* **`'r+'` - Read and write from the start.**
* **`'a+'` - Read and write from the end.**
* **`'t'`  - Text mode (default).**
* **`'b'`  - Binary mode.**

### File
```python
<file>.seek(0)                      # Moves to the start of the file.
```

```python
<str/bytes> = <file>.readline()     # Returns a line.
<list>      = <file>.readlines()    # Returns a list of lines.
```

```python
<file>.write(<str/bytes>)           # Writes a string or bytes object.
<file>.writelines(<list>)           # Writes a list of strings or bytes objects.
```
* **Methods do not add or strip trailing newlines.**

### Read Text from File
```python
def read_file(filename):
    with open(filename, encoding='utf-8') as file:
        return file.readlines() # or read()

for line in read_file(filename):
  print(line)
```

### Write Text to File
```python
def write_to_file(filename, text):
    with open(filename, 'w', encoding='utf-8') as file:
        file.write(text)
```

### Append Text to File
```python
def append_to_file(filename, text):
    with open(filename, 'a', encoding='utf-8') as file:
        file.write(text)
```

Useful Libraries
=========

CSV
---
```python
import csv
```

### Read Rows from CSV File
```python
def read_csv_file(filename):
    with open(filename, encoding='utf-8') as file:
        return csv.reader(file, delimiter=';')
```

### Write Rows to CSV File
```python
def write_to_csv_file(filename, rows):
    with open(filename, 'w', encoding='utf-8') as file:
        writer = csv.writer(file, delimiter=';')
        writer.writerows(rows)
```


JSON
----
```python
import json
<str>    = json.dumps(<object>, ensure_ascii=True, indent=None)
<object> = json.loads(<str>)
```

### Read Object from JSON File
```python
def read_json_file(filename):
    with open(filename, encoding='utf-8') as file:
        return json.load(file)
```

### Write Object to JSON File
```python
def write_to_json_file(filename, an_object):
    with open(filename, 'w', encoding='utf-8') as file:
        json.dump(an_object, file, ensure_ascii=False, indent=2)
```


Pickle
------
```python
import pickle
<bytes>  = pickle.dumps(<object>)
<object> = pickle.loads(<bytes>)
```

### Read Object from File
```python
def read_pickle_file(filename):
    with open(filename, 'rb') as file:
        return pickle.load(file)
```

### Write Object to File
```python
def write_to_pickle_file(filename, an_object):
    with open(filename, 'wb') as file:
        pickle.dump(an_object, file)
```


Profile
-------
### Basic
```python
from time import time
start_time = time()  # Seconds since
...
duration = time() - start_time
```

### Math
```python
from math import e, pi
from math import cos, acos, sin, asin, tan, atan, degrees, radians
from math import log, log10, log2
from math import inf, nan, isinf, isnan
```

### Statistics
```python
from statistics import mean, median, variance, pvariance, pstdev
```

### Random
```python
from random import random, randint, choice, shuffle
random() # random float between 0 and 1
randint(0, 100) # random integer between 0 and 100
random_el = choice([1,2,3,4]) # select a random element from list
shuffle([1,2,3,4]) # shuffles a list
```


Datetime
--------
* **Module 'datetime' provides 'date' `<D>`, 'time' `<T>`, 'datetime' `<DT>` and 'timedelta' `<TD>` classes. All are immutable and hashable.**
* **Time and datetime can be 'aware' `<a>`, meaning they have defined timezone, or 'naive' `<n>`, meaning they don't.**
* **If object is naive it is presumed to be in system's timezone.**

```python
from datetime import date, time, datetime, timedelta
from dateutil.tz import UTC, tzlocal, gettz
```

### Constructors
```python
<D>  = date(year, month, day)
<T>  = time(hour=0, minute=0, second=0, microsecond=0, tzinfo=None, fold=0)
<DT> = datetime(year, month, day, hour=0, minute=0, second=0, ...)
<TD> = timedelta(days=0, seconds=0, microseconds=0, milliseconds=0,
                 minutes=0, hours=0, weeks=0)
```
* **Use `'<D/DT>.weekday()'` to get the day of the week (Mon == 0).**
* **`'fold=1'` means second pass in case of time jumping back for one hour.**

### Now
```python
<D/DTn>  = D/DT.today()                     # Current local date or naive datetime.
<DTn>    = DT.utcnow()                      # Naive datetime from current UTC time.
<DTa>    = DT.now(<tz>)                     # Aware datetime from current tz time.
```

### Timezone
```python
<tz>     = UTC                              # UTC timezone.
<tz>     = tzlocal()                        # Local timezone.
<tz>     = gettz('<Cont.>/<City>')          # Timezone from 'Continent/City_Name' str.
```

```python
<DTa>    = <DT>.astimezone(<tz>)            # Datetime, converted to passed timezone.
<Ta/DTa> = <T/DT>.replace(tzinfo=<tz>)      # Unconverted object with new timezone.
```

Regex
-----
```python
import re
<str>   = re.sub(<regex>, new, text, count=0)  # Substitutes all occurrences.
<list>  = re.findall(<regex>, text)            # Returns all occurrences.
<list>  = re.split(<regex>, text, maxsplit=0)  # Use brackets in regex to keep the matches.
<Match> = re.search(<regex>, text)             # Searches for first occurrence of pattern.
<Match> = re.match(<regex>, text)              # Searches only at the beginning of the text.
```


### Match Object
```python
<str>   = <Match>.group()   # Whole match.
<str>   = <Match>.group(1)  # Part in first bracket.
<tuple> = <Match>.groups()  # All bracketed parts.
<int>   = <Match>.start()   # Start index of a match.
<int>   = <Match>.end()     # Exclusive end index of a match.
```

### Special Sequences
**Expressions below hold true for strings that contain only ASCII characters. Use capital letters for negation.**
```python
'\d' == '[0-9]'          # Digit
'\s' == '[ \t\n\r\f\v]'  # Whitespace
'\w' == '[a-zA-Z0-9_]'   # Alphanumeric
```


Credits
------
Inspired by: https://github.com/gto76/python-cheatsheet



File: 345_shakkaist_Python.txt
ID: 345
Full Name: shakkaist/Python
Description: None
Created At: 2017-10-19T03:19:02Z
Updated At: 2023-03-11T00:20:30Z
Pushed At: 2024-01-06T12:52:21Z
Language: Jupyter Notebook
URL: https://github.com/shakkaist/Python
Forks: 79
Stars: 13
Topics: 
README:



File: 348_ms-iot_python.txt
ID: 348
Full Name: ms-iot/python
Description: None
Created At: 2015-02-20T01:01:09Z
Updated At: 2024-07-23T22:09:05Z
Pushed At: 2022-11-16T20:24:24Z
Language: Python
URL: https://github.com/ms-iot/python
Forks: 59
Stars: 63
Topics: 
README:
# python
## cpython
This folder contains a modified version of CPython which supports running in a Windows 10 UWP application.  
Specifically, this supports running in Python in a background application on Windows 10 IoT Core and also contains some module extensions which also support Windows 10 IoT Core.  See [README_uwp.md](README_uwp.md) for differences running under Windows 10 IoT core.
* Before performing any builds, ensure to run *cpython\PCBuild\get_externals -c* from command line first
* For UWP specific builds, open *cpython\Tools\pyuwp\pyuwp.sln*.
* For all CPython projects, open *cpython\PCBuild\pcbuild.sln*.

## pywindevices.sln
This file is the solution pulling the 3 device extension modules together to build for Windows 10 IoT Core UWP
### wingpio
This folder contains a GPIO extension module to work in Windows 10 IoT Core UWP applications for communication with GPIO pins 
### wini2c
This folder contains an I2C extension module to work in Windows 10 IoT Core UWP applications for communication with I2C interfaces
### winspi
This folder contains a SPI extension module to work in Windows 10 IoT Core UWP applications for communication with SPI interfaces

===

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.




File: 360_krishnaik06_Complete-Python-Bootcamp.txt
ID: 360
Full Name: krishnaik06/Complete-Python-Bootcamp
Description: None
Created At: 2024-06-11T09:05:05Z
Updated At: 2024-12-02T02:31:42Z
Pushed At: 2024-08-12T14:46:51Z
Language: Jupyter Notebook
URL: https://github.com/krishnaik06/Complete-Python-Bootcamp
Forks: 1026
Stars: 765
Topics: 
README:
# Complete-Python-Bootcamp


File: 397_mk-codingspace_Python.txt
ID: 397
Full Name: mk-codingspace/Python
Description: None
Created At: 2021-03-04T02:10:28Z
Updated At: 2024-05-13T20:40:06Z
Pushed At: 2023-02-21T13:53:10Z
Language: Python
URL: https://github.com/mk-codingspace/Python
Forks: 78
Stars: 24
Topics: 
README:
This is a repository holding code for Python Projects. Please visit my Youtube channel at
https://www.youtube.com/channel/UCXSKsJMfXnw3aWBa3DjBUCg



File: 405_analyticswithadam_Python.txt
ID: 405
Full Name: analyticswithadam/Python
Description: None
Created At: 2021-05-16T21:15:18Z
Updated At: 2024-11-08T19:43:55Z
Pushed At: 2024-07-17T06:30:53Z
Language: Jupyter Notebook
URL: https://github.com/analyticswithadam/Python
Forks: 54
Stars: 57
Topics: 
README:



File: 427_marktao99_python.txt
ID: 427
Full Name: marktao99/python
Description: None
Created At: 2012-12-28T07:09:17Z
Updated At: 2024-04-10T11:46:40Z
Pushed At: 2020-10-01T11:35:09Z
Language: Python
URL: https://github.com/marktao99/python
Forks: 25
Stars: 35
Topics: 
README:



File: 438_AileenNielsen_TimeSeriesAnalysisWithPython.txt
ID: 438
Full Name: AileenNielsen/TimeSeriesAnalysisWithPython
Description: None
Created At: 2016-06-28T02:57:43Z
Updated At: 2024-11-30T06:23:02Z
Pushed At: 2022-04-26T13:23:19Z
Language: Jupyter Notebook
URL: https://github.com/AileenNielsen/TimeSeriesAnalysisWithPython
Forks: 1114
Stars: 1825
Topics: 
README:
# TimeSeriesAnalysisWithPython


File: 444_learn-co-curriculum_python-p3-running-python-code.txt
ID: 444
Full Name: learn-co-curriculum/python-p3-running-python-code
Description: None
Created At: 2022-06-03T19:18:07Z
Updated At: 2024-11-14T04:52:01Z
Pushed At: 2024-05-20T13:12:58Z
Language: Python
URL: https://github.com/learn-co-curriculum/python-p3-running-python-code
Forks: 3445
Stars: 2
Topics: 
README:
# Running Python Code

## Learning Goals

- Run Python code from a file.
- Log output to the terminal.
- Run Python code from the Python shell.
- Create a `pipenv` virtual environment.
- Run `pytest` tests.

***

## Key Vocab

- **Interpreter**: a program that executes other programs. Python programs
require the Python interpreter to be installed on your computer so that they
can be run.
- **Python Shell**: an interactive interpreter that can be accessed from the
command line.
- **Data Type**: a specific kind of data. The Python interpreter uses these
types to determine which actions can be performed on different data items.
- **Exception**: a type of error that can be predicted and handled without
causing a program to crash.
- **Code Block**: a collection of code that is interpreted together. Python
groups code blocks by indentation level.
- **Function**: a named code block that performs a sequence of actions when it
is called.
- **Scope**: the area in your program where a specific variable can be called.

***

## Introduction

In this lesson, you'll get some practice running Python code, and see a few
different ways to check what your code is doing. Make sure to code along to get
comfortable in this new environment!

***

## Creating a Python Application

Let's dive right in. To get started on any new Python application, the first
thing we need is a file. Fork and clone this lesson from GitHub, then create a
new file in this repo's `lib/` directory called `app.py`. In this file, add
the following:

```python
# lib/app.py
print("Hello world!")
```

`print()` is a built-in Python function that will output a string of text to the
terminal. It's the Python equivalent of `console.log()` in JavaScript. It will
print the string "Hello world!" along with a line break at the end.

The line above `print()` is a Python comment. In Python, any line that starts with
a `#` won't be executed by the interpreter. This is the Python equivalent of
`//` in JavaScript.

***

## Running Python Applications

Unlike JavaScript, you won't be running Python applications in the browser.
Instead, you'll need to use the Python interpreter to run your code from the
terminal. You can check which version of Python you're using with this command:

```console
$ python --version
Python 3.8.13
```

To run the application, enter the command `python filename.py`, where
`filename.py` is the relative path to the file you'd like to run:

```console
$ python lib/app.py
Hello world!
```

Congrats on running your first Python application! 🎉

***

## Displaying Data with "print()"

Now that we have a place to write some code, let's explore a few of Python's
built-in options for displaying data in different ways.

### Standard print() Statements

By default, `print()` includes a newline character at the end of your string.
Try entering several `print()` statements in a row in `lib/app.py`:

```python
# lib/app.py
print("Hello world!")
print("Hello sun!")
print("Hello sky!")
```

What do you see when you execute `lib/app.py` from the command line?

```console
$ python lib/app.py
# => Hello world!
# => Hello sun!
# => Hello sky!
```

***

### Choosing your own print() Ending

Let's say you're writing a full paragraph and don't need a newline character
after every sentence. `print()` can accommodate that through its optional `end`
parameter. Try modifying your `print()` statements as follows:

```py
# lib/app.py
print("Hello world!", end=" ")
print("Hello sun!", end="!! ")
print("Hello sky!", end="!!!\n")
```

What do you see when you execute `lib/app.py` from the command line with these new
`end` strings?

```console
$ python lib/app.py
# => Hello world! Hello sun!!! Hello sky!!!!
```

`end` can be a string of any length, including characters like the newline `\n`.

***

## Exploring Python with the Python Interpreter

Python comes with a command line interpreter (often called the "Python shell")
for running a Python REPL (read-evaluate-print-loop) in the terminal, which
provides similar functionality to the browser console that you're familiar with
from JavaScript. Using the Python shell is a great way to quickly test out some
code, or check your syntax, without needing to run an entire application.

To use the Python shell, go into the terminal and enter `python`:

```console
$ python
Python 3.8.13 (default, Jun  2 2022, 15:59:12)
[Clang 13.1.6 (clang-1316.0.21.2.5)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
>>>
```

This gives you a prompt where you can enter Python code. Try entering in
`print("Hello Python shell")`:

```console
$ python
Python 3.8.13 (default, Jun  2 2022, 15:59:12)
[Clang 13.1.6 (clang-1316.0.21.2.5)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
>>> print("Hello Python shell")
# => Hello Python shell
```

Try running a few more expressions in the Python Shell:

```console
>>> first_number = 7
>>> print(first_number)
# => 7
```

In the code above, we've declared a **local variable** called `first_number` and
assigned it a value of `7`. When we tell the Python shell to `print(first_number)`,
we see our local variable's value on the next line.

> In Python, it's convention to use underscores ( \_ ) to separate words in
> variables. This is referred to as **snake case** (as opposed to **camel
> case**, which is the convention in JavaScript).

You can exit the Python shell by typing `exit()`, or pressing `ctrl + d`.

***

## Running `pytest` Tests

All the lessons in the Python curriculum use the `pytest` library for testing your
Python code.

In this lesson, you'll see a `testing/` folder with one file, `app_test.py`.
`app_test.py` is where we've defined tests specifically for this lesson.

`pytest` is a Python library (the Python equivalent of an npm package) that
provides a very simple and clean way to write tests.

***

### Installing `pytest`

Each lesson in the Python curriculum will contain a file called `Pipfile`. This
file contains all of the required Python libraries for your work, and restricts
them to the repository that you're working in.

To install `pytest` and any other required libraries, simply navigate to a folder
with a `Pipfile` and enter `pipenv install`:

```console
$ pipenv install
Pipfile.lock not found, creating...
Locking [dev-packages] dependencies...
Building requirements...
Resolving dependencies...
✔ Success!
Locking [packages] dependencies...
Building requirements...
Resolving dependencies...
✔ Success!
Updated Pipfile.lock (cb35ed)!
Installing dependencies from Pipfile.lock (cb35ed)...
  🐍   ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0/0 — 00:00:00
To activate this project's virtualenv, run pipenv shell.
Alternatively, run a command inside the virtualenv with pipenv run.
```

Now that your `pipenv` virtual environment is ready to use, enter `pipenv shell`
to start working:

```console
$ pipenv shell
Launching subshell in virtual environment...
 . /Users/.../venv/bin/activate
$  . /Users/.../.venv/bin/activate
(python-p3-running-python-code) $
```

Let's take one of these tests as an example to see `pytest`'s syntax:

```python
def test_app_py_exists():
    assert(path.exists("lib/app.py"))
```

`pytest` expects a **function** with `test` in its name within the `testing`
folder. We will discuss functions later on in this module. For now, all that
you need to know is that a function performs an action when it's called.

Normally, you would have to call the function yourself with
`test_app_py_exists()`, but in this case `pytest` is calling all `test`
functions for you.

Delete the file `lib/app.py` to start from scratch so we can try getting these
tests to pass.

To run the tests, you will simply run `pytest` from inside of your
`python-p3-running-python-code` directory.

```console
$ pytest
============================= test session starts ==============================
platform darwin -- Python 3.10.4, pytest-7.1.2, pluggy-1.0.0
rootdir: /Users/benbotsford/Documents/python-p3-running-python-code
collected 3 items

lib/app.py exists in lib directory F                                         [ 33%]
lib/app.py is executable F                                                   [ 66%]
lib/app.py prints "Hello World! Pass this test, please." F                   [100%]

=================================== FAILURES ===================================

...

=========================== short test summary info ============================
FAILED lib/app.py exists in lib directory - AssertionError: assert False
FAILED lib/app.py is executable - FileNotFoundError: [Errno 2] No such file or di...
FAILED lib/app.py prints "Hello World! Pass this test, please." - FileNotFoundErr...
============================== 3 failed in 0.02s ===============================
```

`pytest` provides all kinds of useful information about what went right and wrong
with our code, so make sure to spend your time reading all the output here! It
will tell you:

- Which tests passed/didn't pass
- Why each failing test failed (the difference between the expected output and
  the actual output)
- The line number of the failing test

You can also use the `-x` flag to tell `pytest` to stop running after the first
failing test. This technique is helpful for focusing your attention on one
problem at a time:

```console
$ pytest -x

============================= test session starts ==============================
platform darwin -- Python 3.10.4, pytest-7.1.2, pluggy-1.0.0
rootdir: /Users/benbotsford/Documents/python-p3-running-python-code
collected 3 items

lib/app.py exists in lib directory F

=================================== FAILURES ===================================
_________________________ TestAppPy.test_app_py_exists _________________________

self = <app_test.TestAppPy object at 0x103743a90>

    def test_app_py_exists(self):
        '''
        exists in lib directory
        '''
>       assert(path.exists("lib/app.py"))
E       AssertionError: assert False
E        +  where False = <function exists at 0x10292e0e0>('lib/app.py')
E        +    where <function exists at 0x10292e0e0> = path.exists

testing/app_test.py:16: AssertionError
=========================== short test summary info ============================
FAILED lib/app.py exists in lib directory - AssertionError: assert False
!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!
============================== 1 failed in 0.01s ===============================
```

***

## Instructions

To finish this lab, use the `print()` in the `lib/app.py` file
as described by the tests:

- Use `print()` to display the text on one line: "Hello World! Pass this test,
  please."

Using `pytest` will run the tests. After they are passing, sync your progress
using Git. When your tests are all passing and your work is synced, the lab is
complete!

***

## Conclusion

This lesson covered a good amount of material, but now you should be familiar
with running code in a Python `pipenv` environment, and using tools like the
Python Shell and `pytest` as well as built-in methods like `print()` to
understand what happens when your Python code is running. You'll need all these
tools going forward, so make sure to get practice with all of them as you
progress through this phase!

***

## Resources

- [Python print() function](https://www.w3schools.com/python/ref_func_print.asp)
- [Python Getting Started](https://www.w3schools.com/python/python_getstarted.asp)
- [pipenv Documentation](https://pipenv.pypa.io/en/latest/)
- [pytest Documentation](https://docs.pytest.org/en/7.1.x/)


File: 446_Shaligram1234_Python.txt
ID: 446
Full Name: Shaligram1234/Python
Description: None
Created At: 2020-05-08T10:51:45Z
Updated At: 2023-09-21T21:51:29Z
Pushed At: 2023-09-21T22:26:41Z
Language: Python
URL: https://github.com/Shaligram1234/Python
Forks: 46
Stars: 14
Topics: 
README:



File: 452_Premalatha-success_Python.txt
ID: 452
Full Name: Premalatha-success/Python
Description: None
Created At: 2021-11-08T12:20:45Z
Updated At: 2023-05-18T12:46:15Z
Pushed At: 2021-12-19T10:18:09Z
Language: Jupyter Notebook
URL: https://github.com/Premalatha-success/Python
Forks: 54
Stars: 15
Topics: 
README:



File: 467_eye9poob_python.txt
ID: 467
Full Name: eye9poob/python
Description: None
Created At: 2013-12-11T21:32:28Z
Updated At: 2024-09-18T07:39:46Z
Pushed At: 2018-03-18T18:10:32Z
Language: Python
URL: https://github.com/eye9poob/python
Forks: 53
Stars: 40
Topics: 
README:
A misc collection of useful python scripts for you



File: 477_quandl_quandl-python.txt
ID: 477
Full Name: quandl/quandl-python
Description: None
Created At: 2013-03-24T12:53:23Z
Updated At: 2024-12-02T04:13:17Z
Pushed At: 2022-04-29T15:50:15Z
Language: Python
URL: https://github.com/quandl/quandl-python
Forks: 340
Stars: 1393
Topics: api-client, data-frame, dataset, python, quandl, retrieve-data
README:
# Quandl is now Nasdaq Data Link

We are excited to announce that the Quandl technology platform is being transformed into a new global solution: Nasdaq Data Link. This development is the first step toward realizing a single, unified data discovery and delivery experience with Nasdaq.

In accordance with this change Nasdaq Data Link has released a new version of this Python Client.  Moving forward, we are encouraging user to use this [VERSION](https://github.com/Nasdaq/data-link-python) in order to take advantage of new features.

# Quandl Python Client
[![Build Status](https://codebuild.us-east-1.amazonaws.com/badges?uuid=eyJlbmNyeXB0ZWREYXRhIjoiZUtvUFNYREloNE4vV0xWWEUxVS81S0toZjdQbzQrWXhQZ1BUbE1mZ1FMVXdSZXQ2K1ZLQ1ducmtqYTVWa2xBZXhRMWVGemVKWitzVm5MNXI4cGZYb21RPSIsIml2UGFyYW1ldGVyU3BlYyI6Im0vdUljcjBjdmpGVU9XdXUiLCJtYXRlcmlhbFNldFNlcmlhbCI6MX0%3D&branch=master)]()
[![PyPI version](https://badge.fury.io/py/Quandl.svg)](https://badge.fury.io/py/Quandl)

This is the official documentation for Quandl's Python Package. The package can be used to interact with the latest version of the [Quandl RESTful API](https://www.quandl.com/docs/api). This package is compatible with python v2.7.x and v3.x+.

## Deprecation of old package

Please see this readme for more information and upgrade instructions: [2.x series transition notes](./2_SERIES_UPGRADE.md)

## Installation

The installation process varies depending on your python version and system used. However in most cases the following should work:

```shell
pip install quandl
```

Alternatively on some systems python3 may use a different pip executable and may need to be installed via an alternate pip command. For example:

```shell
pip3 install quandl
```

## Configuration

| Option | Explanation | Example |
|---|---|---|
| api_key | Your access key | `tEsTkEy123456789` | Used to identify who you are and provide full access. |
| use_retries | Whether API calls which return statuses in `retry_status_codes` should be automatically retried | True
| number_of_retries | Maximum number of retries that should be attempted. Only used if `use_retries` is True | 5
| max_wait_between_retries | Maximum amount of time in seconds that should be waited before attempting a retry. Only used if `use_retries` is True | 8
| retry_backoff_factor | Determines the amount of time in seconds that should be waited before attempting another retry. Note that this factor is exponential so a `retry_backoff_factor` of 0.5 will cause waits of [0.5, 1, 2, 4, etc]. Only used if `use_retries` is True | 0.5
| retry_status_codes | A list of HTTP status codes which will trigger a retry to occur. Only used if `use_retries` is True| [429, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511]

```python
import quandl
quandl.ApiConfig.api_key = 'tEsTkEy123456789'
```
By default, SSL verification is enabled. To bypass SSL verification
```python
quandl.ApiConfig.verify_ssl = False
```

### Local API Key file
Save local key to `$HOME/.quandl_apikey` file
```
import quandl
quandl.save_key("supersecret")
print(quandl.ApiConfig.api_key)
```

Load the API Key without exposing the key in the script or notebook
```
import quandl
quandl.read_key()
print(quandl.ApiConfig.api_key)
```

Set a custom location for the API key file, e.g. store the externally outside a docker container
```
import quandl
quandl.save_key("ourcorporateapikey", filename="/srv/data/somecontainer/.corporatequandlapikey")
```
and call within the docker container with mount point at `/data`
```
import quandl
quandl.read_key(filepath="/data/.corporatequandlapikey")
```


## Retrieving Data

There are two methods for retrieving data in Python: the Quick method and the Detailed method. The latter is more suitable to application programming. Both methods work with Quandl's two types of data structures: time-series (dataset) data and non-time series (datatable).

The following quick call can be used to retrieve a dataset:

```python
import quandl
data = quandl.get('NSE/OIL')
```

This example finds all data points for the dataset `NSE/OIL` and stores them in a pandas dataframe. You can then view the dataframe with data.head().

A similar quick call can be used to retrieve a datatable:

```python
import quandl
data = quandl.get_table('ZACKS/FC', ticker='AAPL')
```

This example retrieves all rows for `ZACKS/FC` where `ticker='AAPL'` and stores them in a pandas dataframe. Similarly you can then view the dataframe with data.head().

Note that in both examples if an `api_key` has not been set you may receive limited or sample data. You can find more details on these quick calls and others in our [Quick Method Guide](./FOR_ANALYSTS.md).

### Logging

Currently, Quandl debug logging is limited in scope.  However, to enable debug
logs you can use the following snippet.

```python
import quandl
import logging

logging.basicConfig()
# logging.getLogger().setLevel(logging.DEBUG)  # optionally set level for
everything.  Useful to see dependency debug info as well.

quandl_log = logging.getLogger("quandl")
quandl_log.setLevel(logging.DEBUG)
```


### Detailed Usage

Our API can provide more than just data. It can also be used to search and provide metadata or to programmatically retrieve data. For these more advanced techniques please follow our [Detailed Method Guide](./FOR_DEVELOPERS.md).

## Local Development

### Setup

If you wish to work on local development please clone/fork the git repo and use `pip install -r requirements.txt` to setup the project.

### Testing

We recommend the following tools for testing any changes:

* [nose](https://nose.readthedocs.org/en/latest/) for running tests.
* [tox](https://pypi.python.org/pypi/tox) for testing against multiple versions of python.
* [flake8](https://flake8.readthedocs.org/en/latest/) for syntax checking.
* [virtualenv](https://virtualenv.pypa.io/en/latest/) for use with tox virtualization.

The following are instructions for running our tests:

1. Make sure a version of python 2.7 or python 3.x is installed locally in your system. To avoid permission issues on OSX we recommend installing the packages from: https://www.python.org/downloads/
2. Install `virtualenv` and `tox` using:
    `pip install tox virtualenv`
3. Run following command (you may notice slow performance the first time):
    `python setup.py install`
4. Run the following command to test the plugin in all versions of python we support:
    `tox`

Once you have all required packages installed, you can run tests locally with:

Running all tests locally

```python
python -W always setup.py -q test
```

Running an individual test

```python
python -m unittest test.[test file name].[class name].[individual test name]`
```

Example:

```python
python -m unittest -v test.test_datatable.ExportDataTableTest.test_download_get_file_info
```

## Recommended Usage

We would suggest downloading the data in raw format in the highest frequency possible and performing any data manipulation
in pandas itself.

See [this link](http://pandas.pydata.org/pandas-docs/dev/timeseries.html) for more information about timeseries in pandas.

## Release the Package

To release the package, you can follow the instructions on this [page](https://packaging.python.org/tutorials/packaging-projects/#packaging-python-projects)

## Additional Links

* [Quandl](https://www.quandl.com)
* [Quandl Tools](https://www.quandl.com/tools/api)
* [API Docs](https://www.quandl.com/docs/api)

## License

[MIT License](http://opensource.org/licenses/MIT)



File: 490_starksecurity_Pierian-Data-Complete-Python-3-Bootcamp.txt
ID: 490
Full Name: starksecurity/Pierian-Data-Complete-Python-3-Bootcamp
Description: None
Created At: 2018-06-01T09:38:21Z
Updated At: 2024-11-29T16:04:37Z
Pushed At: 2023-10-09T13:43:03Z
Language: Jupyter Notebook
URL: https://github.com/starksecurity/Pierian-Data-Complete-Python-3-Bootcamp
Forks: 1808
Stars: 866
Topics: 
README:
# Complete-Python-3-Bootcamp
Course Files for Complete Python 3 Bootcamp Course on Udemy


Get it now for 95% off with the link:
https://www.udemy.com/complete-python-bootcamp/?couponCode=COMPLETE_GITHUB

Thanks!



File: 49_soyHenry_Python-Prep.txt
ID: 49
Full Name: soyHenry/Python-Prep
Description: None
Created At: 2022-01-11T18:05:17Z
Updated At: 2024-11-26T16:23:41Z
Pushed At: 2024-08-12T23:15:17Z
Language: Jupyter Notebook
URL: https://github.com/soyHenry/Python-Prep
Forks: 13703
Stars: 765
Topics: 
README:
![HenryLogo](https://d31uz8lwfmyn8g.cloudfront.net/Assets/logo-henry-white-lg.png)


# **🧑‍💻 PREP COURSE | HENRY 👩‍💻**

## **📌 INTRODUCCIÓN**

¡Hola 😄! Bienvenid@ al Prep Course para la carrera de Data Science

En este curso introductorio podrás aprender y practicar todo el contenido que necesitas para alcanzar un nivel intermedio en Python, el lenguaje con el que vas a trabajar en la carrera. Encontrarás todo el material que necesitas para lograr avanzar en la evaluación del Henry Challenge (último paso para ingresar a la carrera de Data).

</br >

## **🔎 ¿QUÉ ES EL PREP COURSE?**

El Prep Course (curso preparatorio) es un curso diseñado con la finalidad de nivelar a todos nuestros aplicantes. Con este curso darás tus primeros pasos en el mundo de la tecnología y aprenderás esos conceptos básicos que son necesarios para poder realizar la carrera.

El curso consiste en una serie de videos, material teórico y ejercicios con los que podrás aprender nuestro lenguaje de desarrollo: Python. Puedes avanzar con el contenido a tu ritmo y de manera asincrónica (es decir, en los horarios y tiempos que tu prefieras).Una vez que hayas terminado de estudiarlo, podrás continuar con el contenido de matemática que se encuentra en:  [Prep de Matemática](math.prep.soyhenry.com)
 Cuando hayas finalizado, podrás inscribirte para realizar el Henry Challenge.

</br >

## **📖 ¿QUÉ ES EL HENRY CHALLENGE?**

Es un examen en el que evaluamos los conceptos que se aprenden durante el Prep Course. El examen tiene la finalidad de asegurarnos que realmente has adquirido los conocimientos, dado que tenerlos bien claros es la clave del éxito para que puedas avanzar sin problemas dentro de la carrera. El examen se realiza todos sábado por medio sábados, con previo registro e  [inscripción](https://admissions.soyhenry.com/  ). Podrás rendirlo hasta 3 veces. Tambien incluye una evaluación de Matematica, pero solamente para conocer tu nivel.

</br >

## **🤨 ¿QUÉ PUEDO HACER SI TENGO DUDAS?**



-  **SLACK:** es nuestra plataforma de comunicación, donde podrás ponerte en contacto con nuestra comunidad que siempre te ayudará a resolver todas tus dudas. Encontrarás acceso a Slack desde la [plataforma de admisión](https://www.admissions.soyhenry.com/) o desde los mails que recibiste al momento de aplicar.



</br >

## **😋 ¿CÓMO AVANZAR EN ESTE PROCESO?**

Para avanzar debes seguir el material teórico junto con los videos de este curso introductorio. Para afianzar tus conocimientos y comenzar a practicar realiza cada una de estas **_Homeworks_**. Esto te facilitará resolver el Henry Challenge.

Cualquier duda, nos puedes escribir a admisiones@soyhenry.com

</br>



File: 520_krishnaik06_Pyspark-With-Python.txt
ID: 520
Full Name: krishnaik06/Pyspark-With-Python
Description: None
Created At: 2021-05-04T07:22:22Z
Updated At: 2024-11-20T13:41:27Z
Pushed At: 2021-05-17T14:50:05Z
Language: Jupyter Notebook
URL: https://github.com/krishnaik06/Pyspark-With-Python
Forks: 701
Stars: 467
Topics: 
README:
# Pyspark-With-Python


File: 538_AlexTheAnalyst_PythonCode.txt
ID: 538
Full Name: AlexTheAnalyst/PythonCode
Description: None
Created At: 2020-07-15T02:32:14Z
Updated At: 2024-11-27T10:30:57Z
Pushed At: 2023-10-26T16:30:00Z
Language: Jupyter Notebook
URL: https://github.com/AlexTheAnalyst/PythonCode
Forks: 149
Stars: 240
Topics: 
README:



File: 562_AyeshaSahar_Python.txt
ID: 562
Full Name: AyeshaSahar/Python
Description: None
Created At: 2021-04-24T20:29:24Z
Updated At: 2024-09-01T14:43:41Z
Pushed At: 2022-08-02T00:14:45Z
Language: Python
URL: https://github.com/AyeshaSahar/Python
Forks: 42
Stars: 45
Topics: 
README:
# Python

Just some python projects :)



File: 564_patrickloeber_python-engineer-notebooks.txt
ID: 564
Full Name: patrickloeber/python-engineer-notebooks
Description: None
Created At: 2019-05-19T12:39:42Z
Updated At: 2024-12-01T07:49:43Z
Pushed At: 2024-02-26T19:50:47Z
Language: Jupyter Notebook
URL: https://github.com/patrickloeber/python-engineer-notebooks
Forks: 522
Stars: 712
Topics: 
README:
# Collection of Jupyter Notebooks for the website


File: 568_Pitsillides91_Python-Tutorials.txt
ID: 568
Full Name: Pitsillides91/Python-Tutorials
Description: None
Created At: 2019-10-13T13:32:26Z
Updated At: 2024-12-01T22:43:47Z
Pushed At: 2024-11-29T17:47:02Z
Language: Jupyter Notebook
URL: https://github.com/Pitsillides91/Python-Tutorials
Forks: 568
Stars: 236
Topics: 
README:



File: 577_uber_Python-Sample-Application.txt
ID: 577
Full Name: uber/Python-Sample-Application
Description: None
Created At: 2014-08-06T21:19:49Z
Updated At: 2024-11-03T11:21:11Z
Pushed At: 2023-10-02T10:01:43Z
Language: Python
URL: https://github.com/uber/Python-Sample-Application
Forks: 669
Stars: 383
Topics: 
README:
Example Uber app for developers
==============================

[![TravisCI](https://travis-ci.org/uber/Python-Sample-Application.svg?branch=master)](https://travis-ci.org/uber/Python-Sample-Application)
[![Coverage Status](https://coveralls.io/repos/uber/Python-Sample-Application/badge.png)](https://coveralls.io/r/uber/Python-Sample-Application)

https://developer.uber.com/

What Is This?
-------------

This is a simple Python/Flask application intended to provide a working example of Uber's external API. The goal of these endpoints is to be simple, well-documented and to provide a base for developers to develop other applications off of.


How To Use This
---------------

1. Navigate over to https://developer.uber.com/, and sign up for an Uber developer account.
2. Register a new Uber application and make your Redirect URI `http://localhost:7000/submit` - ensure that both the `profile` and `history` OAuth scopes are checked.
3. Fill in the relevant information in the `config.json` file in the root folder and add your client id and secret as the environment variables `UBER_CLIENT_ID` and `UBER_CLIENT_SECRET`.
4. Run `export UBER_CLIENT_ID="`*{your client id}*`"&&export UBER_CLIENT_SECRET="`*{your client secret}*`"`
5. Run `pip install -r requirements.txt` to install dependencies
6. Run `python app.py`
7. Navigate to http://localhost:7000 in your browser


Testing
-------

1. Install the dependencies with `make bootstrap`
2. Run the command `make test`
3. If you delete the fixtures, or decide to add some of your own, you’ll have to re-generate them, and the way this is done is by running the app, getting an auth_token from the main page of the app. Paste that token in place of the `test_auth_token` at the top of the `test_endpoints.py` file, then run the tests.


Development
-----------

If you want to work on this application we’d love your pull requests and tickets on GitHub!

1. If you open up a ticket, please make sure it describes the problem or feature request fully.
2. If you send us a pull request, make sure you add a test for what you added, and make sure the full test suite runs with `make test`.

Deploy to Heroku
----------------

Click the button below to set up this sample app on Heroku:

[![Deploy](https://www.herokucdn.com/deploy/button.png)](https://heroku.com/deploy)

After creating your app on Heroku, you have to configure the redirect URL for your Uber OAuth app. Use a `https://`*{your-app-name}*`.herokuapp.com/submit` URL.
You will also want to configure the heroku environment variable FLASK_DEBUG=False in order to properly serve SSL traffic.

Making Requests
---------------

The base for all requests is https://api.uber.com/v1/, to find a list of all available endpoints, please visit: https://developer.uber.com/v1/endpoints/



File: 582_Snowflake-Labs_sfguide-data-engineering-with-snowpark-python.txt
ID: 582
Full Name: Snowflake-Labs/sfguide-data-engineering-with-snowpark-python
Description: None
Created At: 2023-01-23T16:06:45Z
Updated At: 2024-11-16T18:16:54Z
Pushed At: 2024-10-10T18:57:47Z
Language: Python
URL: https://github.com/Snowflake-Labs/sfguide-data-engineering-with-snowpark-python
Forks: 3338
Stars: 113
Topics: 
README:
# Data Engineering Pipelines with Snowpark Python
This repository contains the code for the *Data Engineering Pipelines with Snowpark Python* Snowflake Quickstart.

### ➡️ For overview, prerequisites, and to learn more, complete this end-to-end tutorial [Data Engineering Pipelines with Snowpark Python](https://quickstarts.snowflake.com/guide/data_engineering_pipelines_with_snowpark_python/index.html?index=..%2F..index#0) on quickstarts.snowflake.com.

___
Here is an overview of what we'll build in this lab:

<img src="images/demo_overview.png" width=800px>



File: 597_Kartavec_python.txt
ID: 597
Full Name: Kartavec/python
Description: None
Created At: 2018-06-20T15:56:43Z
Updated At: 2023-01-31T17:01:29Z
Pushed At: 2024-07-04T15:59:44Z
Language: Python
URL: https://github.com/Kartavec/python
Forks: 75
Stars: 4
Topics: 
README:
# python


File: 599_reconSF_python.txt
ID: 599
Full Name: reconSF/python
Description: None
Created At: 2013-11-30T04:23:55Z
Updated At: 2024-11-24T05:37:40Z
Pushed At: 2013-11-30T04:24:50Z
Language: Python
URL: https://github.com/reconSF/python
Forks: 34
Stars: 66
Topics: 
README:



File: 608_CodementorIO_Python-Learning-Resources.txt
ID: 608
Full Name: CodementorIO/Python-Learning-Resources
Description: None
Created At: 2015-05-26T09:06:29Z
Updated At: 2024-11-30T12:36:28Z
Pushed At: 2024-01-31T18:19:44Z
Language: None
URL: https://github.com/CodementorIO/Python-Learning-Resources
Forks: 393
Stars: 1055
Topics: 
README:
# Awesome-Python
Python is an easy to learn language many beginners to coding choose as their first programming language and it is not limited to web development, as you can build games and applications for academical research with it. If you are new to programming or simply interested in learning Python, here are some resources you can use.

## Best Collection of Python Tutorials
  - Learning Guide- [Learn Python Online](https://www.codementor.io/learn-python-online)
  - Tutorial- [Python Tutorials for Beginners and Programmers](https://www.codementor.io/python/tutorial)

## Online Help
  - Online Experts- [1:1 Python Help from Proven Experts](https://www.codementor.io/python-experts)

## Platform for Python Tutorials
  - [Bucky's Room](https://buckysroom.org/videos.php?cat=98)
  - [Think Python](http://www.greenteapress.com/thinkpython/)
  - [Learn Python](http://www.learnpython.org/)
  - [Python for You and Me](http://pymbook.readthedocs.org/en/py3/)
  - [Learn Python the Hard Way](http://learnpythonthehardway.org/book/)
  - [edX Introduction to Computer Science and Programming Using Python] (https://www.edx.org/course/introduction-computer-science-mitx-6-00-1x-5)

## General Topics for Beginners
  - [Python Tutorials for Beginners and Programmers ](https://www.codementor.io/python/tutorial)
  - [Python Beginner Tutorial: for Loops and Iterators](https://www.codementor.io/python/tutorial/python-generators-and-iterators)
  - [Python 2.7 vs Python 3.4 ─ What should Python Beginners choose?](https://www.codementor.io/python/tutorial/python-2-7-vs-python-3-4)
  - [Wishful Coding in Python: A Problem Solving Philosophy](https://www.codementor.io/python/tutorial/wishful-coding-python-solving-big-problems)
  - [Introduction to Python Decorators](https://www.codementor.io/python/tutorial/introduction-to-decorators)
  - [Beginner's Guide to Debugging Python: Print Statements](https://www.codementor.io/python/tutorial/how-to-debug-python-code-beginners-print-line)
  - [How to Create Custom Exceptions in Python](https://www.codementor.io/python/tutorial/python-custom-exception)
  - [A SQLAlchemy Cheat Sheet](https://www.codementor.io/python/tutorial/understanding-sqlalchemy-cheat-sheet)
  - [Python Framework Comparison: Django vs. Pyramid](https://www.codementor.io/python/tutorial/django-vs-pyramid-python-framework-comparison)
  - [How to Set up NumPy on a 64 bit Windows OS](https://www.codementor.io/numpy/tutorial/installing-numpy-64-bit-windows)
  - [Python Q&A with #1 Stack Overflow Python Expert](https://www.codementor.io/python/tutorial/stack-overflow-python-expert-answers-questions)
  - [Stack Overflow Legend Martijn Pieters: Python Optimization and How it Can Affect Your Code](https://www.codementor.io/python/tutorial/stack-overflow-martijn-pieters-python-optimization)
  - [6 Useful Python Libraries Recommended by #1 Stack Overflow Answerer](https://www.codementor.io/python/tutorial/6-useful-python-libraries)
  - [Martijn Pieters on the Future of Django](https://www.codementor.io/python/tutorial/martijn-pieters-future-django)
  - [Python Internals: Codementor Office Hours with Martijn Pieters](https://www.codementor.io/python/tutorial/python-internals-codementor-office-hours-martijn-pieters)
  - [Building a Simple Snake Game with Python](https://www.codementor.io/python/tutorial/build-snake-game-using-curses)

## Data Science with Python
  - [Data Frames with Python & R](https://www.codementor.io/python/tutorial/python-vs-r-for-data-science-data-frames-i), [Part 2](https://www.codementor.io/python/tutorial/python-vs-r-data-science-data-frames-ii)
  - [Exploratory Data Analysis](https://www.codementor.io/python/tutorial/data-science-python-r-exploratory-data-analysis-visualization)
  - [Dimension Reduction & Clustering](https://www.codementor.io/python/tutorial/data-science-python-pandas-r-dimensionality-reduction)
  - [Sentiment Classification Using Linear Methods](https://www.codementor.io/python/tutorial/data-science-python-r-sentiment-classification-machine-learning)
  - [Building a Wine Review & Recommendation Site with Django](https://www.codementor.io/python/tutorial/get-started-with-django-building-recommendation-review-app), [Part 2](https://www.codementor.io/python/tutorial/build-data-product-django-user-management), [Part 3](https://www.codementor.io/python/tutorial/build-data-products-django-machine-learning-clustering-user-preferences)

## Python & Apache Spark
  - [Getting Data into the basic Spark data structure: Resilient Distributed Datasets](https://www.codementor.io/spark/tutorial/spark-python-rdd-basics), [Part 2](https://www.codementor.io/spark/tutorial/spark-python-data-aggregations)
  - [Machine Learning Library (MLlib) Basic Statistics & Exploratory Data Analysis](https://www.codementor.io/spark/tutorial/mllib-basic-statistics-exploratory-data-analysis)
  - [MLlib Logistic Regression](https://www.codementor.io/spark/tutorial/spark-mllib-logistic-regression)
  - [MLlib Decision Trees](https://www.codementor.io/spark/tutorial/spark-python-mllib-decision-trees)
  - [SQL & DataFrames](https://www.codementor.io/spark/tutorial/python-spark-sql-dataframes)
  - [Building a Movie Recommendation Service with Apache Spark & Flask](https://www.codementor.io/spark/tutorial/building-a-recommender-with-apache-spark-python-example-app-part1), [Part 2](https://www.codementor.io/spark/tutorial/building-a-web-service-with-apache-spark-flask-example-app-part2)

## Tips
  - [Creating An Asset Pipeline in Python](https://www.codementor.io/python/tutorial/creating-an-asset-pipeline-in-python-with-paver)
  - [Caching Angular Partials with Python](https://www.codementor.io/python/tutorial/html-optimization-caching-angularjs-partials-templates)
  - [How do I remove the first and last rows and columns from a 2D numpy array?](https://www.codementor.io/tips/2843378231/how-do-i-remove-the-first-and-last-rows-and-columns-from-a-2d-numpy-array)
  - [How to check keys in two levels loop? ](https://www.codementor.io/tips/6813274333/how-to-check-keys-in-two-levels-loop)
  - [Python array unpacking error: need more than 3 values ](https://www.codementor.io/tips/3317328246/python-array-unpacking-error-need-more-than-3-values)
  - [scheduling events with a while loop and time.sleep](https://www.codementor.io/tips/1344523786/scheduling-events-with-a-while-loop-and-time-sleep)
  - [Fetching an RSS feed and converting it into a json response](https://www.codementor.io/tips/3493772831/fetching-an-rss-feed-and-converting-it-into-a-json-response)
  - [Opencv: display contours](https://www.codementor.io/tips/4930721378/opencv-display-contours)
  - [Django form choices loaded from database are not updatedCan't figure out what's wrong with my method](https://www.codementor.io/tips/4933721348/can-t-figure-out-what-s-wrong-with-my-method)
  - [Different initial values in a Django formset](https://www.codementor.io/tips/0731824832/different-initial-values-in-a-django-formset)
  - [Why does python's struct think little-endian and big-endian imply different lengths?](https://www.codementor.io/tips/0818274433/why-does-python-s-struct-think-little-endian-and-big-endian-imply-different-lengths)
  - [Comparing two class types in python](https://www.codementor.io/tips/6130438872/comparing-two-class-types-in-python)
  - [How can I get Travis-CI to recognize and open external files during testing](https://www.codementor.io/tips/8102473038/how-can-i-get-travis-ci-to-recognize-and-open-external-files-during-testing)


## Videos
  - [Carte-Blanche, a Django Permission Framework for Rapid Prototyping, with its creator, Eric Neuman ](https://www.codementor.io/officehours/6962831504/carte-blanche-a-django-permission-framework-for-rapid-prototyping-with-its-creator-eric-neuman)
  - [Introduction to Machine Learning & NLP: Building a Spam Classifier](https://www.codementor.io/officehours/1385095426/building-a-spam-classifier)
  - [Stack Overflow Legend Martijn Pieters: Python Optimization and How it Can Affect Your Code](https://www.codementor.io/officehours/9015644327/stack-overflow-legend-martijn-pieters-python-optimization-and-how-it-can-affect-your-code)


## Documentations
  - [Python Documentations](https://www.python.org/doc/)

## Courses
  - [Live Python Class](https://www.codementor.io/classes/learn-python-live)
  - [MIT Introduction to Computer Science and Programming](http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-00sc-introduction-to-computer-science-and-programming-spring-2011/)
  - [Programming for Everybody (Python)](https://www.coursera.org/course/pythonlearn)
  - [Google's Python Class](https://developers.google.com/edu/python/?hl=de-DE&csw=1)
  - [Lynda.com](http://www.lynda.com/Python-training-tutorials/415-0.html)
  - [Intro to Computer Science](https://www.udacity.com/course/ud036)
  - [Code School's Try Python](https://www.codeschool.com/courses/try-python)


## Developer Tools
  - [PythonAnywhere](https://www.pythonanywhere.com/)
  - [PyDev](http://pydev.org/)
  - [PyCharm](http://www.jetbrains.com/pycharm/)
  - [Flake8Lint](https://github.com/dreadatour/Flake8Lint)
  - [WingWare Python IDE](https://wingware.com/)
  - [Pytest](http://pytest.org/latest/)
  - [Mock](http://www.voidspace.org.uk/python/mock/)
  - [PyLint](http://www.pylint.org/)
  - [Scrapy](http://scrapy.org/)
  - [Robobrowser](http://robobrowser.readthedocs.org/en/latest/)
  - [PyGame](http://pygame.org/news.html)




File: 611_Premalatha-success_Books-Python.txt
ID: 611
Full Name: Premalatha-success/Books-Python
Description: None
Created At: 2022-05-27T16:06:51Z
Updated At: 2024-08-03T10:29:54Z
Pushed At: 2022-05-28T03:38:02Z
Language: None
URL: https://github.com/Premalatha-success/Books-Python
Forks: 953
Stars: 59
Topics: 
README:



File: 616_NillionNetwork_nillion-python-starter.txt
ID: 616
Full Name: NillionNetwork/nillion-python-starter
Description: None
Created At: 2024-02-09T20:27:26Z
Updated At: 2024-11-26T16:28:47Z
Pushed At: 2024-11-21T12:34:57Z
Language: Python
URL: https://github.com/NillionNetwork/nillion-python-starter
Forks: 567
Stars: 432
Topics: 
README:
# Nillion Python Starter <a href="https://github.com/NillionNetwork/nillion-python-starter/blob/main/LICENSE"><img src="https://img.shields.io/badge/license-MIT-blue.svg"></a>

Welcome to the start of your Nillion developer journey.

This repo corresponds to the Nillion Python quickstart. To get started with Nillion head over to the [Python QuickStart docs](https://docs.nillion.com/python-quickstart) and follow the quickstart guide. 

For more python examples, check out https://github.com/NillionNetwork/python-examples which contains the following:
- core_concept_multi_party_compute
- core_concept_permissions
- core_concept_single_party_compute
- core_concept_store_and_retrieve_secrets
- millionaires_problem_example
- nada_programs
- voting_tutorial



File: 620_RockTeach_PythonCourse.txt
ID: 620
Full Name: RockTeach/PythonCourse
Description: None
Created At: 2017-12-16T05:05:59Z
Updated At: 2024-08-09T07:15:01Z
Pushed At: 2019-05-23T15:39:56Z
Language: None
URL: https://github.com/RockTeach/PythonCourse
Forks: 154
Stars: 150
Topics: python
README:
# Summary

## Course
课程内容请移步 <a href=https://github.com/jackfrued/Python-100-Days>Python100天</a>


## Welfare

* [科学上网](welfare/ke-xue-shang-wang.md)






File: 630_googleapis_python-bigquery.txt
ID: 630
Full Name: googleapis/python-bigquery
Description: None
Created At: 2019-12-10T00:09:04Z
Updated At: 2024-11-26T18:17:00Z
Pushed At: 2024-11-27T18:57:14Z
Language: Python
URL: https://github.com/googleapis/python-bigquery
Forks: 307
Stars: 746
Topics: 
README:
Python Client for Google BigQuery
=================================

|GA| |pypi| |versions|

Querying massive datasets can be time consuming and expensive without the
right hardware and infrastructure. Google `BigQuery`_ solves this problem by
enabling super-fast, SQL queries against append-mostly tables, using the
processing power of Google's infrastructure.

-  `Client Library Documentation`_
-  `Product Documentation`_

.. |GA| image:: https://img.shields.io/badge/support-GA-gold.svg
   :target: https://github.com/googleapis/google-cloud-python/blob/main/README.rst#general-availability
.. |pypi| image:: https://img.shields.io/pypi/v/google-cloud-bigquery.svg
   :target: https://pypi.org/project/google-cloud-bigquery/
.. |versions| image:: https://img.shields.io/pypi/pyversions/google-cloud-bigquery.svg
   :target: https://pypi.org/project/google-cloud-bigquery/
.. _BigQuery: https://cloud.google.com/bigquery/what-is-bigquery
.. _Client Library Documentation: https://googleapis.dev/python/bigquery/latest
.. _Product Documentation: https://cloud.google.com/bigquery/docs/reference/v2/

Quick Start
-----------

In order to use this library, you first need to go through the following steps:

1. `Select or create a Cloud Platform project.`_
2. `Enable billing for your project.`_
3. `Enable the Google Cloud BigQuery API.`_
4. `Setup Authentication.`_

.. _Select or create a Cloud Platform project.: https://console.cloud.google.com/project
.. _Enable billing for your project.: https://cloud.google.com/billing/docs/how-to/modify-project#enable_billing_for_a_project
.. _Enable the Google Cloud BigQuery API.:  https://cloud.google.com/bigquery
.. _Setup Authentication.: https://googleapis.dev/python/google-api-core/latest/auth.html

Installation
~~~~~~~~~~~~

Install this library in a `virtualenv`_ using pip. `virtualenv`_ is a tool to
create isolated Python environments. The basic problem it addresses is one of
dependencies and versions, and indirectly permissions.

With `virtualenv`_, it's possible to install this library without needing system
install permissions, and without clashing with the installed system
dependencies.

.. _`virtualenv`: https://virtualenv.pypa.io/en/latest/


Supported Python Versions
^^^^^^^^^^^^^^^^^^^^^^^^^
Python >= 3.7

Unsupported Python Versions
^^^^^^^^^^^^^^^^^^^^^^^^^^^
Python == 2.7, Python == 3.5, Python == 3.6.

The last version of this library compatible with Python 2.7 and 3.5 is
`google-cloud-bigquery==1.28.0`.


Mac/Linux
^^^^^^^^^

.. code-block:: console

    pip install virtualenv
    virtualenv <your-env>
    source <your-env>/bin/activate
    <your-env>/bin/pip install google-cloud-bigquery


Windows
^^^^^^^

.. code-block:: console

    pip install virtualenv
    virtualenv <your-env>
    <your-env>\Scripts\activate
    <your-env>\Scripts\pip.exe install google-cloud-bigquery

Example Usage
-------------

Perform a query
~~~~~~~~~~~~~~~

.. code:: python

    from google.cloud import bigquery

    client = bigquery.Client()

    # Perform a query.
    QUERY = (
        'SELECT name FROM `bigquery-public-data.usa_names.usa_1910_2013` '
        'WHERE state = "TX" '
        'LIMIT 100')
    query_job = client.query(QUERY)  # API request
    rows = query_job.result()  # Waits for query to finish

    for row in rows:
        print(row.name)

Instrumenting With OpenTelemetry
--------------------------------

This application uses `OpenTelemetry`_ to output tracing data from
API calls to BigQuery. To enable OpenTelemetry tracing in
the BigQuery client the following PyPI packages need to be installed:

.. _OpenTelemetry: https://opentelemetry.io

.. code-block:: console

    pip install google-cloud-bigquery[opentelemetry] opentelemetry-exporter-gcp-trace

After installation, OpenTelemetry can be used in the BigQuery
client and in BigQuery jobs. First, however, an exporter must be
specified for where the trace data will be outputted to. An
example of this can be found here:

.. code-block:: python

    from opentelemetry import trace
    from opentelemetry.sdk.trace import TracerProvider
    from opentelemetry.sdk.trace.export import BatchSpanProcessor
    from opentelemetry.exporter.cloud_trace import CloudTraceSpanExporter
    tracer_provider = TracerProvider()
    tracer_provider = BatchSpanProcessor(CloudTraceSpanExporter())
    trace.set_tracer_provider(TracerProvider())

In this example all tracing data will be published to the Google
`Cloud Trace`_ console. For more information on OpenTelemetry, please consult the `OpenTelemetry documentation`_.

.. _OpenTelemetry documentation: https://opentelemetry-python.readthedocs.io
.. _Cloud Trace: https://cloud.google.com/trace



File: 641_marcospereirampj_python-keycloak.txt
ID: 641
Full Name: marcospereirampj/python-keycloak
Description: None
Created At: 2019-06-04T11:26:27Z
Updated At: 2024-11-29T07:08:02Z
Pushed At: 2024-11-29T07:07:58Z
Language: Python
URL: https://github.com/marcospereirampj/python-keycloak
Forks: 304
Stars: 731
Topics: keycloak
README:
[![CircleCI](https://github.com/marcospereirampj/python-keycloak/actions/workflows/daily.yaml/badge.svg)](https://github.com/marcospereirampj/python-keycloak/)
[![Documentation Status](https://readthedocs.org/projects/python-keycloak/badge/?version=latest)](http://python-keycloak.readthedocs.io/en/latest/?badge=latest)

# Python Keycloak

**python-keycloak** is a Python package providing access to the Keycloak API.

## Installation

Install via PyPI:

`$ pip install python-keycloak`

## Bug reports

Please report bugs and feature requests at
https://github.com/marcospereirampj/python-keycloak/issues

## Documentation

The documentation for python-keycloak is available on [readthedocs](http://python-keycloak.readthedocs.io).

## Keycloak version support

The library strives to always support Keycloak's latest version. Additionally to that, we also support 5 latest major versions of Keycloak,
in order to give our user base more time for smoother upgrades.

Current list of supported Keycloak versions:

- 26.X
- 25.X
- 24.X
- 23.X
- 22.X

## Python version support

We only support Python versions that have active or security support by the Python Software Foundation. You can find the list of active Python versions [here](https://endoflife.date/python).

## Example of Using Keycloak OpenID

```python
from keycloak import KeycloakOpenID

# Configure client
keycloak_openid = KeycloakOpenID(server_url="http://localhost:8080/auth/",
                                 client_id="example_client",
                                 realm_name="example_realm",
                                 client_secret_key="secret")

# Get WellKnown
config_well_known = keycloak_openid.well_known()

# Get Code With Oauth Authorization Request
auth_url = keycloak_openid.auth_url(
    redirect_uri="your_call_back_url",
    scope="email",
    state="your_state_info")

# Get Access Token With Code
access_token = keycloak_openid.token(
    grant_type='authorization_code',
    code='the_code_you_get_from_auth_url_callback',
    redirect_uri="your_call_back_url")


# Get Token
token = keycloak_openid.token("user", "password")
token = keycloak_openid.token("user", "password", totp="012345")

# Get token using Token Exchange
token = keycloak_openid.exchange_token(token['access_token'], "my_client", "other_client", "some_user")

# Get Userinfo
userinfo = keycloak_openid.userinfo(token['access_token'])

# Refresh token
token = keycloak_openid.refresh_token(token['refresh_token'])

# Logout
keycloak_openid.logout(token['refresh_token'])
```

## Example of Using Keycloak Admin API

```python
from keycloak import KeycloakAdmin
from keycloak import KeycloakOpenIDConnection

keycloak_connection = KeycloakOpenIDConnection(
                        server_url="http://localhost:8080/",
                        username='example-admin',
                        password='secret',
                        realm_name="master",
                        user_realm_name="only_if_other_realm_than_master",
                        client_id="my_client",
                        client_secret_key="client-secret",
                        verify=True)

keycloak_admin = KeycloakAdmin(connection=keycloak_connection)

# Add user
new_user = keycloak_admin.create_user({"email": "example@example.com",
                                       "username": "example@example.com",
                                       "enabled": True,
                                       "firstName": "Example",
                                       "lastName": "Example"})

# Add user and raise exception if username already exists
# exist_ok currently defaults to True for backwards compatibility reasons
new_user = keycloak_admin.create_user({"email": "example@example.com",
                                       "username": "example@example.com",
                                       "enabled": True,
                                       "firstName": "Example",
                                       "lastName": "Example"},
                                      exist_ok=False)

# Add user and set password
new_user = keycloak_admin.create_user({"email": "example@example.com",
                                       "username": "example@example.com",
                                       "enabled": True,
                                       "firstName": "Example",
                                       "lastName": "Example",
                    "credentials": [{"value": "secret","type": "password",}]})
```

For more details, see the documentation available on [readthedocs](http://python-keycloak.readthedocs.io).



File: 643_selfteaching_selfteaching-python-camp.txt
ID: 643
Full Name: selfteaching/selfteaching-python-camp
Description: None
Created At: 2019-03-15T05:48:44Z
Updated At: 2024-09-06T05:34:12Z
Pushed At: 2023-06-14T06:02:16Z
Language: Python
URL: https://github.com/selfteaching/selfteaching-python-camp
Forks: 881
Stars: 147
Topics: 
README:
# 自学 Python 训练营

### 入门训练营

#### 基本介绍

> 所谓"自学"，就是"自己一个人（默默地）学" —— 这恰恰是绝大多数人一生学习失败的最根本原因。
训练营由 "新生大学" 联合 "糖果" 发起，针对基础相对薄弱，想要自学 Python 的人组织的训练营。

训练营期间由 `教研组` 规划学习路线、提供学习素材，`学员` 通过阅读、实践、交流等方式自学为主，遇到确实无法完成的难题会有专业的 `编程教练` 帮助解答，`辅导员` 会在整个过程中鼓励、推动，帮助学员完成整个训练。

#### 简单规则

1. 训练营每期 50 人，每 10 人一小组，每小组配备一名 `编程教练` 和一名 `辅导员`，周期为 14 天。
2. 训练营需缴纳保证金 + 服务费，具体定价会根据运营成本动态调整。
3. 每天 00:00 会发布当天 `学习材料` 和 `自学任务`，学员需要在 24:00 前完成。
4. 每天需要 `提交作业` 和 `学习总结打卡`，可获得 `星星`，通过积累 `星星` 到达合格标准以上，在结营时可全额返回保证金。
5. 每期会有10个名额针对 "新生大学会员" 推荐的在校高中生和在校大学生免收服务费。



[《自学 Python 入门训练营》报名入口](https://h5.youzan.com/v2/goods/2fo1zmvtzgvec)



File: 683_kiteco_python-youtube-code.txt
ID: 683
Full Name: kiteco/python-youtube-code
Description: None
Created At: 2020-02-11T18:04:32Z
Updated At: 2024-11-09T02:51:43Z
Pushed At: 2023-04-14T11:42:40Z
Language: Jupyter Notebook
URL: https://github.com/kiteco/python-youtube-code
Forks: 555
Stars: 339
Topics: 
README:
# Kite's Youtube Code Repo

You can find all the code associated with our Youtube Channel here. You can use the code here to follow along the videos from our Youtube Channel (https://www.youtube.com/channel/UCxVRDu9ujwOrmDxu72V3ujQ).

* [Hangman with Python](https://www.youtube.com/watch?v=m4nEnsavl6w) - https://github.com/kiteco/python-youtube-code/tree/master/build-hangman-in-python
* [Twitter API](https://www.youtube.com/watch?v=EAvEa5fLwRA) - https://github.com/kiteco/python-youtube-code/tree/master/Twitter-api-geolocator
* [Baby Yoda Webscraping](youtube.com) - https://github.com/kiteco/python-youtube-code/tree/master/Webscraping-baby-yoda-with-requests-and-bs4
* [1 Day Builds - Discord Bot](youtube.com) - https://github.com/kiteco/python-youtube-code/tree/master/one-day-build-discord-bot
* [5 Minute Coding Interview Bootcamp - Basic Algorithms](youtube.com) - https://github.com/kiteco/python-youtube-code/tree/master/5-minute-coding-interview-bootcamp-basic-algorithms

# What is Kite?

Kite is an AI-powered programming assistant that helps you write Python code in your code editor. Kite helps you write code faster by showing you the right information at the right time. Learn more about how Kite heightens VS Code's capabilities at https://kite.com/.

At a high level, Kite provides you with:
* 🧠 __[Line-of-Code Completions](https://kite.com/blog/product/launching-line-of-code-completions-going-cloudless-and-17-million-in-funding/)__ powered by machine learning models trained on the entire open source code universe
* 📝 __[Intelligent Snippets](https://kite.com/blog/product/announcing-intelligent-snippets-for-python/)__ that automatically provide context-relevant code snippets for your function calls
* 🔍 __[Instant documentation](https://kite.com/copilot/)__ for the symbol underneath your cursor so you save time searching for Python docs

## Installation

### Installing the Kite Engine

The [Kite Engine](https://kite.com/) needs to be installed in order for the package to work properly. The package itself
provides the frontend that interfaces with the Kite Engine, which performs all the code analysis and machine learning 100% locally on your computer (no code is sent to a cloud server).

__macOS Instructions__
1. Download the [installer](https://kite.com/download/) and open the downloaded `.dmg` file.
2. Drag the Kite icon into the `Applications` folder.
3. Run `Kite.app` to start the Kite Engine.

__Windows Instructions__
1. Download the [installer](https://kite.com/download/) and run the downloaded `.exe` file.
2. The installer should run the Kite Engine automatically after installation is complete.

__Linux Instructions__
1. Visit https://kite.com/linux/ to install Kite.
2. The installer should run the Kite Engine automatically after installation is complete.

## Usage

The following is a brief guide to using Kite in its default configuration.

### Hover

Hover your mouse cursor over a symbol to view a short summary of what the symbol represents.

![hover](https://s3.amazonaws.com/helpscout.net/docs/assets/589ced522c7d3a784630c348/images/5c3eb72c2c7d3a3194501270/file-LaHSHhYTkH.png)

### Documentation

Click on the `Docs` link in the hover popup to open the documentation for the symbol inside the Copilot, Kite's standalone
reference tool.

![copilot](https://github.com/kiteco/atom-plugin/blob/master/docs/images/copilot.png?raw=true)

### Definitions

If a `Def` link is available in the hover popup, clicking on it will jump to the definition of the symbol.

### Autocompletions

Simply start typing in a saved Python file and Kite will automatically suggest completions for what you're typing. Kite's
autocompletions are all labeled with the `⟠` symbol.

![completions](https://s3.amazonaws.com/helpscout.net/docs/assets/589ced522c7d3a784630c348/images/5c3eb54f04286304a71e4292/file-jJZznGIq2t.png)

### Function Signatures

When you call a function, Kite will show you the arguments required to call it. Kite's function signatures are also all
labeled with the `⟠` symbol.

![signature](https://s3.amazonaws.com/helpscout.net/docs/assets/589ced522c7d3a784630c348/images/5c3eb6ad2c7d3a319450126e/file-j1bl9zETcx.png)

> __Note:__ If you have the Microsoft Python extension installed, Kite will _not_ be able to show you information on
> function signatures.

### Commands

Kite comes with sevaral commands that you can run from VS Code's command palette.

|Command|Description|
|:---|:---|
|`kite.open-copilot`|Open the Copilot|
|`kite.docs-at-cursor`|Show documentation of the symbol underneath your cursor in the Copilot|
|`kite.engine-settings`|Open the settings for the Kite Engine|
|`kite.help`|Open Kite's help website in the browser|


## Contact Us

Feel free to contact us with bug reports, feature requests, or general comments at feedback@kite.com.

Happy coding!


---

#### About Kite

Kite is built by a team in San Francisco devoted to making programming easier and more enjoyable for all. Follow Kite on
[Twitter](https://twitter.com/kitehq) and get the latest news and programming tips on the
[Kite Blog](https://kite.com/blog/).
Kite has been featured in [Wired](https://www.wired.com/2016/04/kites-coding-asssitant-spots-errors-finds-better-open-source/), 
[VentureBeat](https://venturebeat.com/2019/01/28/kite-raises-17-million-for-its-ai-powered-developer-environment/), 
[The Next Web](https://thenextweb.com/dd/2016/04/14/kite-plugin/), and 
[TechCrunch](https://techcrunch.com/2019/01/28/kite-raises-17m-for-its-ai-driven-code-completion-tool/). 



File: 695_omercengiz_PythonCourse.txt
ID: 695
Full Name: omercengiz/PythonCourse
Description: None
Created At: 2020-11-26T11:24:55Z
Updated At: 2024-08-24T18:04:56Z
Pushed At: 2023-11-05T10:51:18Z
Language: Jupyter Notebook
URL: https://github.com/omercengiz/PythonCourse
Forks: 156
Stars: 102
Topics: 
README:
# Welcome to our Introduction to Python Programming Course Repo!

## Syllabus

### [Lesson 0](https://github.com/omercengiz/PythonCourse/blob/master/Day0.ipynb)
- What is Python?
- Version Control
- Comments
- Variables
- Data Types
- Arithmetic Operations
- Logical Operations

### [Lesson 1](https://github.com/omercengiz/PythonCourse/blob/master/Day1.ipynb)
- Type Conversion
- Indexing and Slicing on Strings
- Lists

### [Lesson 2](https://github.com/omercengiz/PythonCourse/blob/master/Day2.ipynb)
- If Conditions
- While Loop
- For Loop

### [Lesson 3](https://github.com/omercengiz/PythonCourse/blob/master/Day3.ipynb)
- Dictionaries
- Sets
- Tuples

### [Lesson 4](https://github.com/omercengiz/PythonCourse/blob/master/Day4.ipynb)
- Functions
- Return Statements
- Lambda Function
- *args and **kwargs
- Modules


### [Lesson 5](https://github.com/omercengiz/PythonCourse/blob/master/Day5.ipynb)
- Try-Except
- Introduction to OOP
- Introduction to NumPy








File: 707_tongzm_ml-python.txt
ID: 707
Full Name: tongzm/ml-python
Description: None
Created At: 2018-09-07T06:16:50Z
Updated At: 2024-11-11T03:32:33Z
Pushed At: 2024-05-21T02:41:03Z
Language: Jupyter Notebook
URL: https://github.com/tongzm/ml-python
Forks: 344
Stars: 376
Topics: 
README:
# ml-python


File: 727_zacharski_pg2dm-python.txt
ID: 727
Full Name: zacharski/pg2dm-python
Description: None
Created At: 2015-07-01T22:14:38Z
Updated At: 2024-12-02T05:53:33Z
Pushed At: 2020-10-01T04:28:41Z
Language: Python
URL: https://github.com/zacharski/pg2dm-python
Forks: 482
Stars: 878
Topics: 
README:
# pg2dm-python

Python code for the free book [A Programmer's Guide to Data Mining](http://guidetodatamining.com)


File: 783_LordPouic_Python.txt
ID: 783
Full Name: LordPouic/Python
Description: None
Created At: 2020-10-07T08:24:48Z
Updated At: 2024-11-23T19:56:21Z
Pushed At: 2024-10-29T08:04:44Z
Language: None
URL: https://github.com/LordPouic/Python
Forks: 47
Stars: 18
Topics: 
README:



File: 789_learn-co-students_python-variables-readme-data-science-intro-000.txt
ID: 789
Full Name: learn-co-students/python-variables-readme-data-science-intro-000
Description: None
Created At: 2018-04-10T20:07:19Z
Updated At: 2024-11-17T16:08:55Z
Pushed At: 2019-06-20T13:43:57Z
Language: Jupyter Notebook
URL: https://github.com/learn-co-students/python-variables-readme-data-science-intro-000
Forks: 8693
Stars: 10
Topics: 
README:

# Naming things with Variables

### Introduction

> "There are only two hard things in Computer Science: cache invalidation and naming things."

> -- Phil Karlton

> "...But ordinary language is all right."

> Ludwig Wittgenstein

### Objectives

* Learn about how to use variables to give meaning to data
* Learn how to assign a variable to data
* Learn how to declare a variable
* Learn how to reassign a variable

### Declaring and Assigning Variables

So far we have worked with data -- strings, numbers, and booleans.  In this lesson, we'll learn how to use variables to assign names to this data.  For example, this is a string from our Working with **Data Types Lab**.


```python
"art vandelay"
```




    'art vandelay'



Now months later, if we see that string in some code, we may be confused as to what it is, and with even more data, this only becomes more difficult. Think of what we saw in our **Data Types Lab**: `"art.vandelay@vandelay.co"`, `"Ceo"`, `"7285553334"`, `"vandelay.com"`. There's a lot to keep track of.

So, let's use variables to indicate what each of these strings mean.


```python
email = "art.vandelay@vandelay.co"
```

> **Note:** For this, and all of the subsequent code in gray boxes, you should press shift + enter to ensure that the code executes. If you do not do so with the line above for example, then when we reference `email` in the lines that follow, Jupyter will throw an error indicating that the variable is undefined. So, it is not enough to just type the correct code, we need to run shift + enter on our gray boxes to run this code.

In programming terms, we say that we just declared a variable, `email`, and assigned it to the string, `"art.vandelay@vandelay.co"`.  To do so, we'll follow the procedure below:

    variable = data

Now that we have assigned a variable `email` to a string, we just type the word `email` to see the string again.


```python
email
```

> *remember to press shift + enter on the gray box above to see the value of our variable, *`email`*.*

Now let's try this with the website:


```python
website = "vandelay.com"
website
```

Note that if you introduce a new variable, (declare it), but do not also assign it in the same line, Python will raise an error.


```python
name
```


    ----------------------------------------------------------

    NameError                Traceback (most recent call last)

    <ipython-input-6-9bc0cb2ed6de> in <module>()
    ----> 1 name


    NameError: name 'name' is not defined


So that error tells us that `name` is not defined.  We just fix this by declaring `name` and assigning the variable in the same line.


```python
name = 'Art Vandelay'
name
```

So this is assigning and reading a variable.  And when we want to see some information again, we can easily find out.


```python
email
```

### Declaring variables without assignment

We have seen that we can have data without assigning it to variables.  


```python
"Unassigned data"
```




    'Unassigned data'



Sometimes we wish to declare a variable without assigning it to data.  In Python, that's a little tricky to do.  As we just saw with `name`, declaring variables without assignment throws an error.  Thankfully, Python has a special type for us that represents nothing at all.


```python
None
```


```python
type(None)
```




    NoneType



None is a data type in Python that represents nothing.  So, if we do not know the type of a variable and want to have the data to the variable be assigned later, we can assign that variable to `None`.


```python
address = None
```

Notice that `address` is now assigned, but it is assigned to `None`.


```python
address
```

**Note:** *when variables are assigned to `None`, pressing shift + enter on the cell block will not output anything.*

### Reassigning variables

Now that we have this data, we can imagine using it for some kind of instruction.  For example, say we want to write ourself a memo on how to reach out to someone we just met. Here's the message:


```python
"Send an email to Art Vandelay at 'art.vandelay@vandelay.com' to say how nice it was meeting yesterday."
```

If we construct this message with variables, we can write the following:


```python
name = "Art Vandelay"
email = "art.vandelay@vandelay.com"
```


```python
"Send an email to " + name + " at " + email +  " to say how nice it was meeting yesterday."
```

Now you meet someone else, "Liz Kaplan" with the email of "liz@ka-plan.com" and want to write a memo with the same instructions, but the only thing that varies are the name and email. This should be easy enough given the way we set up our memo above. First we need to change the variables, `name` and `email`, by setting them to our new data.


```python
name = 'Liz Kaplan'
email = 'liz@ka-plan.com'
```

So as you can see, we reassign our variables by just setting `variable = 'new data'`. Presto, our variable is then updated.


```python
name # 'Liz Kaplan'
```


```python
email # 'liz@ka-plan.com'
```

Now, if we copy and re-run our previous code, we will see it is automatically updated.


```python
"Send an email to " + name + " at " + email +  " to say how nice it was meeting yesterday."
```

So in the line above, we are getting to some of the real power of programming.  By choosing the correct variable name, we can begin to change the values of `name` or `email` and operate on their underlying values in the same ways.

### Operating on variables

Just to hammer this point home let's see what we can now do with the name variable.


```python
name
```


```python
name.upper()
```


```python
name.title()
```

Just like how we are able to directly call methods on a string, we can also call methods on a variable that points to a string.  And, if we try to call a method on something that we think is a string, but really is a number, we will see an error.


```python
name = 42
```


```python
name.upper()
```

We receive the same error from calling `upper` directly on the number `42` as we do when we call `upper` on a variable that points to the number `42`. So, now that we are working with variables, we may run into errors where we thought a variable is one thing, but it is actually something else. Don't worry, this is no big deal.  We can just check to see what the variable is.


```python
name
```

Once we have see what the variable is, we can make our change.


```python
name = 'Liz Kaplan'
name
```

### Summary

In this lesson, we got a taste for what makes computer programs so powerful.  By using variables, we can write programs that know how to combine data.  This can save us time by avoiding boring, repetitive tasks.  We declare and assign a variable with the pattern of `variable = data`, and reassign a variable with the same pattern.  To reference a variable, we simply type the variable's name.  

We also saw that one of the things to pay attention to when working with variables is that they are sometimes different from what we expect.  So we just type the name of the variable, to see what it really is and make any necessary changes.



File: 792_davidbombal_python-keylogger.txt
ID: 792
Full Name: davidbombal/python-keylogger
Description: None
Created At: 2022-08-02T12:11:51Z
Updated At: 2024-11-26T20:48:19Z
Pushed At: 2022-08-17T07:58:13Z
Language: Python
URL: https://github.com/davidbombal/python-keylogger
Forks: 235
Stars: 669
Topics: 
README:
# Simple Python Keylogger with Pynput. Sending data to a server.

## This code DOES NOT promote or encourage any illegal activities! The content in this document is provided solely for educational purposes and to create awareness!



## This is a proof of concept and could be improved on in a lot of ways.



1. To run this code use `git clone https://github.com/davidbombal/python-keylogger.git`

2. Run the command `cd python-keylogger`

3. Create Virtual Environment in Windows. Using command `<python_path>\py -m venv keylogger_env`

4. Run command `keylogger_env\Scripts\activate`

5. Run the command `pip install -r requirements.txt` to install all the packages required in your virtual environment.

6. Run `py keylogger.py` this will run the program.



### To get the file to run on Windows 11 evading the antivirus I compiled the PyInstaller bootloader locally using Microsoft C/C++ compiler, and then used it to compile the code.




File: 820_techwithtim_Python-Platformer.txt
ID: 820
Full Name: techwithtim/Python-Platformer
Description: None
Created At: 2022-11-03T01:12:38Z
Updated At: 2024-11-27T21:23:51Z
Pushed At: 2024-10-17T13:31:25Z
Language: Python
URL: https://github.com/techwithtim/Python-Platformer
Forks: 347
Stars: 246
Topics: 
README:
# Python-Platformer

# 💻 Launch Your Software Development Career Today!  

🎓 **No degree? No problem!** My program equips you with everything you need to break into tech and land an entry-level software development role.  

🚀 **Why Join?**  
- 💼 **$70k+ starting salary potential**  
- 🕐 **Self-paced:** Complete on your own time  
- 🤑 **Affordable:** Low risk compared to expensive bootcamps or degrees
- 🎯 **45,000+ job openings** in the market  

👉 **[Start your journey today!](https://techwithtim.net/dev)**  
No experience needed—just your determination. Future-proof your career and unlock six-figure potential like many of our students have!  



File: 840_learn-co-students_python-lists-readme-data-science-intro-000.txt
ID: 840
Full Name: learn-co-students/python-lists-readme-data-science-intro-000
Description: None
Created At: 2018-04-10T20:07:19Z
Updated At: 2024-11-17T16:08:58Z
Pushed At: 2021-04-08T09:41:19Z
Language: Jupyter Notebook
URL: https://github.com/learn-co-students/python-lists-readme-data-science-intro-000
Forks: 7183
Stars: 11
Topics: 
README:

# Introduction to lists

So far, we have worked with individual pieces of data like the string `'hello'`. Then with variables we saw how to give this data a name.  Now in this lesson, we'll see how we can group data together with lists.  

### Creating a list 

A list is our first form of a collection.  A collection is just a way of grouping data together, and lists certainly accomplish this.  For example, let's consider the top cities for travel according to the magazine Travel and Leisure. Here is how we are used to seeing a list of travel locations in a document or on a website.

#### Travel Locations
1. Solta
2. Greenville
3. Buenos Aires
4. Los Cabos
5. Walla Walla Valley
6. Marakesh
7. Albuquerque
8. Archipelago Sea
9. Iguazu Falls
10. Salina Island
11. Toronto
12. Pyeongchang

Here is what that list looks like as a Python `list`:


```python
['Solta', 'Greenville', 'Buenos Aires', 'Los Cabos', 'Walla Walla Valley', 'Marakesh', 'Albuquerque', 'Archipelago Sea', 'Iguazu Falls', 'Salina Island', 'Toronto', 'Pyeongchang']
```




    ['Solta',
     'Greenville',
     'Buenos Aires',
     'Los Cabos',
     'Walla Walla Valley',
     'Marakesh',
     'Albuquerque',
     'Archipelago Sea',
     'Iguazu Falls',
     'Salina Island',
     'Toronto',
     'Pyeongchang']



We indicate that we are initializing a `list` with an opening bracket, `[`, and we end the list with a closing bracket `]`. We separate each list item, also called an element, with a comma.


```python
['Croatia', 'USA', 'Argentina', 'Mexico', 'USA', 'Morocco', 'New Mexico', 'Finland', 'Argentina', 'Italy', 'Canada', 'South Korea']
```




    ['Croatia',
     'USA',
     'Argentina',
     'Mexico',
     'USA',
     'Morocco',
     'New Mexico',
     'Finland',
     'Argentina',
     'Italy',
     'Canada',
     'South Korea']



We can, of course, declare variables and set them equal to our lists so that we can both name and later retrieve the list.


```python
top_travel_cities = ['Solta', 'Greenville', 'Buenos Aires', 'Los Cabos', 'Walla Walla Valley', 'Marakesh', 'Albuquerque', 'Archipelago Sea', 'Iguazu Falls', 'Salina Island', 'Toronto', 'Pyeongchang']
```


```python
top_travel_cities
```




    ['Solta',
     'Greenville',
     'Buenos Aires',
     'Los Cabos',
     'Walla Walla Valley',
     'Marakesh',
     'Albuquerque',
     'Archipelago Sea',
     'Iguazu Falls',
     'Salina Island',
     'Toronto',
     'Pyeongchang']




```python
countries_of_top_cities = ['Croatia', 'USA', 'Argentina', 'Mexico', 'USA', 'Morocco', 'New Mexico', 'Finland', 'Argentina', 'Italy', 'Canada', 'South Korea']
```

### Accessing Elements of Lists

Now our `top_travel_cities` list contains multiple elements, and just like we are used to list elements having a rank or number associated with them...

1. Solta
2. Greenville
3. Buenos Aires

...a list in Python also assigns a number to each element.


```python
top_travel_cities
```




    ['Solta',
     'Greenville',
     'Buenos Aires',
     'Los Cabos',
     'Walla Walla Valley',
     'Marakesh',
     'Albuquerque',
     'Archipelago Sea',
     'Iguazu Falls',
     'Salina Island',
     'Toronto',
     'Pyeongchang']




```python
top_travel_cities[0]
```




    'Solta'



In the above line we are referencing a list and then using the brackets to access a specific element of our list, the first element.  We access elements in a list with the `index`, and there is a separate index for each element in the list.  It begins at the number zero, increases for every element thereafter.

So to access the second element we write `top_travel_cities[1]`, and the third element is `top_travel_cities[2]`.


```python
top_travel_cities[2]
```




    'Buenos Aires'



How would we access the last element?  Well, we could count all of the elements in the list, and `Pyeongchang` would just be one less than that. Or we can ask Python to start from the end and move back one:


```python
top_travel_cities[-1]
```




    'Pyeongchang'



And we can move back as many as we want.


```python
top_travel_cities[-2]
```




    'Toronto'



Each element in our list is a string, so, we can always set an element of our string equal to a variable.


```python
top_canadian_city = top_travel_cities[-2]
top_canadian_city
```




    'Toronto'




```python
type(top_canadian_city)
```




    str



Now we have a variable of `top_canadian_city`, equal to the string 'Toronto', and a variable of `top_travel_cities` equal to the list of cities.  


```python
top_travel_cities
```




    ['Solta',
     'Greenville',
     'Buenos Aires',
     'Los Cabos',
     'Walla Walla Valley',
     'Marakesh',
     'Albuquerque',
     'Archipelago Sea',
     'Iguazu Falls',
     'Salina Island',
     'Toronto',
     'Pyeongchang']




```python
type(top_travel_cities)
```




    list



### Accessing Multiple Elements

Now imagine that we don't want to access just one element of a list, but multiple elements at once.  Python allows us to do that as well:


```python
top_travel_cities[0:2]
```




    ['Solta', 'Greenville']



As we can see from the above example, we can access elements of a list by placing two numbers separated by a colon inside of our brackets. The first number indicates the index of the first element we want returned.  

The second number could represent the number of elements we want returned back, or maybe it represents the stopping index of the elements that we are retrieving.  Looking at our `top_travel_cities` it could be either.


```python
top_travel_cities
```




    ['Solta',
     'Greenville',
     'Buenos Aires',
     'Los Cabos',
     'Walla Walla Valley',
     'Marakesh',
     'Albuquerque',
     'Archipelago Sea',
     'Iguazu Falls',
     'Salina Island',
     'Toronto',
     'Pyeongchang']



Let's try a different experiment to answer our question.


```python
top_travel_cities[4:5]
```




    ['Walla Walla Valley']



Ok, so that second number is not representing the number of elements we want returned.  Instead it must be the index at which we stop our selection of elements.


```python
top_travel_cities[4:6]
```




    ['Walla Walla Valley', 'Marakesh']



This operation is called `slice`.  So, we can say we are `slicing` the elements with indices 4 and 5 in the line above.  Note that even though we are `slicing` elements, our list remains intact.


```python
top_travel_cities
```




    ['Solta',
     'Greenville',
     'Buenos Aires',
     'Los Cabos',
     'Walla Walla Valley',
     'Marakesh',
     'Albuquerque',
     'Archipelago Sea',
     'Iguazu Falls',
     'Salina Island',
     'Toronto',
     'Pyeongchang']



In programming terms, we would say that slicing elements is non-destructive, because it does not change the underlying data structure.  We can do it as many times as we like, and our `top_travel_cities` array remains unchanged.  If we wish to store that slice of elements, we can store it in another variable.


```python
top_two = top_travel_cities[0:2]
top_two
```




    ['Solta', 'Greenville']



Now we have another variable called `top_two` that points to an array which contains an array of elements equal to the first two elements of `top_travel_cities`.

### Changing elements with destructive methods

Now that we can read and select certain elements from lists, let's work on changing these lists. To add a new element to a list, we can use the `append` method.


```python
top_travel_cities.append('San Antonio')
```

Now let's take another look at `top_travel_cities`.


```python
top_travel_cities
```




    ['Solta',
     'Greenville',
     'Buenos Aires',
     'Los Cabos',
     'Walla Walla Valley',
     'Marakesh',
     'Albuquerque',
     'Archipelago Sea',
     'Iguazu Falls',
     'Salina Island',
     'Toronto',
     'Pyeongchang',
     'San Antonio']



You will see that 'San Antonio' has been added to the list.  Note that unlike slice, `append` is destructive.  That is, it changes our underlying data structure.  Every time we execute the `append` method, another element is added to our list.   Now what if we accidentally add 'San Antonio' a second time to our list.


```python
top_travel_cities.append('San Antonio')
top_travel_cities
```




    ['Solta',
     'Greenville',
     'Buenos Aires',
     'Los Cabos',
     'Walla Walla Valley',
     'Marakesh',
     'Albuquerque',
     'Archipelago Sea',
     'Iguazu Falls',
     'Salina Island',
     'Toronto',
     'Pyeongchang',
     'San Antonio',
     'San Antonio']



If you press shift+enter on the above line of code, we will have `'San Antonio'` as the last two elements of the list.  Luckily, we have the `pop` method to remove one of them.  The `pop` method is available to call on any list and removes the last element from the list. As you can see below, calling `pop` removed our last element.


```python
top_travel_cities.pop()
```




    'San Antonio'



Now if we want to change an element from the middle of the list, we can access and then reassign that element. For example, let's change 'Walla Walla Valley' to the number 4.


```python
top_travel_cities[4]
```




    'Walla Walla Valley'




```python
top_travel_cities[4] = 4
```


```python
top_travel_cities
```




    ['Solta',
     'Greenville',
     'Buenos Aires',
     'Los Cabos',
     4,
     'Marakesh',
     'Albuquerque',
     'Archipelago Sea',
     'Iguazu Falls',
     'Salina Island',
     'Toronto',
     'Pyeongchang',
     'San Antonio']



Our list is changed, but now it's not as sensible, so let's change it back.


```python
top_travel_cities[4] = 'Walla Walla Valley'
```

With that, our list is back to the way we like it.


```python
top_travel_cities
```




    ['Solta',
     'Greenville',
     'Buenos Aires',
     'Los Cabos',
     'Walla Walla Valley',
     'Marakesh',
     'Albuquerque',
     'Archipelago Sea',
     'Iguazu Falls',
     'Salina Island',
     'Toronto',
     'Pyeongchang',
     'San Antonio']



### Finding Unique elements and length of lists

If we are not sure whether there are repeated elements, we can use Python to get a unique list.


```python
top_travel_cities.append('Solta')
```

For example, now that we have added Solta to the end of our list, Solta appears twice.

Well to see a unique list of the elements, we can call the `set` function. The set function is non-destructive on our list.


```python
unique_travel_cities = set(top_travel_cities)
unique_travel_cities
```




    {'Albuquerque',
     'Archipelago Sea',
     'Buenos Aires',
     'Greenville',
     'Iguazu Falls',
     'Los Cabos',
     'Marakesh',
     'Pyeongchang',
     'Salina Island',
     'San Antonio',
     'Solta',
     'Toronto',
     'Walla Walla Valley'}



The set function initializes a new set in Python.  A set is a different type collection in Python.  


```python
type(set())
```




    set



A set is just like a list, except elements do not have order and each element appears just once.


```python
unique_travel_cities[1]
```


    -------------------------------------------------------------------

    TypeError                         Traceback (most recent call last)

    <ipython-input-26-3d2453cad46e> in <module>()
    ----> 1 unique_travel_cities[1]
    

    TypeError: 'set' object does not support indexing


 So here, when we convert our list into a set, our set just consists of the unique elements.  But unfortunately this structure is a set, not a list.


```python
type(unique_travel_cities)
```




    set



So let's convert this set, which has a unique list of our travel cities, into a list.


```python
unique_travel_cities = list(unique_travel_cities)
```


```python
type(unique_travel_cities)
```




    list



So the array of `unique_travel_cities` is a unique list.


```python
unique_travel_cities
```




    ['Toronto',
     'Archipelago Sea',
     'Iguazu Falls',
     'Pyeongchang',
     'Los Cabos',
     'Buenos Aires',
     'Marakesh',
     'Greenville',
     'Albuquerque',
     'Salina Island',
     'Walla Walla Valley',
     'San Antonio',
     'Solta']



And you can see quickly that it differs from the list of top travel cities by checking the length.


```python
len(unique_travel_cities)
```




    13




```python
len(top_travel_cities)
```




    14




```python
top_travel_cities
```




    ['Solta',
     'Greenville',
     'Buenos Aires',
     'Los Cabos',
     'Walla Walla Valley',
     'Marakesh',
     'Albuquerque',
     'Archipelago Sea',
     'Iguazu Falls',
     'Salina Island',
     'Toronto',
     'Pyeongchang',
     'San Antonio',
     'Solta']



> **Note:** *For most purposes, Python developers prefer to work with `lists` as opposed to sets, as `lists` are generally easier to manipulate, as you will see in future lessons.*

### Summary

In this section we saw how to associate data together in a collection, called a list.  A list is similar to a list in the real world - it implies the data has some connection, and that it has an order to it.  We initialize a list with the brackets, `[]`, and separate each element by a comma.  To access elements from a list, we use the bracket accessor followed by the index of the element we want to retrieve, and our indices begin at zero and increase from there. To add a new element to the end of the list we use the `append` method, and to remove an element from the end of a list we use `pop`. We can change elements anywhere between by first accessing the elements and then reassigning them.



File: 846_learn-co-students_python-practice-with-datatypes-data-science-intro-000.txt
ID: 846
Full Name: learn-co-students/python-practice-with-datatypes-data-science-intro-000
Description: None
Created At: 2018-04-10T20:07:19Z
Updated At: 2024-11-17T16:08:10Z
Pushed At: 2021-10-13T07:04:43Z
Language: Jupyter Notebook
URL: https://github.com/learn-co-students/python-practice-with-datatypes-data-science-intro-000
Forks: 9627
Stars: 13
Topics: 
README:

# Practice with Data Types

## Introduction

In the past few lessons, you learned about working with different types of data in Python: strings, numbers (ints and floats), and booleans.  Now, you'll put that knowledge into action.

Imagine that you're at a business event and exchanged business cards with a few people. One of the business cards belongs to Art Vandelay, a new travel agent. Here, you'll use your programming skills to format this information correctly.  

## Learning Objectives
* Manipulate strings with built-in methods
* Practice coercing data types and changing numbers

## Here to mingle 

The next morning you take out the business card, ready to format it using your programming skills, and here is what we find.

![](https://learn-verified.s3.amazonaws.com/data-science-assets/biz-card-mistakes.jpg)

## String Transformations

When storing text in a spreadsheet or database programmatically, you will often preprocess the data to ensure that it is properly formatted. For example, you might ensure that a telephone number matches the required format, or that a field on a web form is filled out. 

Here's a simple example of how you might go about doing this:


```python
name = "art vandelay" # "ART VANDELAY"
name.upper()
```

If you haven't already, put your cursor into the cell above and press `shift + enter` to run the code in the cell. You should see an updated output produced by the `.upper()` string method. 

Another important note is the hashtag `#`. In python, hashtags indicate a comment. Comments are notes used to provide additional information but are ignored by the computer when running the code. 


```python
'hello' ### whattttt
```

After pressing shift+enter on the cell above, you'll see that Python ignores the comment. In Flatiron coding labs, a comment will be provided to indicate what you are aiming to have the code return. This allows you to then easily check your answer upon running your code.

## Get going with strings

With that, use the appropriate string method to transform each string to match the desired output in the comment.

Use the `title` method to capitalize the first letter of each word in "art vandelay"`.


```python
"art vandelay" # 'Art Vandelay'
```

Now use the `upper` method to capitalize all of the letters of "Ceo".


```python
"Ceo" # 'CEO'
```

Next, write a method that verifies whether an email addresses is valid. To make this introductory example simple, assume that every email address should end with ".com".  With that, use your knowledge of string methods to check if the email address ends with ".com" and return `True` or `False` accordingly. 


```python
"art.vandelay@vandelay.co" # False
```

As you can see below, the website "vandelay.com" is not preceded by `"www."`. You can perform string concatenation to fix this! string concatenation allows you to join two strings. It works just like numerical addition. For example, ```"This is the start" + "and this is the end"``` would return ```"This is the start and this is the end"```. Use string concatenation to change the website `'vandelay.com'` to the string `'www.vandelay.com'` by prepending `'www.'`.


```python
'vandelay.com' # 'www.vandelay.com'
```

## String Slicing

Finally, Mr. Vandelay gave us his phone number. Extract the area code by selecting the first three characters of the string. You can do this using brackets to select characters from the string as in ```"George"[:4]``` which would return ```"Geor"```.


```python
"7285553334" # 728
```

## Summary

Congratulations! You just completed your first lab! You practiced working with string methods to operate on and answer questions about strings. You also used methods that return Booleans and sliced strings. So much of working with data is ensuring that it is properly formatted and in this lab, you started practicing your data wrangling skills.



File: 850_KalleHallden_PythonProjects.txt
ID: 850
Full Name: KalleHallden/PythonProjects
Description: None
Created At: 2019-10-18T10:43:53Z
Updated At: 2024-11-12T11:30:22Z
Pushed At: 2024-04-16T11:09:36Z
Language: Python
URL: https://github.com/KalleHallden/PythonProjects
Forks: 92
Stars: 203
Topics: 
README:


requirements for Database project:
packages: 
    imageio
    opencv-python

to install:
    pip install imageio
    pip install opencv-python


File: 85_digitalinnovationone_trilha-python-dio.txt
ID: 85
Full Name: digitalinnovationone/trilha-python-dio
Description: None
Created At: 2022-08-14T17:58:11Z
Updated At: 2024-11-30T13:57:04Z
Pushed At: 2024-08-18T21:58:21Z
Language: Python
URL: https://github.com/digitalinnovationone/trilha-python-dio
Forks: 4559
Stars: 3118
Topics: 
README:
# Trilha Python DIO



File: 873_cbrownley_foundations-for-analytics-with-python.txt
ID: 873
Full Name: cbrownley/foundations-for-analytics-with-python
Description: None
Created At: 2015-11-05T17:41:59Z
Updated At: 2024-11-20T12:32:17Z
Pushed At: 2021-09-26T06:43:36Z
Language: Python
URL: https://github.com/cbrownley/foundations-for-analytics-with-python
Forks: 681
Stars: 460
Topics: 
README:
foundations-for-analytics-with-python
========================

This repository contains all of the Python scripts, input files, and output files associated with the book, Foundations for Analytics with Python. <br>

<b>About</b> <br>
<a href="https://cbrownley.wordpress.com/2016/03/02/foundations-for-analytics-with-python-from-non-programmer-to-hacker/">My Blog Post: Foundations for Analytics with Python</a> <br>

<b>Shop</b> <br>
O'Reilly Media <br>
<a href="http://shop.oreilly.com/product/0636920038375.do">Foundations for Analytics with Python</a> <br>

Amazon <br>
<a href="https://www.amazon.com/Foundations-Analytics-Python-Brownley/dp/1491922532">Foundations for Analytics with Python</a> <br>

<b>Advance Praise</b> <br>
"This book is a useful learning resource for new Python programmers working with data. The tutorial style and accompanying exercises will help users get their feet wet with the Python language, programming environment, and a number of the most important packages in the ecosystem." - Wes McKinney, Creator of pandas library <br>

"This is a must read book for anyone who feels limited by spreadsheets and wants to master the basics of coding and automation for business applications.  This is also good primer on programmatic approaches to conducting the most common statistical methods, incluing correlations, t-tests, and regressions." - Rajiv Krishnamurthy, Manager, Infra Data Science, Facebook <br>

"Foundations for Analytics with Python is an extremely well-written introduction to Python for analysts, giving clear and practical guidance for the new programmer. It connects principles and best-practices effectively, as if Mr. Brownley was sitting next to you, guiding you each step of the way." - Dean Abbott, Co-Founder and Chief Data Scientist at SmarterHQ <br>

"Data analysis is an essential skill for the modern professional and Clinton's book is the perfect primer to move beyond the pre-defined tools into truly flexible analytics with real code.  Even if you haven't written a single line of code before." - Chandika Jayasundara, CEO & Co-Founder, Creately <br>

"Python is widely used for data analysis -- it is in fact one of the most popular tools/languages for data analysis and data science.  Via this book, Clinton is adding to the field in a much needed manner: by teaching the reader to learn how to program as well as automate and scale their data analyses.  Everyone today would be well served to learn to code and to apply programming to data analysis.  This book serves exactly that purpose: it targets non-coders and teaches them fundamentals of Analytics using Python -- the tool of choice for data scientists today!" - Sameer Chopra, Chief Analytics Officer, GoDaddy <br>

to download
========================
<b>Mac computer:</b> <br>
1. Open a Terminal window <br>
2. Navigate to the folder where you want to download the foundations-for-analytics-with-python folder <br>
&nbsp;&nbsp;&nbsp;&nbsp;For example, to download the foundations-for-analytics-with-python folder onto your Desktop: <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;First, type the following and then hit Enter: `cd` <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Second, type the following and then hit Enter: `cd Desktop/` <br>
3. Finally, to download the foundations-for-analytics-with-python folder, type the following and then hit Enter: <br>
&nbsp;&nbsp;&nbsp;&nbsp;`git clone https://github.com/cbrownley/foundations-for-analytics-with-python.git` <br>

<b>Windows computer:</b> <br>
1. Go to: https://github.com/cbrownley/foundations-for-analytics-with-python <br>
2. Click 'Clone or download' and then 'Download ZIP' in the right side of the page <br>
3. Click on the zipped folder to open it in File Explorer <br>
4. Click 'Extract all' <br>
5. Edit the path to save the foundations-for-analytics-with-python folder on your Desktop <br>
6. Click 'Extract' <br>



File: 916_cod3rcursos_curso-python.txt
ID: 916
Full Name: cod3rcursos/curso-python
Description: None
Created At: 2018-10-31T14:38:10Z
Updated At: 2024-11-11T18:18:17Z
Pushed At: 2023-01-20T16:43:53Z
Language: Python
URL: https://github.com/cod3rcursos/curso-python
Forks: 212
Stars: 512
Topics: 
README:
# curso-python


File: 919_abhaysamantni_PythonReview.txt
ID: 919
Full Name: abhaysamantni/PythonReview
Description: None
Created At: 2022-08-24T15:52:17Z
Updated At: 2024-09-04T22:07:09Z
Pushed At: 2024-09-04T22:07:04Z
Language: Python
URL: https://github.com/abhaysamantni/PythonReview
Forks: 469
Stars: 4
Topics: 
README:



File: 923_makersacademy_intro-to-python.txt
ID: 923
Full Name: makersacademy/intro-to-python
Description: None
Created At: 2023-04-20T19:07:31Z
Updated At: 2024-11-22T07:57:33Z
Pushed At: 2024-10-06T20:18:05Z
Language: Python
URL: https://github.com/makersacademy/intro-to-python
Forks: 806
Stars: 55
Topics: 
README:



File: 928_anthropics_anthropic-sdk-python.txt
ID: 928
Full Name: anthropics/anthropic-sdk-python
Description: None
Created At: 2023-01-17T20:57:10Z
Updated At: 2024-12-01T21:54:21Z
Pushed At: 2024-11-28T16:29:10Z
Language: Python
URL: https://github.com/anthropics/anthropic-sdk-python
Forks: 184
Stars: 1535
Topics: 
README:
# Anthropic Python API library

[![PyPI version](https://img.shields.io/pypi/v/anthropic.svg)](https://pypi.org/project/anthropic/)

The Anthropic Python library provides convenient access to the Anthropic REST API from any Python 3.8+
application. It includes type definitions for all request params and response fields,
and offers both synchronous and asynchronous clients powered by [httpx](https://github.com/encode/httpx).

## Documentation

The REST API documentation can be found on [docs.anthropic.com](https://docs.anthropic.com/claude/reference/). The full API of this library can be found in [api.md](api.md).

## Installation

```sh
# install from PyPI
pip install anthropic
```

## Usage

The full API of this library can be found in [api.md](api.md).

```python
import os
from anthropic import Anthropic

client = Anthropic(
    api_key=os.environ.get("ANTHROPIC_API_KEY"),  # This is the default and can be omitted
)

message = client.messages.create(
    max_tokens=1024,
    messages=[
        {
            "role": "user",
            "content": "Hello, Claude",
        }
    ],
    model="claude-3-opus-20240229",
)
print(message.content)
```

While you can provide an `api_key` keyword argument,
we recommend using [python-dotenv](https://pypi.org/project/python-dotenv/)
to add `ANTHROPIC_API_KEY="my-anthropic-api-key"` to your `.env` file
so that your API Key is not stored in source control.

## Async usage

Simply import `AsyncAnthropic` instead of `Anthropic` and use `await` with each API call:

```python
import os
import asyncio
from anthropic import AsyncAnthropic

client = AsyncAnthropic(
    api_key=os.environ.get("ANTHROPIC_API_KEY"),  # This is the default and can be omitted
)


async def main() -> None:
    message = await client.messages.create(
        max_tokens=1024,
        messages=[
            {
                "role": "user",
                "content": "Hello, Claude",
            }
        ],
        model="claude-3-opus-20240229",
    )
    print(message.content)


asyncio.run(main())
```

Functionality between the synchronous and asynchronous clients is otherwise identical.

## Streaming responses

We provide support for streaming responses using Server Side Events (SSE).

```python
from anthropic import Anthropic

client = Anthropic()

stream = client.messages.create(
    max_tokens=1024,
    messages=[
        {
            "role": "user",
            "content": "Hello, Claude",
        }
    ],
    model="claude-3-opus-20240229",
    stream=True,
)
for event in stream:
    print(event.type)
```

The async client uses the exact same interface.

```python
from anthropic import AsyncAnthropic

client = AsyncAnthropic()

stream = await client.messages.create(
    max_tokens=1024,
    messages=[
        {
            "role": "user",
            "content": "Hello, Claude",
        }
    ],
    model="claude-3-opus-20240229",
    stream=True,
)
async for event in stream:
    print(event.type)
```

### Streaming Helpers

This library provides several conveniences for streaming messages, for example:

```py
import asyncio
from anthropic import AsyncAnthropic

client = AsyncAnthropic()

async def main() -> None:
    async with client.messages.stream(
        max_tokens=1024,
        messages=[
            {
                "role": "user",
                "content": "Say hello there!",
            }
        ],
        model="claude-3-opus-20240229",
    ) as stream:
        async for text in stream.text_stream:
            print(text, end="", flush=True)
        print()

    message = await stream.get_final_message()
    print(message.to_json())

asyncio.run(main())
```

Streaming with `client.messages.stream(...)` exposes [various helpers for your convenience](helpers.md) including accumulation & SDK-specific events.

Alternatively, you can use `client.messages.create(..., stream=True)` which only returns an async iterable of the events in the stream and thus uses less memory (it does not build up a final message object for you).

## Token counting

To get the token count for a message without creating it you can use the `client.beta.messages.count_tokens()` method. This takes the same `messages` list as the `.create()` method.

```py
count = client.beta.messages.count_tokens(
    model="claude-3-5-sonnet-20241022",
    messages=[
        {"role": "user", "content": "Hello, world"}
    ]
)
count.input_tokens  # 10
```

You can also see the exact usage for a given request through the `usage` response property, e.g.

```py
message = client.messages.create(...)
message.usage
# Usage(input_tokens=25, output_tokens=13)
```

## Message Batches

This SDK provides beta support for the [Message Batches API](https://docs.anthropic.com/en/docs/build-with-claude/message-batches) under the `client.beta.messages.batches` namespace.


### Creating a batch

Message Batches take the exact same request params as the standard Messages API:

```python
await client.beta.messages.batches.create(
    requests=[
        {
            "custom_id": "my-first-request",
            "params": {
                "model": "claude-3-5-sonnet-20240620",
                "max_tokens": 1024,
                "messages": [{"role": "user", "content": "Hello, world"}],
            },
        },
        {
            "custom_id": "my-second-request",
            "params": {
                "model": "claude-3-5-sonnet-20240620",
                "max_tokens": 1024,
                "messages": [{"role": "user", "content": "Hi again, friend"}],
            },
        },
    ]
)
```


### Getting results from a batch

Once a Message Batch has been processed, indicated by `.processing_status === 'ended'`, you can access the results with `.batches.results()`

```python
result_stream = await client.beta.messages.batches.results(batch_id)
async for entry in result_stream:
    if entry.result.type == "succeeded":
        print(entry.result.message.content)
```

## Tool use

This SDK provides support for tool use, aka function calling. More details can be found in [the documentation](https://docs.anthropic.com/claude/docs/tool-use).

## AWS Bedrock

This library also provides support for the [Anthropic Bedrock API](https://aws.amazon.com/bedrock/claude/) if you install this library with the `bedrock` extra, e.g. `pip install -U anthropic[bedrock]`.

You can then import and instantiate a separate `AnthropicBedrock` class, the rest of the API is the same.

```py
from anthropic import AnthropicBedrock

client = AnthropicBedrock()

message = client.messages.create(
    max_tokens=1024,
    messages=[
        {
            "role": "user",
            "content": "Hello!",
        }
    ],
    model="anthropic.claude-3-sonnet-20240229-v1:0",
)
print(message)
```

The bedrock client supports the following arguments for authentication

```py
AnthropicBedrock(
  aws_profile='...',
  aws_region='us-east'
  aws_secret_key='...',
  aws_access_key='...',
  aws_session_token='...',
)
```

For a more fully fledged example see [`examples/bedrock.py`](https://github.com/anthropics/anthropic-sdk-python/blob/main/examples/bedrock.py).

## Google Vertex

This library also provides support for the [Anthropic Vertex API](https://cloud.google.com/vertex-ai?hl=en) if you install this library with the `vertex` extra, e.g. `pip install -U anthropic[vertex]`.

You can then import and instantiate a separate `AnthropicVertex`/`AsyncAnthropicVertex` class, which has the same API as the base `Anthropic`/`AsyncAnthropic` class.

```py
from anthropic import AnthropicVertex

client = AnthropicVertex()

message = client.messages.create(
    model="claude-3-sonnet@20240229",
    max_tokens=100,
    messages=[
        {
            "role": "user",
            "content": "Hello!",
        }
    ],
)
print(message)
```

For a more complete example see [`examples/vertex.py`](https://github.com/anthropics/anthropic-sdk-python/blob/main/examples/vertex.py).

## Using types

Nested request parameters are [TypedDicts](https://docs.python.org/3/library/typing.html#typing.TypedDict). Responses are [Pydantic models](https://docs.pydantic.dev) which also provide helper methods for things like:

- Serializing back into JSON, `model.to_json()`
- Converting to a dictionary, `model.to_dict()`

Typed requests and responses provide autocomplete and documentation within your editor. If you would like to see type errors in VS Code to help catch bugs earlier, set `python.analysis.typeCheckingMode` to `basic`.

## Pagination

List methods in the Anthropic API are paginated.

This library provides auto-paginating iterators with each list response, so you do not have to request successive pages manually:

```python
from anthropic import Anthropic

client = Anthropic()

all_batches = []
# Automatically fetches more pages as needed.
for batch in client.beta.messages.batches.list(
    limit=20,
):
    # Do something with batch here
    all_batches.append(batch)
print(all_batches)
```

Or, asynchronously:

```python
import asyncio
from anthropic import AsyncAnthropic

client = AsyncAnthropic()


async def main() -> None:
    all_batches = []
    # Iterate through items across all pages, issuing requests as needed.
    async for batch in client.beta.messages.batches.list(
        limit=20,
    ):
        all_batches.append(batch)
    print(all_batches)


asyncio.run(main())
```

Alternatively, you can use the `.has_next_page()`, `.next_page_info()`, or `.get_next_page()` methods for more granular control working with pages:

```python
first_page = await client.beta.messages.batches.list(
    limit=20,
)
if first_page.has_next_page():
    print(f"will fetch next page using these details: {first_page.next_page_info()}")
    next_page = await first_page.get_next_page()
    print(f"number of items we just fetched: {len(next_page.data)}")

# Remove `await` for non-async usage.
```

Or just work directly with the returned data:

```python
first_page = await client.beta.messages.batches.list(
    limit=20,
)

print(f"next page cursor: {first_page.last_id}")  # => "next page cursor: ..."
for batch in first_page.data:
    print(batch.id)

# Remove `await` for non-async usage.
```

## Handling errors

When the library is unable to connect to the API (for example, due to network connection problems or a timeout), a subclass of `anthropic.APIConnectionError` is raised.

When the API returns a non-success status code (that is, 4xx or 5xx
response), a subclass of `anthropic.APIStatusError` is raised, containing `status_code` and `response` properties.

All errors inherit from `anthropic.APIError`.

```python
import anthropic
from anthropic import Anthropic

client = Anthropic()

try:
    client.messages.create(
        max_tokens=1024,
        messages=[
            {
                "role": "user",
                "content": "Hello, Claude",
            }
        ],
        model="claude-3-opus-20240229",
    )
except anthropic.APIConnectionError as e:
    print("The server could not be reached")
    print(e.__cause__)  # an underlying Exception, likely raised within httpx.
except anthropic.RateLimitError as e:
    print("A 429 status code was received; we should back off a bit.")
except anthropic.APIStatusError as e:
    print("Another non-200-range status code was received")
    print(e.status_code)
    print(e.response)
```

Error codes are as followed:

| Status Code | Error Type                 |
| ----------- | -------------------------- |
| 400         | `BadRequestError`          |
| 401         | `AuthenticationError`      |
| 403         | `PermissionDeniedError`    |
| 404         | `NotFoundError`            |
| 422         | `UnprocessableEntityError` |
| 429         | `RateLimitError`           |
| >=500       | `InternalServerError`      |
| N/A         | `APIConnectionError`       |

## Request IDs

> For more information on debugging requests, see [these docs](https://docs.anthropic.com/en/api/errors#request-id)

All object responses in the SDK provide a `_request_id` property which is added from the `request-id` response header so that you can quickly log failing requests and report them back to Anthropic.

```python
message = client.messages.create(
    max_tokens=1024,
    messages=[
        {
            "role": "user",
            "content": "Hello, Claude",
        }
    ],
    model="claude-3-opus-20240229",
)
print(message._request_id)  # req_018EeWyXxfu5pfWkrYcMdjWG
```

Note that unlike other properties that use an `_` prefix, the `_request_id` property
*is* public. Unless documented otherwise, *all* other `_` prefix properties,
methods and modules are *private*.

### Retries

Certain errors are automatically retried 2 times by default, with a short exponential backoff.
Connection errors (for example, due to a network connectivity problem), 408 Request Timeout, 409 Conflict,
429 Rate Limit, and >=500 Internal errors are all retried by default.

You can use the `max_retries` option to configure or disable retry settings:

```python
from anthropic import Anthropic

# Configure the default for all requests:
client = Anthropic(
    # default is 2
    max_retries=0,
)

# Or, configure per-request:
client.with_options(max_retries=5).messages.create(
    max_tokens=1024,
    messages=[
        {
            "role": "user",
            "content": "Hello, Claude",
        }
    ],
    model="claude-3-opus-20240229",
)
```

### Timeouts

By default requests time out after 10 minutes. You can configure this with a `timeout` option,
which accepts a float or an [`httpx.Timeout`](https://www.python-httpx.org/advanced/#fine-tuning-the-configuration) object:

```python
from anthropic import Anthropic

# Configure the default for all requests:
client = Anthropic(
    # 20 seconds (default is 10 minutes)
    timeout=20.0,
)

# More granular control:
client = Anthropic(
    timeout=httpx.Timeout(60.0, read=5.0, write=10.0, connect=2.0),
)

# Override per-request:
client.with_options(timeout=5.0).messages.create(
    max_tokens=1024,
    messages=[
        {
            "role": "user",
            "content": "Hello, Claude",
        }
    ],
    model="claude-3-opus-20240229",
)
```

On timeout, an `APITimeoutError` is thrown.

Note that requests that time out are [retried twice by default](#retries).

## Default Headers

We automatically send the `anthropic-version` header set to `2023-06-01`.

If you need to, you can override it by setting default headers per-request or on the client object.

Be aware that doing so may result in incorrect types and other unexpected or undefined behavior in the SDK.

```python
from anthropic import Anthropic

client = Anthropic(
    default_headers={"anthropic-version": "My-Custom-Value"},
)
```

## Advanced

### Logging

We use the standard library [`logging`](https://docs.python.org/3/library/logging.html) module.

You can enable logging by setting the environment variable `ANTHROPIC_LOG` to `info`.

```shell
$ export ANTHROPIC_LOG=info
```

Or to `debug` for more verbose logging.

### How to tell whether `None` means `null` or missing

In an API response, a field may be explicitly `null`, or missing entirely; in either case, its value is `None` in this library. You can differentiate the two cases with `.model_fields_set`:

```py
if response.my_field is None:
  if 'my_field' not in response.model_fields_set:
    print('Got json like {}, without a "my_field" key present at all.')
  else:
    print('Got json like {"my_field": null}.')
```

### Accessing raw response data (e.g. headers)

The "raw" Response object can be accessed by prefixing `.with_raw_response.` to any HTTP method call, e.g.,

```py
from anthropic import Anthropic

client = Anthropic()
response = client.messages.with_raw_response.create(
    max_tokens=1024,
    messages=[{
        "role": "user",
        "content": "Hello, Claude",
    }],
    model="claude-3-opus-20240229",
)
print(response.headers.get('X-My-Header'))

message = response.parse()  # get the object that `messages.create()` would have returned
print(message.content)
```

These methods return an [`LegacyAPIResponse`](https://github.com/anthropics/anthropic-sdk-python/tree/main/src/anthropic/_legacy_response.py) object. This is a legacy class as we're changing it slightly in the next major version.

For the sync client this will mostly be the same with the exception
of `content` & `text` will be methods instead of properties. In the
async client, all methods will be async.

A migration script will be provided & the migration in general should
be smooth.

#### `.with_streaming_response`

The above interface eagerly reads the full response body when you make the request, which may not always be what you want.

To stream the response body, use `.with_streaming_response` instead, which requires a context manager and only reads the response body once you call `.read()`, `.text()`, `.json()`, `.iter_bytes()`, `.iter_text()`, `.iter_lines()` or `.parse()`. In the async client, these are async methods.

As such, `.with_streaming_response` methods return a different [`APIResponse`](https://github.com/anthropics/anthropic-sdk-python/tree/main/src/anthropic/_response.py) object, and the async client returns an [`AsyncAPIResponse`](https://github.com/anthropics/anthropic-sdk-python/tree/main/src/anthropic/_response.py) object.

```python
with client.messages.with_streaming_response.create(
    max_tokens=1024,
    messages=[
        {
            "role": "user",
            "content": "Hello, Claude",
        }
    ],
    model="claude-3-opus-20240229",
) as response:
    print(response.headers.get("X-My-Header"))

    for line in response.iter_lines():
        print(line)
```

The context manager is required so that the response will reliably be closed.

### Making custom/undocumented requests

This library is typed for convenient access to the documented API.

If you need to access undocumented endpoints, params, or response properties, the library can still be used.

#### Undocumented endpoints

To make requests to undocumented endpoints, you can make requests using `client.get`, `client.post`, and other
http verbs. Options on the client will be respected (such as retries) when making this
request.

```py
import httpx

response = client.post(
    "/foo",
    cast_to=httpx.Response,
    body={"my_param": True},
)

print(response.headers.get("x-foo"))
```

#### Undocumented request params

If you want to explicitly send an extra param, you can do so with the `extra_query`, `extra_body`, and `extra_headers` request
options.

#### Undocumented response properties

To access undocumented response properties, you can access the extra fields like `response.unknown_prop`. You
can also get all the extra fields on the Pydantic model as a dict with
[`response.model_extra`](https://docs.pydantic.dev/latest/api/base_model/#pydantic.BaseModel.model_extra).

### Configuring the HTTP client

You can directly override the [httpx client](https://www.python-httpx.org/api/#client) to customize it for your use case, including:

- Support for proxies
- Custom transports
- Additional [advanced](https://www.python-httpx.org/advanced/clients/) functionality

```python
from anthropic import Anthropic, DefaultHttpxClient

client = Anthropic(
    # Or use the `ANTHROPIC_BASE_URL` env var
    base_url="http://my.test.server.example.com:8083",
    http_client=DefaultHttpxClient(
        proxies="http://my.test.proxy.example.com",
        transport=httpx.HTTPTransport(local_address="0.0.0.0"),
    ),
)
```

You can also customize the client on a per-request basis by using `with_options()`:

```python
client.with_options(http_client=DefaultHttpxClient(...))
```

### Managing HTTP resources

By default the library closes underlying HTTP connections whenever the client is [garbage collected](https://docs.python.org/3/reference/datamodel.html#object.__del__). You can manually close the client using the `.close()` method if desired, or with a context manager that closes when exiting.

## Versioning

This package generally follows [SemVer](https://semver.org/spec/v2.0.0.html) conventions, though certain backwards-incompatible changes may be released as minor versions:

1. Changes that only affect static types, without breaking runtime behavior.
2. Changes to library internals which are technically public but not intended or documented for external use. _(Please open a GitHub issue to let us know if you are relying on such internals)_.
3. Changes that we do not expect to impact the vast majority of users in practice.

We take backwards-compatibility seriously and work hard to ensure you can rely on a smooth upgrade experience.

We are keen for your feedback; please open an [issue](https://www.github.com/anthropics/anthropic-sdk-python/issues) with questions, bugs, or suggestions.

### Determining the installed version

If you've upgraded to the latest version but aren't seeing any new features you were expecting then your python environment is likely still using an older version.

You can determine the version that is being used at runtime with:

```py
import anthropic
print(anthropic.__version__)
```

## Requirements

Python 3.8 or higher.

## Contributing

See [the contributing documentation](./CONTRIBUTING.md).



File: 955_jackh001_python100Day.txt
ID: 955
Full Name: jackh001/python100Day
Description: None
Created At: 2019-05-04T01:12:38Z
Updated At: 2024-11-01T09:46:51Z
Pushed At: 2022-12-08T05:04:06Z
Language: HTML
URL: https://github.com/jackh001/python100Day
Forks: 87
Stars: 257
Topics: 
README:
## Python - 100天从新手到大师

> 作者：骆昊

### Python应用领域和就业形势分析

简单的说，Python是一个“优雅”、“明确”、“简单”的编程语言。

 - 学习曲线低，非专业人士也能上手
 - 开源系统，拥有强大的生态圈
 - 解释型语言，完美的平台可移植性
 - 支持面向对象和函数式编程
 - 能够通过调用C/C++代码扩展功能
 - 代码规范程度高，可读性强

目前几个比较流行的领域，Python都有用武之地。

 - 云基础设施 - Python / Java / Go
 - DevOps - Python / Shell / Ruby / Go
 - 网络爬虫 - Python / PHP / C++
 - 数据分析挖掘 - Python / R / Scala / Matlab
 - 机器学习 - Python / R / Java / Lisp

作为一名Python开发者，主要的就业领域包括：

- Python服务器后台开发 / 游戏服务器开发 / 数据接口开发工程师
- Python自动化运维工程师
- Python数据分析 / 数据可视化 / 大数据工程师
- Python爬虫工程师
- Python聊天机器人开发 / 图像识别和视觉算法 / 深度学习工程师

下图显示了主要城市Python招聘需求量及薪资待遇排行榜（截止到2018年5月）。

![Python招聘需求及薪资待遇Top 10](./res/python-top-10.png)

![](./res/python-bj-salary.png)

![](./res/python-cd-salary.png)

给初学者的几个建议：

- Make English as your working language.
- Practice makes perfect.
- All experience comes from mistakes.
- Don't be one of the leeches.
- Either stand out or kicked out.

### Day01~15 - [Python语言基础](./Day01-15)

#### Day01 - [初识Python](./Day01-15/Day01/初识Python.md)

- Python简介 - Python的历史 / Python的优缺点 / Python的应用领域
- 搭建编程环境 - Windows环境 / Linux环境 / MacOS环境
- 从终端运行Python程序 - DOS命令 / Hello, world / print函数 / 运行程序
- 使用IDLE - 交互式环境(REPL) / 编写多行代码 / 运行程序 / 退出IDLE
- 注释 - 注释的作用 / 单行注释 / 多行注释

#### Day02 - [语言元素](./Day01-15/Day02/语言元素.md)

- 程序和进制 - 指令和程序 / 冯诺依曼机 / 二进制和十进制 / 八进制和十六进制
- 变量和类型 - 变量的命名 / 变量的使用 / input函数 / 检查变量类型 / 类型转换
- 数字和字符串 - 整数 / 浮点数 / 复数 / 字符串 / 字符串基本操作 / 字符编码
- 运算符 - 数学运算符 / 赋值运算符 / 比较运算符 / 逻辑运算符 / 身份运算符 / 运算符的优先级
- 应用案例 - 华氏温度转换成摄氏温度 / 输入圆的半径计算周长和面积 / 输入年份判断是否是闰年

#### Day03 - [分支结构](./Day01-15/Day03/分支结构.md)

- 分支结构的应用场景 - 条件 / 缩进 / 代码块 / 流程图
- if语句 - 简单的if / if-else结构 / if-elif-else结构 / 嵌套的if
- 应用案例 - 用户身份验证 / 英制单位与公制单位互换 / 掷骰子决定做什么 / 百分制成绩转等级制 / 分段函数求值 / 输入三条边的长度如果能构成三角形就计算周长和面积

#### Day04 - [循环结构](./Day01-15/Day04/循环结构.md)

- 循环结构的应用场景 - 条件 / 缩进 / 代码块 / 流程图
- while循环 - 基本结构 / break语句 / continue语句
- for循环 - 基本结构 / range类型 / 循环中的分支结构 / 嵌套的循环 / 提前结束程序 
- 应用案例 - 1~100求和 / 判断素数 / 猜数字游戏 / 打印九九表 / 打印三角形图案 / 猴子吃桃 / 百钱百鸡

#### Day05 - [总结和练习](./Day01-15/Day05/总结和练习.md)

- 基础练习 - 水仙花数 / 完美数 / 五人分鱼 / Fibonacci数列 / 回文素数 
- 综合练习 - Craps赌博游戏

#### Day06 - [函数和模块的使用](./Day01-15/Day06/函数和模块的使用.md)

- 函数的作用 - 代码的坏味道 / 用函数封装功能模块
- 定义函数 - def语句 / 函数名 / 参数列表 / return语句 / 调用自定义函数
- 调用函数 - Python内置函数 /  导入模块和函数
- 函数的参数 - 默认参数 / 可变参数 / 关键字参数 / 命名关键字参数
- 函数的返回值 - 没有返回值  / 返回单个值 / 返回多个值
- 作用域问题 - 局部作用域 / 嵌套作用域 / 全局作用域 / 内置作用域 / 和作用域相关的关键字
- 用模块管理函数 - 模块的概念 / 用自定义模块管理函数 / 命名冲突的时候会怎样（同一个模块和不同的模块）

#### Day07 - [字符串和常用数据结构](./Day01-15/Day07/字符串和常用数据结构.md)

- 字符串的使用 - 计算长度 / 下标运算 / 切片 / 常用方法
- 列表基本用法 - 定义列表 / 用下表访问元素 / 下标越界 / 添加元素 / 删除元素 / 修改元素 / 切片 / 循环遍历
- 列表常用操作 - 连接 / 复制(复制元素和复制数组) / 长度 / 排序 / 倒转 / 查找
- 生成列表 - 使用range创建数字列表 / 生成表达式 / 生成器
- 元组的使用 - 定义元组 / 使用元组中的值 / 修改元组变量 / 元组和列表转换
- 集合基本用法 - 集合和列表的区别 /  创建集合 / 添加元素 / 删除元素 /  清空
- 集合常用操作 - 交集 / 并集 / 差集 / 对称差 / 子集 / 超集
- 字典的基本用法 - 字典的特点 / 创建字典 / 添加元素 / 删除元素 / 取值 / 清空
- 字典常用操作 - keys()方法 / values()方法 / items()方法 / setdefault()方法
- 基础练习 - 跑马灯效果 / 列表找最大元素 / 统计考试成绩的平均分 / Fibonacci数列 / 杨辉三角
- 综合案例 - 双色球选号 / 井字棋

#### Day08 - [面向对象编程基础](./Day01-15/Day08/面向对象编程基础.md)

- 类和对象 - 什么是类 / 什么是对象 / 面向对象其他相关概念
- 定义类 - 基本结构 / 属性和方法 / 构造器 / 析构器 / \_\_str\_\_方法
- 使用对象 - 创建对象 / 给对象发消息
- 面向对象的四大支柱 - 抽象 / 封装 / 继承 / 多态
- 基础练习 - 定义学生类 / 定义时钟类 / 定义图形类 / 定义汽车类

#### Day09 - [面向对象进阶](./Day01-15/Day09/面向对象进阶.md)

- 属性 - 类属性 / 实例属性 / 属性访问器 / 属性修改器 / 属性删除器 / 使用\_\_slots\_\_
- 类中的方法 - 实例方法 / 类方法 / 静态方法
- 运算符重载 - \_\_add\_\_ / \_\_sub\_\_ / \_\_or\_\_ /\_\_getitem\_\_ / \_\_setitem\_\_ / \_\_len\_\_ / \_\_repr\_\_ / \_\_gt\_\_ / \_\_lt\_\_ / \_\_le\_\_ / \_\_ge\_\_ / \_\_eq\_\_ / \_\_ne\_\_ / \_\_contains\_\_ 
- 类(的对象)之间的关系 - 关联 / 继承 / 依赖
- 继承和多态 - 什么是继承 / 继承的语法 / 调用父类方法 / 方法重写 / 类型判定 / 多重继承 / 菱形继承(钻石继承)和C3算法
- 综合案例 - 工资结算系统 / 图书自动折扣系统 / 自定义分数类

#### Day10 - [图形用户界面和游戏开发](./Day01-15/Day10/图形用户界面和游戏开发.md)

- 使用tkinter开发GUI
- 使用pygame三方库开发游戏应用
- “大球吃小球”游戏

#### Day11 - [文件和异常](./Day01-15/Day11/文件和异常.md)

- 读文件 - 读取整个文件 / 逐行读取 / 文件路径
- 写文件 - 覆盖写入 / 追加写入 / 文本文件 / 二进制文件
- 异常处理 - 异常机制的重要性 / try-except代码块 / else代码块 / finally代码块 / 内置异常类型 / 异常栈 / raise语句
- 数据持久化 - CSV文件概述 / csv模块的应用 / JSON数据格式 / json模块的应用
- 综合案例 - 歌词解析

#### Day12 - [字符串和正则表达式](./Day01-15/Day12/字符串和正则表达式.md)

- 字符串高级操作 - 转义字符 \ 原始字符串 \ 多行字符串 \ in和 not in运算符 \ is开头的方法 \ join和split方法 \ strip相关方法 \ pyperclip模块 \ 不变字符串和可变字符串 \ StringIO的使用
- 正则表达式入门 - 正则表达式的作用 \ 元字符 \ 转义 \ 量词 \ 分组 \ 零宽断言 \贪婪匹配与惰性匹配懒惰 \ 使用re模块实现正则表达式操作（匹配、搜索、替换、捕获）
- 使用正则表达式 - re模块 \ compile函数 \ group和groups方法 \ match方法 \ search方法 \ findall和finditer方法 \ sub和subn方法 \ split方法
- 应用案例 - 使用正则表达式验证输入的字符串

#### Day13 - [进程和线程](./Day01-15/Day13/进程和线程.md)

- 进程和线程的概念 - 什么是进程 / 什么是线程 / 多线程的应用场景
- 使用进程 - fork函数 / multiprocessing模块 / 进程池 / 进程间通信
- 使用线程 - thread模块 / threading模块 / Thread类 / Lock类 / Condition类 / 线程池

#### Day14-A - [网络编程入门](./Day01-15/Day14-A/网络编程入门.md)

- 计算机网络基础 - 计算机网络发展史 / “TCP-IP”模型 / IP地址 / 端口 / 协议 / 其他相关概念
- 网络应用架构 - “客户端-服务器”架构 / “浏览器-服务器”架构
- Python网络编程 - 套接字的概念 / socket模块 /  socket函数 / 创建TCP服务器 / 创建TCP客户端 / 创建UDP服务器 / 创建UDP客户端 / SocketServer模块

#### Day14-B - [网络应用开发](./Day01-15/Day14-B/网络应用开发.md)

- 访问网络API - 网络API概述 / 访问URL / requests模块 / 解析JSON格式数据
- 文件传输 - FTP协议 / ftplib模块 / 交互式FTP应用
- 电子邮件 - SMTP协议 / POP3协议 / IMAP协议 / smtplib模块 / poplib模块 / imaplib模块
- 短信服务 - twilio模块 / 国内的短信服务

#### Day15 - [图像和文档处理](./Day01-15/Day15/图像和办公文档处理.md)

- 用Pillow处理图片 - 图片读写 / 图片合成 / 几何变换 / 色彩转换 / 滤镜效果
- 读写Word文档 - 文本内容的处理 / 段落 / 页眉和页脚 / 样式的处理
- 读写Excel文件 - xlrd模块 / xlwt模块
- 生成PDF文件 - pypdf2模块 / reportlab模块

### Day16~Day20 - [Python语言进阶 ](./Day16-20/Python语言进阶.md)

- 常用数据结构
- 函数的高级用法 - “一等公民” / 高阶函数 / Lambda函数 / 作用域和闭包 / 装饰器
- 面向对象高级知识 - “三大支柱” / 类与类之间的关系 / 垃圾回收 / 魔术属性和方法 / 混入 / 元类 / 面向对象设计原则 / GoF设计模式
- 迭代器和生成器 - 相关魔术方法 / 创建生成器的两种方式 / 
- 并发和异步编程 - 多线程 / 多进程 / 异步IO / async和await

### Day21~30 - [Web前端入门](./Day21-30/Web前端概述.md)

- 用HTML标签承载页面内容
- 用CSS渲染页面
- 用JavaScript处理交互式行为
- jQuery入门和提高
- Vue.js入门
- Element的使用
- Bootstrap的使用

### Day31~35 - [玩转Linux操作系统](./Day31-35/玩转Linux操作系统.md)

- 操作系统发展史和Linux概述
- Linux基础命令
- Linux中的实用程序
- Linux的文件系统
- Vim编辑器的应用
- 环境变量和Shell编程
- 软件的安装和服务的配置
- 网络访问和管理
- 其他相关内容

### Day36~40 - [数据库基础和进阶](./Day36-40)

- [关系型数据库MySQL](./Day36-40/关系型数据库MySQL.md)
  - 关系型数据库概述
  - MySQL的安装和使用
  - SQL的使用
    - DDL - 数据定义语言 - create / drop / alter
    - DML - 数据操作语言 - insert / delete / update / select
    - DCL - 数据控制语言 - grant / revoke
  - 相关知识
    - 范式理论 - 设计二维表的指导思想
    - 数据完整性
    - 数据一致性
  - 在Python中操作MySQL
- [NoSQL入门](./Day36-40/NoSQL入门.md)
  - NoSQL概述
  - Redis概述
  - Mongo概述

### Day41~55 - [实战Django](./Day41-55)

#### Day41 - [快速上手](./Day41-55/01.快速上手.md)

- Web应用工作原理和HTTP协议
- Django框架概述
- 5分钟快速上手
- 使用视图模板

#### Day42 - [深入模型](./Day41-55/02.深入模型.md)

- 关系型数据库配置
- 管理后台的使用
- 使用ORM完成对模型的CRUD操作
- Django模型最佳实践
- 模型定义参考

#### Day43 - [静态资源和Ajax请求](./Day41-55/03.静态资源和Ajax请求.md)

- 加载静态资源
- 用Ajax请求获取数据

#### Day44 - [表单的应用](./Day41-55/04.表单的应用.md)

#### Day45 - [Cookie和会话](./Day41-55/05.Cookie和会话.md)

#### Day46 - [中间件的应用](./Day41-55/06.中间件的应用.md)

#### Day47 - [日志和缓存](./Day41-55/07.日志和缓存.md)

#### Day48 - [文件上传和富文本编辑](./Day41-55/08.文件上传.md)

#### Day49 - [文件下载和报表](./Day41-55/09.文件下载和报表.md)

#### Day50 - [RESTful架构和DRF入门](./Day41-55/10.RESTful架构和DRF入门.md)

#### Day51 - [RESTful架构和DRF进阶](./Day41-55/11.RESTful架构和DRF进阶.md)

#### Day52 - [使用缓存](./Day41-55/12.使用缓存.md)

#### Day53 - [短信和邮件](./Day41-55/13.短信和邮件.md)

#### Day54 - [异步任务和定时任务](./Day41-55/14.异步任务和定时任务.md)

#### Day55 - [单元测试和项目上线](./Day41-55/15.单元测试和项目上线.md)

- 项目开发流程和相关工具
- 生成非HTML内容
- 项目部署和测试
- 项目性能初步调优
- Web应用安全保护


### Day56~60 - [实战Flask](./Day56-65)

#### Day56 - [Flask入门](./Day56-60/01.Flask入门.md) 

#### Day57 - [模板的使用](./Day56-60/02.模板的使用.md) 

#### Day58 - [表单的处理](./Day56-60/03.表单的处理.md) 

#### Day59 - [数据库操作](./Day56-60/04.数据库操作.md)

#### Day60 - [项目实战](./Day56-60/05.项目实战.md)

### Day61~65 - [实战Tornado](./Day61-65)

#### Day61 - [预备知识](./Day61-65/01.预备知识.md)

- 并发编程
- I/O模式和事件驱动

#### Day62 - [Tornado入门](./Day61-65/02.Tornado入门.md)

- Tornado概述
- 5分钟上手Tornado
- 路由解析
- 请求处理器

#### Day63 - [异步化](./Day61-65/03.异步化.md)

- aiomysql和aioredis的使用

#### Day64 - [WebSocket的应用](./Day61-65/04.WebSocket的应用.md)

- WebSocket简介
- WebSocket服务器端编程
- WebSocket客户端编程
- 项目：Web聊天室

#### Day65 - [项目实战](./Day61-65/05.项目实战.md)

- 前后端分离开发和接口文档的撰写
- 使用Vue.js实现前端渲染
- 使用ECharts实现报表功能
- 使用WebSocket实现推送服务

### Day66~75 - [爬虫开发](./Day66-75)

#### Day66 - [网络爬虫和相关工具](./Day66-75/01.网络爬虫和相关工具.md)

#### Day67 - [数据采集和解析](./Day66-75/02.数据采集和解析.md)

#### Day68 - [存储数据](./Day66-75/03.存储数据.md)

#### Day69 - [并发下载](./Day66-75/04.并发下载.md)

#### Day70 - [解析动态内容](./Day66-75/05.解析动态内容.md)

#### Day71 - [表单交互和验证码处理](./Day66-75/06.表单交互和验证码处理.md)

#### Day72 - [Scrapy入门](./Day66-75/07.Scrapy入门.md)

#### Day73 - [Scrapy高级应用](./Day66-75/08.Scrapy高级应用.md)

#### Day74 - [Scrapy分布式实现](./Day66-75/09.Scrapy分布式实现.md)

#### Day75 - [爬虫项目实战](./Day66-75/10.爬虫项目实战.md)

### Day76~90 - [数据处理和机器学习](./Day76-90)

#### Day76 - [机器学习基础](./Day76-90/01.机器学习基础.md)

#### Day77 - [Pandas的应用](./Day76-90/02.Pandas的应用.md)

#### Day78 - [NumPy和SciPy的应用](./Day76-90/03.NumPy和SciPy的应用)

#### Day79 - [Matplotlib和数据可视化](./Day76-90/04.Matplotlib和数据可视化)

#### Day80 - [k最近邻(KNN)分类](./Day76-90/05.k最近邻分类.md)

#### Day81 - [决策树](./Day76-90/06.决策树.md)

#### Day82 - [贝叶斯分类](./Day76-90/07.贝叶斯分类.md)

#### Day83 - [支持向量机(SVM)](./Day76-90/08.支持向量机.md)

#### Day84 - [K-均值聚类](./Day76-90/09.K-均值聚类.md)

#### Day85 - [回归分析](./Day76-90/10.回归分析.md)

#### Day86 - [大数据分析入门](./Day76-90/11.大数据分析入门.md)

#### Day87 - [大数据分析进阶](./Day76-90/12.大数据分析进阶.md)

#### Day88 - [Tensorflow入门](./Day76-90/13.Tensorflow入门.md)

#### Day89 - [Tensorflow实战](./Day76-90/14.Tensorflow实战.md)

#### Day90 - [推荐系统](./Day76-90/15.推荐系统.md)

### Day91~100 - [团队项目开发](./Day91-100)

#### 第91天：团队开发和项目选题

1. 软件过程模型
   - 经典过程模型（瀑布模型）
     - 可行性分析（研究做还是不做），输出《可行性分析报告》。
     - 需求分析（研究做什么），输出《需求规格说明书》和产品界面原型图。
     - 概要设计和详细设计，输出概念模型图、物理模型图、类图、时序图等。
     - 编码 / 测试。
     - 上线 / 维护。
   - 敏捷开发（Scrum）- 产品所有者、Scrum Master、研发人员 - Sprint
     - 产品的Backlog（用户故事、产品原型）。
     - 计划会议（评估和预算）。
     - 日常开发（站立会议、番茄工作法、结对编程、测试先行、代码重构……）。
     - 修复bug（问题描述、重现步骤、测试人员、被指派人）。
     - 评审会议（Showcase）。
     - 回顾会议（当前周期做得好和不好的地方）。

     > 补充：敏捷软件开发宣言
     >
     > - **个体和互动** 高于 流程和工具
     > - **工作的软件** 高于 详尽的文档
     > - **客户合作** 高于 合同谈判
     > - **响应变化** 高于 遵循计划

    ![](./res/the-daily-scrum-in-the-sprint-cycle.png)

      > 角色：产品所有者（决定做什么，能对需求拍板的人）、团队负责人（解决各种问题，专注如何更好的工作，屏蔽外部对开发团队的影响）、开发团队（项目执行人员，具体指开发人员和测试人员）。
      >
      > 准备工作：商业案例和资金、合同、憧憬、初始产品需求、初始发布计划、入股、组建团队。
      >
      > 敏捷团队通常人数为8-10人。
      >
      > 工作量估算：将开发任务量化，包括原型、Logo设计、UI设计、前端开发等，尽量把每个工作分解到最小任务量，最小任务量标准为工作时间不能超过两天，然后估算总体项目时间。把每个任务都贴在白板上面，白板上分三部分：to do（待完成）、in progress（进行中）和done（已完成）。

2. 项目团队组建

   - 团队的构成和角色

     > 说明：谢谢付祥英女士绘制了下面这张精美的公司组织架构图。

     ![company_architecture](./res/company_architecture.png)

   - 编程规范和代码审查（flake8、pylint）

     ![](./res/pylint.png)

   - Python中的一些“惯例”（请参考[《Python惯例-如何编写Pythonic的代码》](Python惯例.md)）

   - 影响代码可读性的原因：

     - 代码注释太少或者没有注释
     - 代码破坏了语言的最佳实践
     - 反模式编程（意大利面代码、复制-黏贴编程、自负编程、……）

3. 团队开发工具介绍
   - 版本控制：Git、Mercury
   - 缺陷管理：[Gitlab](https://about.gitlab.com/)、[Redmine](http://www.redmine.org.cn/)
   - 敏捷闭环工具：[禅道](https://www.zentao.net/)、[JIRA](https://www.atlassian.com/software/jira/features)
   - 持续集成：[Jenkins](https://jenkins.io/)、[Travis-CI](https://travis-ci.org/)

   请参考[《团队项目开发》](Day91-100/团队项目开发.md)。

##### 项目选题和理解业务

1. 选题范围设定

   - CMS（用户端）：新闻聚合网站、问答/分享社区、影评/书评网站等。
   - MIS（用户端+管理端）：KMS、KPI考核系统、HRS、CRM系统、供应链系统、仓储管理系统等。

   - App后台（管理端+数据接口）：二手交易类、报刊杂志类、小众电商类、新闻资讯类、旅游类、社交类、阅读类等。
   - 其他类型：自身行业背景和工作经验、业务容易理解和把控。

2. 需求理解、模块划分和任务分配

   - 需求理解：头脑风暴和竞品分析。
   - 模块划分：画思维导图（XMind），每个模块是一个枝节点，每个具体的功能是一个叶节点（用动词表述），需要确保每个叶节点无法再生出新节点，确定每个叶子节点的重要性、优先级和工作量。
   - 任务分配：由项目负责人根据上面的指标为每个团队成员分配任务。

   ![](./res/requirements_by_xmind.png)

3. 制定项目进度表（每日更新）

   | 模块 | 功能     | 人员   | 状态     | 完成 | 工时 | 计划开始 | 实际开始 | 计划结束 | 实际结束 | 备注             |
   | ---- | -------- | ------ | -------- | ---- | ---- | -------- | -------- | -------- | -------- | ---------------- |
   | 评论 | 添加评论 | 王大锤 | 正在进行 | 50%  | 4    | 2018/8/7 |          | 2018/8/7 |          |                  |
   |      | 删除评论 | 王大锤 | 等待     | 0%   | 2    | 2018/8/7 |          | 2018/8/7 |          |                  |
   |      | 查看评论 | 白元芳 | 正在进行 | 20%  | 4    | 2018/8/7 |          | 2018/8/7 |          | 需要进行代码审查 |
   |      | 评论投票 | 白元芳 | 等待     | 0%   | 4    | 2018/8/8 |          | 2018/8/8 |          |                  |

#### 第92天：数据库设计和OOAD

##### 概念模型和正向工程

1. UML（统一建模语言）的类图

   ![uml](./res/uml-class-diagram.png)

2. 通过模型创建表（正向工程）

   ```Shell
   python manage.py makemigrations app
   python manage.py migrate
   ```

##### 物理模型和反向工程

1. PowerDesigner

   ![](./res/power-designer-pdm.png)

2. 通过数据表创建模型（反向工程）

   ```Shell
   python manage.py inspectdb > app/models.py
   ```

#### 第93-98天：使用Django开发项目

> 说明：具体内容请参考[《Django知识点概述》](Day91-100/Django知识点概述.md)

##### 项目开发中的公共问题

1. 数据库的配置（多数据库、主从复制、数据库路由）
2. 缓存的配置（分区缓存、键设置、超时设置、主从复制、故障恢复（哨兵））
3. 日志的配置
4. 分析和调试（Django-Debug-ToolBar）
5. 好用的Python模块（日期计算、图像处理、数据加密、三方API）

##### REST API设计

1. RESTful架构
   - [理解RESTful架构](http://www.ruanyifeng.com/blog/2011/09/restful.html)
   - [RESTful API设计指南](http://www.ruanyifeng.com/blog/2014/05/restful_api.html)
   - [RESTful API最佳实践](http://www.ruanyifeng.com/blog/2018/10/restful-api-best-practices.html)
2. API接口文档的撰写（[《网络API接口设计》](Day91-100/网络API接口设计.md)）
   - [RAP2](http://rap2.taobao.org/)
   - [YAPI](http://yapi.demo.qunar.com/)
3. [django-REST-framework](https://www.django-rest-framework.org/)的应用

##### 项目中的重点难点剖析

1. 使用缓存缓解数据库压力 - Redis
2. 使用消息队列做解耦合和削峰 - Celery + RabbitMQ

#### 第99-100天：测试和部署

##### 单元测试

1. 测试的种类
2. 编写单元测试（unittest、pytest、nose2、tox、ddt、……）
3. 测试覆盖率（coverage）

##### 项目部署

> 说明：请参考[《项目部署上线指南》](Day91-100/项目部署上线指南.md)。

1. 部署前的准备工作
   - 关键设置（SECRET_KEY / DEBUG / ALLOWED_HOSTS / 缓存 / 数据库）
   - HTTPS / CSRF_COOKIE_SECUR  / SESSION_COOKIE_SECURE  
   - 日志相关配置
2. Linux常用命令回顾
3. Linux常用服务的安装和配置
4. uWSGI/Gunicorn和Nginx的使用
   - Gunicorn和uWSGI的比较
     - 对于不需要大量定制化的简单应用程序，Gunicorn是一个不错的选择，uWSGI的学习曲线比Gunicorn要陡峭得多，Gunicorn的默认参数就已经能够适应大多数应用程序。
     - uWSGI支持异构部署。
     - 由于Nginx本身支持uWSGI，在线上一般都将Nginx和uWSGI捆绑在一起部署，而且uWSGI属于功能齐全且高度定制的WSGI中间件。
     - 在性能上，Gunicorn和uWSGI其实表现相当。
5. 虚拟化技术（Docker）

##### 性能测试

> 说明：具体内容请参考[《Django知识点概述》](Day91-100/Django知识点概述.md)。

1. AB的使用
2. SQLslap的使用
3. sysbench的使用

##### 自动化测试

1. 使用Shell和Python进行自动化测试
2. 使用Selenium实现自动化测试
   - Selenium IDE
   - Selenium WebDriver
   - Selenium Remote Control
3. 测试工具Robot Framework介绍

##### 项目性能调优

1. 数据库性能调优 - 请参考[《MySQL相关知识》](Day91-100/MySQL相关知识.md)
   - 软硬件优化

   - SQL优化

   - 架构优化

     - 分表分库

     - 主从复制，读写分离
     - 集群架构

2. Web服务器性能优化

   - Nginx负载均衡配置

   - Keepalived实现高可用

3. 代码性能调优

   - 多线程
   - 异步化

4. 静态资源访问优化
      - 云存储
      - CDN



> 致谢：感谢的我的同事古晔、张旭、肖世荣、王海飞、荣佳伟、路丰坤等在技术上给予的指导和帮助。


File: 96_UofT-DSI_python.txt
ID: 96
Full Name: UofT-DSI/python
Description: None
Created At: 2022-11-24T11:21:52Z
Updated At: 2024-11-30T16:33:54Z
Pushed At: 2024-11-30T16:36:59Z
Language: Jupyter Notebook
URL: https://github.com/UofT-DSI/python
Forks: 368
Stars: 14
Topics: 
README:
# Python
 
## Content

* [Description](#description)
* [Learning Outcomes](#learning-outcomes)
* [Assignments](#assignments)
* [Contacts](#contacts)
* [Delivery of the Learning Module](#delivery-of-the-learning-module)
* [Schedule](#schedule)
* [Requirements](#requirements)
* [Resources](#resources)
    + [Documents](#documents)
    + [Videos](#videos)
* [Folder Structure](#folder-structure)

## Description

This module introduces participants to the fundamentals of programming using Python. Participants will be introduced to the concepts of functions and object-oriented programming to make use of reusable blocks of code and models, respectively. We also introduce `numPy`, an important library in data science and machine learning. By the end of this module, participants will be able to write reusable code to analyze data.

## Learning Outcomes

By the end of the module, participants will be able to:

1. Identify the differences between data types
2. Identify and resolve errors
3. Write a block of code as a reusable function
4. Write blocks of code in Python using variables and conditionals
5. Use a loop to go over elements of an array
6. Describe the benefits of Object Oriented programming
7. Use the `numPy` library to perform mathematical operations on arrays and datasets

## Assignments

Participants should review the [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md) for instructions on how to complete assignments in this module.

There are two assignments (one per week) in this module:

1. [Anagram Checker](https://github.com/UofT-DSI/python/blob/main/02_activities/assignments/assignment_1.ipynb): Due **Sunday December 1 at 11:59 PM**
2. [Efficacy Analysis of a Hypothetical Arthritis Drug](https://github.com/UofT-DSI/python/blob/main/02_activities/assignments/assignment_2.ipynb): Due **Sunday December 8 at 11:59 PM**

## Contacts

**Questions can be submitted to the _#cohort-5-help_ channel on Slack**

* Technical Facilitator: 
  * **Kaylie Lau** (She/Her): kaylie.lau@mail.utoronto.ca
* Learning Support Staff: 
  * **Anjali Shrivastava** (She/Her): anju_shrivastava@yahoo.com
  * **Moniz Chan**: chanmoniz526@gmail.com
  * **Pedram Aliniaye Asli** (He/Him):  pedram.aliniayeasli@gmail.com

## Delivery of the Learning Module

This module will include live learning sessions and optional, asynchronous work periods. During live learning sessions, the Technical Facilitator will introduce and explain key concepts and demonstrate core skills. Learning is facilitated during this time. Before and after each live learning session, the instructional team will be available for questions related to the core concepts of the module. The Technical Facilitator will introduce concepts through a collaborative live coding session using the Python notebooks found under `/01_materials/slides`. The Technical Facilitator will also upload live coding files to this repository for participants to revisit under `./04_this_cohort/live_code`.


Optional work periods are to be used to seek help from peers, the Learning Support team, and to work through the homework and assignments in the learning module, with access to live help. Content is not facilitated, but rather this time should be driven by participants. We encourage participants to come to these work periods with questions and problems to work through. 
 

Participants are encouraged to engage actively during the learning module. They key to developing the core skills in each learning module is through practice. The more participants engage in coding along with the instructional team, and applying the skills in each module, the more likely it is that these skills will solidify. 

## Schedule

||Day 1|Day 2|Day 3|Day 4|Day 5|
|---|---|---|---|---|---|
|Week 1|Live Learning Session 1 (Introduction, Data Types, Error)|Live Learning Session 2 (Functions, Strings, Converting Types, Input)|Live Learning Session 3 (Control Flow) |Work Period 1|Work Period 2|
|Week 2|Live Learning Session 4 (Reading/Writing, Object Oriented Programming)|Live Learning Session 5 (`numPy`)|Case Study|Work Period 3|Work Period 4|

While Testing, `pandas`, Visualization, and APIs are not covered in this course, you are encouraged to explore the slides at your own pace to deepen your understanding.
 
## Requirements

* Participants are not expected to have any coding experience; the learning content has been designed for beginners.
* Participants are encouraged to ask questions, and collaborate with others to enhance their learning experience.
* Participants must have a computer and an internet connection to participate in online activities.
* Participants must not use generative AI such as ChatGPT to generate code in order to complete assignments. It should be used as a supportive tool to seek out answers to questions you may have.
* We expect participants to have completed the instructions mentioned in the [onboarding repo](https://github.com/UofT-DSI/onboarding/).
* We encourage participants to default to having their camera on at all times, and turning the camera off only as needed. This will greatly enhance the learning experience for all participants and provides real-time feedback for the instructional team. 

## Resources

Feel free to use the following as resources:

### Documents

- [Cheatsheet](https://www.datacamp.com/cheat-sheet/getting-started-with-python-cheat-sheet)
  - [Direct to image](https://images.datacamp.com/image/upload/v1673614099/Python_Cheat_Sheet_for_Beginners_f939d6b1bb.png)
- [Interactive Cheatsheet](https://www.pythoncheatsheet.org/)
- [W3Schools](https://www.w3schools.com/python/)
- [Official Python Docs](https://docs.python.org/3.12/)

### Videos

- [Dictionaries](https://www.youtube.com/watch?v=u0yr9B3nH8c)
- [Loops](https://www.youtube.com/watch?v=dHANJ4l6fwA)
- [Function](https://www.youtube.com/watch?v=NSbOtYzIQI0)
- [Return vs print](https://www.youtube.com/watch?v=LWdsF79H1Pg)
- [OOP Part 1](https://www.youtube.com/watch?v=wfcWRAxRVBA)
- [OOP Part 2](https://www.youtube.com/watch?v=WOwi0h_-dfA)
- [NumPy Playlist](https://www.youtube.com/playlist?list=PLGZqdNxqKzfYVbCaAKTPHVjz-VjQtBzbl)

### How to get help

![image](./steps_to_ask_for_help.png)

<hr>

## Folder Structure

```markdown
.
├── .github
├── 01_materials/slides
├── 02_activities
├── 03_instructional_team
├── 04_this_cohort
├── 05_src/data
├── .gitignore
├── LICENSE
├── README.md
└── steps_to_ask_for_help.png
```

* **.github**: Contains issue templates and pull request templates for the repository.
* **materials/slides**: Module slides and interactive notebooks (.ipynb files) used during learning sessions.
* **activities**: Contains graded assignments, exercises, and homework to practice concepts covered in the learning module.
* **instructional_team**: Resources for the instructional team.
* **this_cohort**: Additional materials and resources for this cohort, including live coding files.
* **src/data**: Source code, databases, logs, and required dependencies (requirements.txt) needed during the module.
* **.gitignore**: Files to exclude from this folder, specified by the Technical Facilitator
* **LICENSE**: The license for this repository.
* **README**: This file.
* **steps_to_ask_for_help.png**: Guide on how to ask for help.




File: 971_umangahuja1_Python.txt
ID: 971
Full Name: umangahuja1/Python
Description: None
Created At: 2017-05-30T22:22:48Z
Updated At: 2022-10-31T18:40:42Z
Pushed At: 2017-10-25T20:31:22Z
Language: Python
URL: https://github.com/umangahuja1/Python
Forks: 60
Stars: 7
Topics: 
README:
# Python



File: 973_INVESTAR_StockAnalysisInPython.txt
ID: 973
Full Name: INVESTAR/StockAnalysisInPython
Description: None
Created At: 2020-03-29T05:40:59Z
Updated At: 2024-11-06T08:06:00Z
Pushed At: 2024-06-30T06:05:12Z
Language: Python
URL: https://github.com/INVESTAR/StockAnalysisInPython
Forks: 415
Stars: 459
Topics: 
README:
# 파이썬 증권 데이터 분석 (Stock Analysis in Python)
본 깃허브에서는 『파이썬 증권 데이터 분석』(한빛출판사, 2020) 서적과 관련된 소스 코드와 추가 자료를 공유합니다.

- 소스 코드는 각 장별 디렉터리에 존재하며, 이미지 파일들은 각 장별로 imgs 디렉터리에 존재합니다.

- 114 페이지 소스코드의 이미지 파일 URL은 http://bit.ly/2JnsHnT → http://bit.ly/3ZZyeXQ 변경됐습니다.

- 지면 관계 상 싣지 못한 파이썬 내장함수표와 AES-256 암복호화 실습은
10_Appendix_(Python_Built-in_Functions_and_AES-256_Encryption).pdf 파일을 참고하시기 바랍니다.

- 서적에 삽입된 그림의 PPT 원본은 PowerPoint_Materials.pptx 파일에 있습니다.

## 네이버 일별시세 전일비 데이터 변경에 따른 DBUpdaterEx 수정 내역
네이버 일별시세의 전일비 데이터가 기존에는 숫자로만 제공되었으나, 전일비 데이터에 상승/하락/보합 등의 문자열이 추가되면서 아래처럼 Exception이 발생하는 현상이 있었습니다.
![ExceptionOccured_2024-06-30](./05_Stock_Price_API/imgs/ExceptionOccured_2024-06-30.jpg)

전일비 데이터(diff)에서 문자를 제외하고 숫자만 추출하도록 DBUpdaterEx.py에 아래처럼 코드 한 줄을 추가하였습니다. (2024-06-30 기준)
![DBUpdaterEx_2024-06-30](./05_Stock_Price_API/imgs/DBUpdaterEx_2024-06-30.jpg)

## 시세조회 DB 업데이트 및 시세조회 API 빠른 사용법
책이 출간된지 제법 시간이 흘렀고 파이썬 라이브러리에도 변경된 내용이 많아서 최신 라이브러리 간 호환성이 확보되지 않을 수 있습니다. 시세조회 DB를 빠르게 구축해서 시세조회 API를 사용하고자 하시는 분은 아래처럼 requirements.txt에 명시된 라이브러리 버전으로 설치하시 바랍니다. (2024-03-03 기준)  
1. Python 설치  
   ① Win+R키를 눌러서 실행창이 나오면 appwiz.cpl를 입력한 후 '프로그램 변경 및 제거' 창에서 기존에 설치된 Python을 전부 제거  
   ② https://www.python.org/ftp/python/3.8.1/python-3.8.1-amd64.exe 다운로드  
   ③ 설치 프로그램을 실행한 후 'Add Python 3.8 to PATH' 체크박스에 체크한 후 'Install Now'로 설치  
   ④ Python 설치가 완료되면 명령창을 새로 실행해서 python --version 명령으로 Python 3.8.1이 설치됐는지 확인
2. Python 라이브러리 설치  
   ① https://github.com/INVESTAR/StockAnalysisInPython/blob/master/02_Python_Programming/requirements.txt 다운로드    
   ② c:\Users\hwang\Downloads>python -m pip install --upgrade pip  
   ③ c:\Users\hwang\Downloads>pip install -r requirements.txt    
3. Investar 데이터베이스 생성   
   ① https://mariadb.com/downloads/ 접속  
   ② MariaDB Community -> Windows 64bit -> 10.5.24GA 다운로드해서 실행  
   ③ 바탕화면에 생성된 HediSQL 아이콘을 더블 클릭하여 실행한 후 Investar DB를 utf8_general_ci 로 생성
   ![HeidiSQL](./05_Stock_Price_API/imgs/HeidiSQL.png)   
   ④ 쿼리 탭을 클릭해서 테이블 생성 쿼리를 실행  
     CREATE TABLE IF NOT EXISTS company_info ( 
    code VARCHAR(20),
    company VARCHAR(40), 
    last_update DATE, 
    PRIMARY KEY (code) 
);
CREATE TABLE IF NOT EXISTS daily_price ( 
    code VARCHAR(20),
    date DATE,
    open BIGINT(20),
    high BIGINT(20),
    low BIGINT(20),
    close BIGINT(20),
    diff BIGINT(20),
    volume BIGINT(20),
    PRIMARY KEY (code, date) 
);  
5. myPackage 생성 및 API 호출   
   ① c:\myPackage\Investar 폴더를 생성  
   ② https://github.com/INVESTAR/StockAnalysisInPython/tree/master/05_Stock_Price_API/Investar 폴더로부터 Analyzer.py, DBUpdaterEx.py, MarketDB.py를 다운로드 받아서 c:\myPackage\Investar 폴더로 복사   
   ③ c:\myPackage\Investar>python DBUpdaterEx.py 실행해서 데이터베이스를 업데이트
   ![DBUpdaterEx2024-03-03](./05_Stock_Price_API/imgs/DBUpdaterEx2024-03-03.png)  
   ④ IDLE에서 c:\myPackage\Invesat\Analyzer.py 파일을 실행한 뒤 아래처럼 API 호출
   ![GetDailyPrice](./05_Stock_Price_API/imgs/GetDailyPrice.png)   
   
## 네이버 금융의 웹 스크레이핑 차단에 대한 안내
아래 내용은 2021년 10월 11일에 발행된 5쇄 서적부터 반영되어 있으며,
기존에 발행된 1쇄~4쇄 서적을 구매하신 분들은 아래 내용을 참고하시기 바랍니다.

2021년 1월 7일 저녁부터 네이버 금융에서 웹 크롤러의 스크레이핑을 차단하기 시작했습니다. 
따라서 기존 방식대로 urllib.request.urlopen()이나 pandas.read_html()를 사용할 경우,
더 이상 네이버 금융의 웹 페이지를 읽어올 수 없습니다. 

네이버 금융 서버에서 http 패킷 헤더의 웹 브라우저 정보(User-Agent)를 체크하기 때문에,
웹 스크레이핑을 하려면 requests 라이브러리를 이용해 웹 브라우저 정보를 보내야 합니다.
변경된 코드는 아래와 같으며 DBUpdaterEx.py로 깃헙에 올려두었습니다.

![DBUpdaterEx](./05_Stock_Price_API/imgs/DBUpdaterEx.jpg)

http://httpbin.org/user-agent 사이트에 접속하시면 
현재 본인이 사용하는 웹 브라우저에 대한 정보를 확인할 수 있습니다.
샘플 코드의 "Mozilla/5.0"를 실제로 본인이 사용하는 웹 브라우저 정보로 변경하면
네이버 금융 페이지에서 차단될 가능성을 조금 더 줄일 수 있습니다.



File: 989_learn-co-curriculum_python-p3-reading-python-error-messages.txt
ID: 989
Full Name: learn-co-curriculum/python-p3-reading-python-error-messages
Description: None
Created At: 2022-06-03T20:07:02Z
Updated At: 2024-05-08T13:35:54Z
Pushed At: 2024-02-03T22:23:17Z
Language: Python
URL: https://github.com/learn-co-curriculum/python-p3-reading-python-error-messages
Forks: 2967
Stars: 1
Topics: 
README:
# Reading Python Error Messages

## Learning Goals

- Read the different parts of an error message.
- Identify common types of errors.

***

## Key Vocab

- **Interpreter**: a program that executes other programs. Python programs
require the Python interpreter to be installed on your computer so that they
can be run.
- **Python Shell**: an interactive interpreter that can be accessed from the
command line.
- **Data Type**: a specific kind of data. The Python interpreter uses these
types to determine which actions can be performed on different data items.
- **Exception**: a type of error that can be predicted and handled without
causing a program to crash.
- **Code Block**: a collection of code that is interpreted together. Python
groups code blocks by indentation level.
- **Function**: a named code block that performs a sequence of actions when it
is called.
- **Scope**: the area in your program where a specific variable can be called.

***

## Introduction

In this lab, you'll be reading error messages from tests. This lab is designed
so that both running the files _and_ running the test suite via the `pytest`
command will show the error messages for you to decode. Moving forward though,
you'll be reading error messages mainly through running the test suite.

***

## Reading Error Messages

Let's start by running some of the Python code in the `lib/` folder to produce an
error message. Run this in your terminal:

```console
$ python lib/a_name_error.py
```

Error messages have 3 parts:

```console
File "lib/a_name_error.py",
line 3, in <module>
    print(hello_world)
NameError: name 'hello_world' is not defined
```

The location of the error, the "where":

   ```console
   "lib/a_name_error.py", line 3, in <module>:
   ```

   - `"lib/a_name_error.py"` is the file the error occurred in.
   - `line 3` is the line of code with the error.
   - `<module>` is the scope of the error.

The type of error, the "who":

   ```console
   NameError:
   ```

   This is a [Python Error Type](https://docs.python.org/3/tutorial/errors.html).

The description, the "why":

   ```console
   name 'hello_world' is not defined
   ```

   The interpreter does the best job it can to tell you what it thinks went wrong.

You've solved games of _Clue_ with less information. This is one of the best
parts of programming: debugging and fixing errors. It's like you're a detective
solving a crime. The only bad thing is that more often than not, you're also the
criminal that caused the error in the first place.

Errors are clues, and reading them is the interpreter telling you what to do to
fix the program and move on.

***

## Three Common Error Types

### Syntax Errors

Syntax errors are pretty self-explanatory: they're the result of incorrect
syntax. Thankfully, they're usually followed by a guess about the location of
the error. For instance:

```py
2 * #
```

Will result in:

```console
File "<stdin>", line 1
    2 * #
        ^
SyntaxError: invalid syntax
```

Here, Python is saying that on line 1, there is a missing number (every `*`
operator must be preceded and followed by a number or variable with a numerical
value). Always read the full details of syntax errors and look for line numbers,
which usually appear at the beginning of the error message.

### Logic Errors

Logic errors are often difficult to find because they are not perceived as
errors by the Python interpreter itself. To find a logic error, a programmer
will often need to comb through their code line by line. Debugging tools such
as `pdb` (which we will cover later on in Phase 3) are very helpful for
locating and fixing logic errors.

```py
count = 1
while count < 100:
    print("%i" % count)
```

Will produce the following output:

```console
1
1
1
1
1
1
1
...
```

The programmer here forgot to increase the count during each iteration of the
`while` loop. This is perfectly valid Python code, so the interpreter will not
throw an error, but the loop will continue forever until it is manually
stopped by the user. (The easiest way to do this in the terminal is `ctrl + c`)

### Exceptions

[Exceptions](https://docs.python.org/3/library/exceptions.html) cover a wide
variety of errors that you may see when running Python code. Our `NameError`
from earlier is one example of a Python exception.

Exceptions pop up when the interpreter knows what to do with a piece of code
but is unable to complete the action. A key difference between the other types
of errors and exceptions is that the Python interpreter can continue reading
your application after an exception- you just need to tell it what to expect.

There are many types of exceptions in Python; here are a few of the most
common:

#### AssertionError

An `assert()` statement tells the interpreter that the code inside of it must
proceed without error or exception. If an assertion fails, an AssertionError is
raised.

```console
assert(1 == 2)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
AssertionError
```

#### IndexError and KeyError

IndexErrors arise when you try to access an element at an index past the end of
a list. Key errors relate to `dict` objects in Python (similar to JSON
objects). If a key is referenced but does not exist, this exception is thrown.

```console
> list = [0, 1, 2, 3, 4]
> dict = {'a':1, 'b':2, 'c':3}

> list[10]
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
IndexError: list index out of range

> dict['d']
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
KeyError: 'd'
```

#### NameError

A NameError arises when a name is referenced before it has been defined.

```console
> flatiron_school
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'flatiron_school' is not defined
```

#### TypeError

TypeErrors arise when an operation or function is applied to an object of the
wrong type.

```console
> wrong_type = 'abc' + 123
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: can only concatenate str (not "int") to str
```

***

## Instructions

To get started, run `pytest -x` to run the first test in the test suite.
Use the error messages to guide your work:

- Read the errors. Scroll through the entire output to get a sense of what the
  failures are trying to tell you. What does the error mean? How can we fix it?

- Each error prints out a **stack trace**, which points to where the code failed
  and attempts to follow it _up the stack_ — that is, through the bits of
  code that ran leading up to the failure. You can use these stack traces to
  pinpoint which line(s) of code need your attention.

- These stack traces can also point you to which files you should run to get a
  better sense of the errors.

Fix the errors in each of the files in `lib/`. Then confirm the fix by running
`pytest` again.

Commit and push your work using `git` when all of your tests have passed!



File: 997_seeditsolution_pythonprogram.txt
ID: 997
Full Name: seeditsolution/pythonprogram
Description: None
Created At: 2020-10-01T08:07:54Z
Updated At: 2023-11-06T12:37:57Z
Pushed At: 2022-10-20T04:02:57Z
Language: Python
URL: https://github.com/seeditsolution/pythonprogram
Forks: 539
Stars: 17
Topics: 
README:
# pythonprogram


it is a new python program
its help for beginners
#python
#beginners
#code
#2020




File: 999_Python001-class01_Python001-class01.txt
ID: 999
Full Name: Python001-class01/Python001-class01
Description: None
Created At: 2020-06-16T03:47:17Z
Updated At: 2024-04-17T14:38:04Z
Pushed At: 2021-08-02T06:57:11Z
Language: None
URL: https://github.com/Python001-class01/Python001-class01
Forks: 340
Stars: 15
Topics: 
README:
# 极客大学「Python进阶训练营-第1期」作业提交仓库

## 讲师课件下载地址

请大家通过该链接查看讲师课件并进行下载， 链接:https://pan.baidu.com/s/1za2g3PEptq5lh4sW-bCPVA  密码:yo3o


## 仓库目录结构说明

1. `week01/` 代表第一周作业提交目录，以此类推。
2. 请在对应周的目录下新建或修改自己的代码作业。
2. 每周均有一个 `NOTE.md` 文档，你可以将自己当周的学习心得以及做题过程中的思考记录在该文档中。

## 作业提交规则
 
1. 先将本仓库 Fork 到自己 GitHub 账号下。
2. 将 Fork 后的仓库 Clone 到本地，然后在本地仓库中对应周的目录下新建或修改自己的代码作业，当周的学习总结写在对应周的NOTE.md文件里。
3. 在本地仓库完成作业后，push 到自己的 GitHub 远程仓库。
4. 最后将远程仓库中当周的作业链接，按格式贴到班级仓库对应学习周的issue下面。
5. 提交issue请务必按照规定格式进行提交，否则作业统计工具将抓取不到你的作业提交记录。 


### Review 与点评
1. 助教会Review并点评大家的作业。
2. 你也可以看到其他同学的作业，取长补短。

## 注意事项
 如果对 Git 和 GitHub 不太了解，请参考 [Git 官方文档](https://git-scm.com/book/zh/v2) 或者极客时间的[《玩转 Git 三剑客》](https://time.geekbang.org/course/intro/145)视频课程。



